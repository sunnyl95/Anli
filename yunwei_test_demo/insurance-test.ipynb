{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据建模\n",
    "## 当在调试环境中运行时\n",
    "使用`保险数据集-训练 `抽样数据进行训练\n",
    "使用`保险数据集-c测试 `抽样数据进行测试\n",
    "## 当在全量环境中运行时\n",
    "使用`保险数据集-训练 `全量数据进行训练\n",
    "使用`保险数据集-c测试 `全量数据进行测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 再使用凸优化函数optim寻找最佳的数值分割点， Quadratic_Weighted_Kappa指标值可提升4个百分点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要的包\n",
    "\n",
    "#计算与可视化\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#评估指标、编码与模型\n",
    "from  sklearn.metrics import accuracy_score,  auc, confusion_matrix, roc_auc_score, classification_report,cohen_kappa_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from scipy.optimize import fmin_powell\n",
    "#from ml_metrics import quadratic_weighted_kappa\n",
    "\n",
    "from wf_analyse.analyse import base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看数据\n",
    "## 字段说明：\n",
    "* Ins_Age：申请人年龄（标准化处理过的结果）\n",
    "* Ht：申请人身高（标准化处理过的结果）\n",
    "* Wt：申请人体重（标准化处理过的结果）\n",
    "* BMI：申请人身体健康指数（标准化处理过的结果）\n",
    "* Product_Info_1-7：申请产品相关的变量（处理后的结果）\n",
    "* Employment_Info_1-6：有关申请人工作经验的变量（处理后的结果）\n",
    "* InsuredInfo_1-6：有关申请人的信息变量（处理后的结果）\n",
    "* Insurance_History_1-9：有关申请人过去的保险信息（处理后的结果）\n",
    "* Family_Hist_1-5:有关申请人家庭相关的信息（处理后的结果）\n",
    "* Medical_History_1-41：有关申请人的医疗史信息（处理后的结果）\n",
    "* Medical_Keyword_1-48：与该保险相关或不相关的医疗信息？？？不太确定含义，该信息是伪变量\n",
    "* Response：响应值（1-8级：1，2，3，4，5，6，7，8）\n",
    "\n",
    "## 字段类型说明：\n",
    "* 连续值变量：\n",
    "<p> Product_Info_4, Ins_Age, Ht, Wt, BMI, Employment_Info_1, Employment_Info_4, Employment_Info_6, Insurance_History_5, Family_Hist_2, Family_Hist_3, Family_Hist_4, Family_Hist_5.<p> \n",
    "\n",
    "* 离散值变量：\n",
    "<p> Medical_History_1, Medical_History_10, Medical_History_15, Medical_History_24, Medical_History_32\n",
    "Medical_Keyword_1-48 are dummy variables.<p> \n",
    "\n",
    "* 无序的类别变量：\n",
    "<p> Product_Info_1, Product_Info_2, Product_Info_3, Product_Info_5, Product_Info_6, Product_Info_7, Employment_Info_2, Employment_Info_3, Employment_Info_5, InsuredInfo_1, InsuredInfo_2, InsuredInfo_3, InsuredInfo_4, InsuredInfo_5, InsuredInfo_6, InsuredInfo_7, Insurance_History_1, Insurance_History_2, Insurance_History_3, Insurance_History_4, Insurance_History_7, Insurance_History_8, Insurance_History_9, Family_Hist_1, Medical_History_2, Medical_History_3, Medical_History_4, Medical_History_5, Medical_History_6, Medical_History_7, Medical_History_8, Medical_History_9, Medical_History_11, Medical_History_12, Medical_History_13, Medical_History_14, Medical_History_16, Medical_History_17, Medical_History_18, Medical_History_19, Medical_History_20, Medical_History_21, Medical_History_22, Medical_History_23, Medical_History_25, Medical_History_26, Medical_History_27, Medical_History_28, Medical_History_29, Medical_History_30, Medical_History_31, Medical_History_33, Medical_History_34, Medical_History_35, Medical_History_36, Medical_History_37, Medical_History_38, Medical_History_39, Medical_History_40, Medical_History_41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据集 insurance-train-sample\n",
    " \n",
    "import wfio\n",
    "_INPUT = '{\"type\":15,\"uri\":\"awss3175a27b5fa3d4cfcb8f037bf21c58374/sd_a27ddb1ba2fe4983ab7492e5b6a98fde\"}'\n",
    " \n",
    "# 读取并返回对应的Dataframe\n",
    "# 参数as_spark: 为True返回Spark DataFrame，为False返回Pandas DataFrame，默认为False \n",
    "train = wfio.read_dataframe(_INPUT,as_spark = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_info_1</th>\n",
       "      <th>product_info_2</th>\n",
       "      <th>product_info_3</th>\n",
       "      <th>product_info_4</th>\n",
       "      <th>product_info_5</th>\n",
       "      <th>product_info_6</th>\n",
       "      <th>product_info_7</th>\n",
       "      <th>ins_age</th>\n",
       "      <th>ht</th>\n",
       "      <th>wt</th>\n",
       "      <th>...</th>\n",
       "      <th>medical_keyword_40</th>\n",
       "      <th>medical_keyword_41</th>\n",
       "      <th>medical_keyword_42</th>\n",
       "      <th>medical_keyword_43</th>\n",
       "      <th>medical_keyword_44</th>\n",
       "      <th>medical_keyword_45</th>\n",
       "      <th>medical_keyword_46</th>\n",
       "      <th>medical_keyword_47</th>\n",
       "      <th>medical_keyword_48</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>A8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.322176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>A6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.225941</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.192469</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_info_1 product_info_2  product_info_3  product_info_4  \\\n",
       "80               1             A8              26        0.230769   \n",
       "81               1             A6              10        0.230769   \n",
       "82               1             A3              26        0.487179   \n",
       "\n",
       "    product_info_5  product_info_6  product_info_7   ins_age        ht  \\\n",
       "80               2               3               1  0.701493  0.781818   \n",
       "81               2               1               1  0.208955  0.727273   \n",
       "82               2               3               1  0.358209  0.618182   \n",
       "\n",
       "          wt  ...  medical_keyword_40  medical_keyword_41  medical_keyword_42  \\\n",
       "80  0.322176  ...                   0                   1                   0   \n",
       "81  0.225941  ...                   0                   0                   0   \n",
       "82  0.192469  ...                   0                   0                   0   \n",
       "\n",
       "    medical_keyword_43  medical_keyword_44  medical_keyword_45  \\\n",
       "80                   1                   0                   0   \n",
       "81                   0                   0                   0   \n",
       "82                   0                   0                   0   \n",
       "\n",
       "    medical_keyword_46  medical_keyword_47  medical_keyword_48  response  \n",
       "80                   0                   0                   0         7  \n",
       "81                   0                   0                   0         7  \n",
       "82                   0                   0                   0         8  \n",
       "\n",
       "[3 rows x 127 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = train[80:]\n",
    "train = train[:80]\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Columns: 127 entries, product_info_1 to response\n",
      "dtypes: float64(18), int64(108), object(1)\n",
      "memory usage: 79.5+ KB\n",
      "None\n",
      "Index(['product_info_1', 'product_info_2', 'product_info_3', 'product_info_4',\n",
      "       'product_info_5', 'product_info_6', 'product_info_7', 'ins_age', 'ht',\n",
      "       'wt',\n",
      "       ...\n",
      "       'medical_keyword_40', 'medical_keyword_41', 'medical_keyword_42',\n",
      "       'medical_keyword_43', 'medical_keyword_44', 'medical_keyword_45',\n",
      "       'medical_keyword_46', 'medical_keyword_47', 'medical_keyword_48',\n",
      "       'response'],\n",
      "      dtype='object', length=127)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_info_1</th>\n",
       "      <th>product_info_2</th>\n",
       "      <th>product_info_3</th>\n",
       "      <th>product_info_4</th>\n",
       "      <th>product_info_5</th>\n",
       "      <th>product_info_6</th>\n",
       "      <th>product_info_7</th>\n",
       "      <th>ins_age</th>\n",
       "      <th>ht</th>\n",
       "      <th>wt</th>\n",
       "      <th>...</th>\n",
       "      <th>medical_keyword_40</th>\n",
       "      <th>medical_keyword_41</th>\n",
       "      <th>medical_keyword_42</th>\n",
       "      <th>medical_keyword_43</th>\n",
       "      <th>medical_keyword_44</th>\n",
       "      <th>medical_keyword_45</th>\n",
       "      <th>medical_keyword_46</th>\n",
       "      <th>medical_keyword_47</th>\n",
       "      <th>medical_keyword_48</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.364103</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.472803</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.854545</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462687</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.309623</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>B2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.179104</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.361925</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_info_1 product_info_2  product_info_3  product_info_4  \\\n",
       "0               1             D3              26        0.364103   \n",
       "1               1             D4              26        0.487179   \n",
       "2               1             A8              26        0.076923   \n",
       "3               1             D3              26        0.076923   \n",
       "4               1             B2              29        0.487179   \n",
       "\n",
       "   product_info_5  product_info_6  product_info_7   ins_age        ht  \\\n",
       "0               2               3               1  0.373134  0.781818   \n",
       "1               2               3               1  0.298507  0.854545   \n",
       "2               2               3               1  0.462687  0.745455   \n",
       "3               2               3               1  0.044776  0.690909   \n",
       "4               2               3               3  0.179104  0.818182   \n",
       "\n",
       "         wt  ...  medical_keyword_40  medical_keyword_41  medical_keyword_42  \\\n",
       "0  0.472803  ...                   0                   0                   0   \n",
       "1  0.320084  ...                   0                   0                   0   \n",
       "2  0.309623  ...                   0                   0                   0   \n",
       "3  0.184100  ...                   0                   0                   0   \n",
       "4  0.361925  ...                   0                   0                   0   \n",
       "\n",
       "   medical_keyword_43  medical_keyword_44  medical_keyword_45  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   medical_keyword_46  medical_keyword_47  medical_keyword_48  response  \n",
       "0                   0                   0                   0         5  \n",
       "1                   0                   0                   0         8  \n",
       "2                   0                   0                   0         6  \n",
       "3                   0                   0                   0         6  \n",
       "4                   0                   0                   0         8  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看训练集数据情况\n",
    "print(train.info())  #\"Product_Info_2是\"object\"类型的数据，其他字段均是数值型\n",
    "print(train.columns)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 80 to 98\n",
      "Columns: 127 entries, product_info_1 to response\n",
      "dtypes: float64(18), int64(108), object(1)\n",
      "memory usage: 19.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_info_1</th>\n",
       "      <th>product_info_2</th>\n",
       "      <th>product_info_3</th>\n",
       "      <th>product_info_4</th>\n",
       "      <th>product_info_5</th>\n",
       "      <th>product_info_6</th>\n",
       "      <th>product_info_7</th>\n",
       "      <th>ins_age</th>\n",
       "      <th>ht</th>\n",
       "      <th>wt</th>\n",
       "      <th>...</th>\n",
       "      <th>medical_keyword_40</th>\n",
       "      <th>medical_keyword_41</th>\n",
       "      <th>medical_keyword_42</th>\n",
       "      <th>medical_keyword_43</th>\n",
       "      <th>medical_keyword_44</th>\n",
       "      <th>medical_keyword_45</th>\n",
       "      <th>medical_keyword_46</th>\n",
       "      <th>medical_keyword_47</th>\n",
       "      <th>medical_keyword_48</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>A8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.322176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>A6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.225941</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>A3</td>\n",
       "      <td>26</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>0.192469</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2</td>\n",
       "      <td>B2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.253731</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.263598</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>C4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358209</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.489540</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_info_1 product_info_2  product_info_3  product_info_4  \\\n",
       "80               1             A8              26        0.230769   \n",
       "81               1             A6              10        0.230769   \n",
       "82               1             A3              26        0.487179   \n",
       "83               2             B2              26        0.076923   \n",
       "84               1             C4              26        0.076923   \n",
       "\n",
       "    product_info_5  product_info_6  product_info_7   ins_age        ht  \\\n",
       "80               2               3               1  0.701493  0.781818   \n",
       "81               2               1               1  0.208955  0.727273   \n",
       "82               2               3               1  0.358209  0.618182   \n",
       "83               2               3               1  0.253731  0.709091   \n",
       "84               2               1               1  0.358209  0.781818   \n",
       "\n",
       "          wt  ...  medical_keyword_40  medical_keyword_41  medical_keyword_42  \\\n",
       "80  0.322176  ...                   0                   1                   0   \n",
       "81  0.225941  ...                   0                   0                   0   \n",
       "82  0.192469  ...                   0                   0                   0   \n",
       "83  0.263598  ...                   0                   0                   0   \n",
       "84  0.489540  ...                   0                   0                   0   \n",
       "\n",
       "    medical_keyword_43  medical_keyword_44  medical_keyword_45  \\\n",
       "80                   1                   0                   0   \n",
       "81                   0                   0                   0   \n",
       "82                   0                   0                   0   \n",
       "83                   0                   0                   0   \n",
       "84                   0                   0                   0   \n",
       "\n",
       "    medical_keyword_46  medical_keyword_47  medical_keyword_48  response  \n",
       "80                   0                   0                   0         7  \n",
       "81                   0                   0                   0         7  \n",
       "82                   0                   0                   0         8  \n",
       "83                   0                   0                   0         5  \n",
       "84                   0                   0                   0         5  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看测试集数据情况\n",
    "test.info()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_wrapper(yhat, y):  \n",
    "    y = np.array(y)\n",
    "    y = y.astype(int)\n",
    "    yhat = np.array(yhat)\n",
    "    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n",
    "    return cohen_kappa_score(yhat, y, weights= 'quadratic')\n",
    "    \n",
    "    \n",
    "def apply_offset(data, bin_offset, sv, scorer=eval_wrapper):\n",
    "    # data has the format of pred=0, offset_pred=1, labels=2 in the first dim\n",
    "    #data[0] = data[1]是预测值， data[2]是真实标签值\n",
    "    #sv是是类别编号sv = 0(1, 2, 3, 4, 5, 6, 7)\n",
    "    #把预测值等于sv这一类的样本预测值取出来 + bin_offset偏移量 作为新的预测值\n",
    "    data[1, data[0].astype(int)==sv] = data[0, data[0].astype(int)==sv] + bin_offset\n",
    "    score = scorer(data[1], data[2])\n",
    "    return score\n",
    "\n",
    "def new_target3(row):\n",
    "    if (row['BMI_Wt']=='under_weight') or (row['Old_Young']=='young')  or (row['Thin_Fat']=='thin'):\n",
    "        val='low_end'\n",
    "    else:\n",
    "        val='non_low_end'\n",
    "    return val\n",
    "\n",
    "\n",
    "def new_target1(row):\n",
    "    if (row['BMI_Wt']=='overweight') or (row['Old_Young']=='old')  or (row['Thin_Fat']=='fat'):\n",
    "        val='extremely_risky'\n",
    "    else:\n",
    "        val='not_extremely_risky'\n",
    "    return val\n",
    "\n",
    "def acc(y, yhat):  \n",
    "    y = np.array(y)\n",
    "    y = y.astype(int)\n",
    "    yhat = np.array(yhat)\n",
    "    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n",
    "    return accuracy_score(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全局变量\n",
    "columns_to_drop = ['response']\n",
    "xgb_num_rounds = 700\n",
    "num_classes = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test[\"response\"].copy()\n",
    "test[\"response\"] = -1000\n",
    "# 将训练集与测试集拼接，并于统一特征处理\n",
    "all_data = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminate missing values\n"
     ]
    }
   ],
   "source": [
    "# 创建新特征 \n",
    "# 特征编码\n",
    "all_data['product_info_2'] = pd.factorize(all_data['product_info_2'])[0]\n",
    "\n",
    "print('Eliminate missing values')    \n",
    "# 空值填充-1\n",
    "all_data.fillna(-1, inplace=True)\n",
    "\n",
    "# 将label转为int值\n",
    "all_data['response'] = all_data['response'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI离散化处理\n",
    "conditions = [\n",
    "    (all_data['bmi'] <= all_data['bmi'].quantile(0.25)),\n",
    "    (all_data['bmi'] > all_data['bmi'].quantile(0.25)) & (all_data['bmi'] <= all_data['bmi'].quantile(0.75)),\n",
    "    (all_data['bmi'] > all_data['bmi'].quantile(0.75))]\n",
    "\n",
    "choices = ['under_weight', 'average', 'overweight']\n",
    "\n",
    "all_data['BMI_Wt'] = np.select(conditions, choices)\n",
    "\n",
    "# 年龄离散化处理\n",
    "conditions = [\n",
    "    (all_data['ins_age'] <= all_data['ins_age'].quantile(0.25)),\n",
    "    (all_data['ins_age'] > all_data['ins_age'].quantile(0.25)) & (all_data['ins_age'] <= all_data['ins_age'].quantile(0.75)),\n",
    "    (all_data['ins_age'] > all_data['ins_age'].quantile(0.75))]\n",
    "\n",
    "choices = ['young', 'average', 'old']\n",
    "all_data['Old_Young'] = np.select(conditions, choices)\n",
    "\n",
    "# 身份离散化处理\n",
    "conditions = [\n",
    "    (all_data['ht'] <= all_data['ht'].quantile(0.25)),\n",
    "    (all_data['ht'] > all_data['ht'].quantile(0.25)) & (all_data['ht'] <= all_data['ht'].quantile(0.75)),\n",
    "    (all_data['ht'] > all_data['ht'].quantile(0.75))]\n",
    "\n",
    "choices = ['short', 'average', 'tall']\n",
    "\n",
    "all_data['Short_Tall'] = np.select(conditions, choices)\n",
    "\n",
    "# 体重离散化处理\n",
    "conditions = [\n",
    "    (all_data['wt'] <= all_data['wt'].quantile(0.25)),\n",
    "    (all_data['wt'] > all_data['wt'].quantile(0.25)) & (all_data['wt'] <= all_data['wt'].quantile(0.75)),\n",
    "    (all_data['wt'] > all_data['wt'].quantile(0.75))]\n",
    "\n",
    "choices = ['thin', 'average', 'fat']\n",
    "\n",
    "all_data['Thin_Fat'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建新特征\n",
    "all_data['extreme_risk'] = all_data.apply(new_target1,axis=1)\n",
    "#创建新特征\n",
    "all_data['low_end_risk'] = all_data.apply(new_target3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['BMI_Wt'] = pd.factorize(all_data['BMI_Wt'])[0]\n",
    "all_data['Old_Young'] = pd.factorize(all_data['Old_Young'])[0]\n",
    "all_data['Short_Tall'] = pd.factorize(all_data['Short_Tall'])[0]\n",
    "all_data['Thin_Fat'] = pd.factorize(all_data['Thin_Fat'])[0]\n",
    "all_data['extreme_risk'] = pd.factorize(all_data['extreme_risk'])[0]\n",
    "all_data['low_end_risk'] = pd.factorize(all_data['low_end_risk'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除无用特征\n",
    "all_data.drop([\"BMI_Wt\", \"Short_Tall\",\"Thin_Fat\",\"Old_Young\"], axis=1, inplace = True)\n",
    "#删除无用字段特征\n",
    "#all_data.drop([\"empty_name\", 'name', \"sex\", \"id_card\",\"mobile_number\", \"email\", \"addr\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params():\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"     \n",
    "    params[\"eta\"] = 0.05\n",
    "    params[\"min_child_weight\"] = 50\n",
    "    params[\"subsample\"] = 0.8\n",
    "    params[\"colsample_bytree\"] = 0.30\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 8\n",
    "    plst = list(params.items())\n",
    "    return plst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分数据集\n",
    "train = all_data[all_data['response']>0].copy()\n",
    "test = all_data[all_data['response']<1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转成xgb格式\n",
    "xgtrain = xgb.DMatrix(train.drop(columns_to_drop, axis=1), train['response'].values)\n",
    "xgtest = xgb.DMatrix(test.drop(columns_to_drop, axis=1), label=test_label.values)\n",
    "\n",
    "# 获取模型参数\n",
    "plst = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_process = dict()   #存储训练过程中的指标，便于后面loss曲线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:5.70722\ttest-rmse:5.76135\n",
      "[50]\ttrain-rmse:2.46571\ttest-rmse:2.23463\n",
      "[100]\ttrain-rmse:2.42794\ttest-rmse:2.15908\n",
      "[150]\ttrain-rmse:2.42787\ttest-rmse:2.15597\n",
      "[200]\ttrain-rmse:2.42794\ttest-rmse:2.15532\n",
      "[250]\ttrain-rmse:2.42783\ttest-rmse:2.15718\n",
      "[300]\ttrain-rmse:2.42838\ttest-rmse:2.15339\n",
      "[350]\ttrain-rmse:2.42822\ttest-rmse:2.16113\n",
      "[400]\ttrain-rmse:2.42785\ttest-rmse:2.15638\n",
      "[450]\ttrain-rmse:2.42785\ttest-rmse:2.15636\n",
      "[500]\ttrain-rmse:2.42822\ttest-rmse:2.15389\n",
      "[550]\ttrain-rmse:2.42785\ttest-rmse:2.15646\n",
      "[600]\ttrain-rmse:2.42784\ttest-rmse:2.15680\n",
      "[650]\ttrain-rmse:2.42795\ttest-rmse:2.15918\n",
      "[699]\ttrain-rmse:2.42801\ttest-rmse:2.15973\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(plst, xgtrain, xgb_num_rounds,evals=[(xgtrain, 'train'),(xgtest,'test')],verbose_eval=50, evals_result = evals_process)\n",
    "#每50轮打印一次结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evals_process['train'][\"rmse\"])   #训练了700个epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAESCAYAAAAVLtXjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de5TcdX3/8edrd/aSbK6QJVwUIhVpQQLYBSMGiEAKIsiJrYr1RlsOreVnT/X36w9sOVYQ1FqlWG+/InoQpJxab/UCpUklhQgoASEEGwElQCiEDZJsrpvLvn9/fL6bTIaZ3dlkZmd2vq/HOXN29juf+X7f893Z13zm870pIjAzs3xpa3QBZmY2/hz+ZmY55PA3M8shh7+ZWQ45/M3Mcsjhb01DklphGWYTgcPfmoKk+cAnx2FRb5X0f8dhOWZNzeFfA5IWSnpS0tOSLm10PSORdH5Wa7+kd1bR/iJJN9a5pqnA32W3evs+ME/S68fyJEmvlvRzSS9I+sc61VZuuadI+s54La9oua+XtCp7n/zVOC53TK+3UeunFcgHee0fSTOBVcD52c8HgfMiYlVDC6tA0s+BvwCWATMi4qVR2l8ELIiIi+pY05XAQxHx3Xoto2R5rwS+EhHnjOE5/wD8JiI+LunAiHixxjVdBCyNiNW1nO++kvRd4DsRcXM1r1fSXwI3RsT68amwOTXb33Ek7vnvvwuA+yPiZxExACwB3tTgmkYyE3gmkhGDfxydCfzbeC0sIp4Btkg6bAxPmwk8kz2/psGfuQiYU4f57quxvt6/BGbUtaKJ4SKa6+9YWUT4th834DPAZ4t+Pxw4jPQmuLFo+lJSD3r4/h8A3wN+nE07F/hWUfuvAn9Y9NijwBrgY1XU9B7gSWA1cFE27X8BzwO7gP7s/uQq5rXX68im/R7pW84zwF8XTf/TbNoLwNWjTc8emwTcVjLtY8BVwKeBF4GubNpi4CngC8AjwB1Z+wuAX2Xz/xrQlk0/GVgOPAtcT/ZNN3vsMuCcKl7/67J1tRXYkN0/K3ssyq0nIIB3AU8DvwaOLZrXg1mdtwCdWe3PA9uB32T3jy6a7wJST7K0pgeB/wGuA9pJgbMa+HA2jxXAwaO8tpf9HUerp8w8Kr6vyv0ds+lvJL2fnwP+FSiM8nrLrs+xtgdemy13Nen/a8Uo6+cU4BfZ3+sHwKRs+lHAXdn76tvA5LGut2a4NbyAiX4DbgCuLDN9dxhkvy9l7/B/DHgrMD2b1pm9KQvZ778CpgK92f1DSUH5KHDiCPX8NulD4pXZc54Gjit6fDUwZwyvr/R1HJi9secC04GHgXOzxwaAo4Hu7J966kjTs8cOBW4pWebHsn+svwF6i6b9EDgPWAvMBoayx1YAZ5NC8J+AV2fr83Hg2Gz6YmBR0TIuAd41hvVwI9kHadG0KLeeSOFzE1AAvgh8DuggBdFZWW0/BC4p9/4oWcYCisKtaD6/R/pQvAP4c1L4bycFbVs2/w+N8Hoq/h1HqmeE+b3sfVXu75hN/2rRe+b2kuXu9Xorrc99aQ/8C6kjcjSwporX9P2svYCrgTdm03/Kng7A14rX81jXWyNvBWx/7SD9EwIg6W2kXmKp0l0MvxYR3x/+JSK2S7oLOEXSBuDRiNgoaQHpm8SDWdMuUqD9vEI9C4EfRhraGB67PZvUU66FU0jj8yuy+d9I+mZyG2k7wqdJ32g+EBEbs+dUmg6pl3RgmeU8EhHXlEx7ANgErIqItUW7bS4DPgK8Cvh4RKyRdBwpEP8za9MJHAMMb1eYRQqsWin9+14VETslLQdOJ30oD0bEkuzx8/ZxOb8NbI+I/wCQ9P+APyGt/yB9MxyS9AAp1CsZ6e9YS+X+jv8beIekm0nfAv6livmUrs99ab+N9D7oJHUIRrMM+DNSp+umiHgs2znhJOAb2duvQMqACcdj/vvvCeDIot/PJYVQqdLx5fvKtPkW8Obs9q1smoA7I+LgiDgYeAXpq+ZIosL9Wqk0/7cC/0jqWa2U1DvKdCJiGzBZUmlHpNz6iZKfw/P4c+CvSd+SHpB0LGm9PVG03g4lDZEMewPw0GgvdAxK/76/KlfrMEnHSjpjH5dVaf0/HxFbRlpulfOppb3+jpLasmmHkXrl36tyPiOuzyrbryL15P+N9G1pRBHxaeCPSB8U/ylpIel9ta3kfTVue0PVksN//30HOEvScZJmA+eQvvoNkIZekHQu8FtVzOsOUk/oTNJXTkj/KCdKOlpSJ2n44vdGmMdi4DxJh0k6BFiUzbdW7gFOkPRaSdOA9wO3SZoMrCR9Q/koqYf+6krTS+Z5G3DhvhYk6VHS8MI1wH+ThjJWkT5UTs0C52bg4qz9UaQhmxf2dZmZjZJemfUG31/8QGRjAEV+CXRLOiOr5wrg+KLH1wFHZPWV+yY0bBXQJenM7P3wp+zprY8lwMv+Hcfw/FLrgCOUHDBCuwNInaPPkrYDVPUBWGZ97kv7i4E3RcSRUcWeZZLuAHoi4rPAj4G+SDt1rJT07qzZJ4Eri55W7d+x4Rz++ykiniRtYP0WaePiNRHxC+DfSf+kS0kBfE8V8xokbXzbFtkuc1lAXUz6MFgN3BsRFfeMibSL6UdIX1nvBf42Imo15EOkPT/eT3q9jwL/GhG3ZT3OL5GC/hngbuBnlaaXzPZzwJ+Nce+bYleSPnCfBzYCP4iI7cA7gc+TPhi2AV/OvmF8njQOvb+uIY1Z/wt7PqzLyup5Oyn01gCDpJ7vsE8BH5H0ImkYp9J8dpB2FvgM6f3wGGk7x5hU+juOdT5FPkraLrKONMxYabnrgK+Tdki4kfTt6zX7sdyxuB14TNIaSfdmQ6oj+RRwg6QXSJ23G7Pp7wU+IOk50jDcVSXPGfXv2Ay8n781BUmvJW2Q/Xidl/MWYFZEfL2ey7Hmkn0Lvp00Xr8TeAdwYUQsamhhDeTwN7OWl33j+xppSBXSt8S/iIifNK6qxnL4m5nlkMf8zcxyyOFvZpZDE+Igr1mzZsWcOXMaXYaZ2YTywAMPrIuI3nKPTYjwnzNnDsuXL290GWZmE4qkpyo95mEfM7MccvibmeWQw9/MLIcc/mZmOeTwNzPLIYe/mVkOOfzNzHKopcN/0+BOrl38GA89s77RpZiZNZWWDv8dO4f4x/98nIeefqnRpZiZNZWWDv+ujvTyBncONbgSM7Pm0tLh311I12jetsPhb2ZWrKXDv61NdLa3sW3nrkaXYmbWVFo6/AG6Cm1s2+HwNzMr1vrh39HuMX8zsxItH/7dHe75m5mVavnw7yq0MegNvmZme2n58O/uaGfQG3zNzPaSi/D3rp5mZnurafhLKkh6WtLS7HZchXY/L2qzsJY1lPLePmZmL1fra/jOBW6NiMsqNZB0IPDLiLiwxssuq7ujnY3bdo7HoszMJoxaD/vMAxZJWibpFknlPlxeD5wi6W5JP5I0rcY17MV7+5iZvVytw/9+4PSImA+sB84t0+bXwJkRcSqwFLio3IwkXSJpuaTl/f39+1xQV6HdR/iamZWodfiviIjnsvurgKPKtPk18MQobYiI6yOiLyL6ent797mg7g7v6mlmVqrW4X+zpOMltQOLgIfLtLkGOD+7//YKbWqmq9DuYR8zsxK1Dv+rgJuBh4B7gQcl3VDS5lrgbyStBAaBr9e4hr10dbSxzad3MDPbS0339omIlaQ9fopdXNLmOdJG33HRXWhn+84hhoaCtjaN12LNzJpaLg7yAti+y71/M7NhLR/+XYX0Ej3ub2a2R8uH/3DP36d4MDPbIwfhP3wdX/f8zcyGtXz4d/k6vmZmL9Py4T/c8/eYv5nZHjkI/9Tz96Uczcz2aPnw994+ZmYv1/Lhv2dvH4e/mdmwHIT/8N4+HvYxMxvW8uG/Z28f9/zNzIa1fvgP7+3jnr+Z2W4tH/679/Zxz9/MbLeWD//hvX085m9mtkfLh39nexuSx/zNzIq1fPhLottX8zIz20vLhz+kjb4e9jEz2yMX4e+ev5nZ3vIR/h1tPqunmVmRXIR/V6Hd5/M3MyuSi/B3z9/MbG+5CP+uDo/5m5kVy0f4F7y3j5lZsZqHv6SCpKclLc1ux1Vod6Wk+yV9odY1lOp2z9/MbC/16PnPBW6NiAXZ7ZHSBpL6gPnAycAaSWfVoY7dujva3fM3MytSj/CfByyStEzSLZIKZdqcBnw7IgJYApxa2kDSJZKWS1re39+/XwV1Fdp8YjczsyL1CP/7gdMjYj6wHji3TJse4Nns/gAwu7RBRFwfEX0R0dfb27tfBXV3tPmUzmZmRcr1yvfXiogYzO6vAo4q02YTMCm7P4U6b3j2Eb5mZnurR+jeLOl4Se3AIuDhMm0eII35AxwPrK5DHbt1dbSxbccu0iiTmZnVI/yvAm4GHgLuBR6UdENJm2XAiZI+B1wO3FqHOnbrLrQzFLBzyOFvZgZ1GPaJiJWkPX6KXVzSZijbw+ctwOci4sla11Fs+Gpe23bsoqM9F4c2mJmNqB5j/lWJiK3At8ZjWbuv47tjiKnd47FEM7PmlotucHchu46vT+5mZgbkJPyLe/5mZpaT8J9UNOZvZmY5Cf/JnWnTxpbtDn8zM8hJ+E/qTD3/Ldt3NrgSM7PmkI/wz4Z9trrnb2YG5CT8J2c9/60e8zczA3IW/h7zNzNLchH+3Z0e9jEzK5aL8J/c4WEfM7NiuQj/Qnsbne1tHvYxM8vkIvwhXdBlq3f1NDMDchT+kzsLHvYxM8vkKPzbPexjZpbJTfh3d7R7bx8zs0xuwn9yZ7uHfczMMrkJ/0ke9jEz2y0/4e9hHzOz3XIT/h72MTPbIzfhP6mz4GEfM7NMXcJf0mxJP6/wWEHS05KWZrfj6lFDqTTs44O8zMwACnWa72eASRUemwvcGhGX1WnZZQ0P+0QEksZz0WZmTafmPX9JZwCbgecrNJkHLJK0TNItkur1AbSXSZ3tDAUM7vRF3M3Mahr+kjqBjwKXj9DsfuD0iJgPrAfOrTCvSyQtl7S8v79/v2vryU7rvHnQQz9mZrXu+V8OfDEi1o/QZkVEPJfdXwUcVa5RRFwfEX0R0dfb27vfhfV0+SLuZmbDah3+ZwGXSloKnCDphjJtbpZ0vKR2YBHwcI1rKGs4/De5529mVt0GX0kzgUOB3wBrI6LswHlEnFb0nKXAtZKujogrippdBfwzIOD7EbFkH2sfkz09f4e/mdmo4S/pMlIPfTLwd8DZwPtGe15ELMjuXlEyfSVpj59xNaUrjflvGvSwj5lZNcM+50fEPODFiLgFOLLONdXF5M70OecNvmZm1YX/gKT3Ad2STiftoTPhTOly+JuZDasm/C8CTgReAi4A/qSeBdXLZO/qaWa226hj/hHxgqQPR0RIehWw/zvdN8DwBt/N3tXTzKyqDb5fBpZImgucSTpy9w/qXVitdRXaKLTJPX8zM6ob9jk2Ir4NzMuOyj20zjXVhSRfx9fMLFNN+O+UdB3wuKSTgR11rqlupnQVfJCXmRnVhf87gf8C/g/QA7y3rhXV0eSugg/yMjOjuiN83wWcAJxPOio3gD+uZ1H10tNV8EFeZmZUH/5/CAyRgn/CmtLV7g2+ZmZUF/5rgSXAU+zp+Z9Rz6LqZXJngRc3bWl0GWZmDVdN+HcAx0XEhE/NKV0FNnvM38ysqvA/GLhf0trhCRExQXv+7WzxmL+ZWVVH+P7ueBQyHryrp5lZMuqunpJuH49CxsPkzgKDO4fYucvX8TWzfKtmP/9HJF1Q90rGQU92Tn+f38fM8q6aMf+TgA9KegTYDMREHfOfUnQ1r+mTOhpcjZlZ41Qz5v+m8ShkPEz2Of3NzIDaX8C9qflSjmZmSa7Cf/hSjlvc8zeznMtV+A+P+Xt3TzPLu1yFf4/D38wMyFn4T+tO4b9xm8PfzPKtmss4HkQ6kVvn8LSIuKmK580G/j0iTqzw+FeB3wFui4irq654P0ztTrt3btw2Ya9HY2ZWE9X0/P8deAXpjJ7Dt2p8BphU7gFJbwPaI+IU4FBJR1U5z/3SWWijq9Dmnr+Z5V41B3kNRMRnxjJTSWeQDgh7vkKTBcA3s/s/BuYDj5fM4xLgEoDDDz98LIsf0dTuDgYc/maWc9X0/JdJulXSmyWdJum0kRpL6gQ+Clw+QrMe4Nns/gAwu7RBRFwfEX0R0dfb21tFmdWZ1l3wsI+Z5V41Pf8dwCrg5Oz3AO4aof3lwBcjYr1UcYRoE3uGhKYwjhuep05yz9/MrJrTO1w5xnmeBZwh6VLgBEk3RMTFJW0eIA313AccD/xyjMvYZ+75m5lV1/Mfk4jYPSwkaSlwraSrI+KKombfA+6WdCjwZmBereuoZGp3gec2bBuvxZmZNaWK4S/p2oj4sKQ72XPhdjGGs3pGxILs7hUl0wckLQAWAp+OiA1jLXxfTe3qcM/fzHKvYvhHxIezn3U5q2dEvMSePX7GzdTuAgNbPeZvZvmWqyN8AaZN6mDrjl3s8NW8zCzHqgp/Sb2SDs9ub6h3UfU0NTvFwybv8WNmOVbN6R2+CrwKmAlsIY3/z69zXXWz5xQPO5nZ0zlKazOz1lRNz/8I4BzgCeB0YEKPlwz3/Ae80dfMcqya8B8EzgTagbeTvgFMWA5/M7Pqwv8dpPPufIh0Fs4/r2tFdTataNjHzCyvqjnCdzNpyAfSOXsmNIe/mVkVPX9Jt49HIeNl6u4LunjYx8zyq5phn0ckXVD3SsbJFF/Ny8ysqnP7nAR8UNIjpHP0V316h2bU0d7GpI52Bra6529m+VXNmH9dTu/QSNMmFdzzN7NcG/PpHSRN2AO8hk3r7mCDe/5mlmPVbPBdXDLpk3WqZdzMnNzJS1u2N7oMM7OGGemUznOBE4HDJL0vm9wDTPiT4c/s6WD1ui2NLsPMrGFG6vmrzM8XSQd9TWju+ZtZ3o10Pv+HgYclHR0RN41jTXU3Iwv/iGCE6wybmbWsUcf8I+Kvx6OQ8TRzcgc7dgWbt+9qdClmZg2Ru4u5QBr2AXhps4d+zCyfchn+Myan8/us3+LdPc0sn3IZ/sMXcfFGXzPLq7qEv6QDJC2UNKse899fu4d9HP5mllM1D39JhwA/Ak4G7pTUW6ZNQdLTkpZmt+NqXcdIZnrYx8xyrpoTu43VscCHIuI+STOB1wF3lLSZC9waEZfVYfmjmj4phb97/maWVzXv+UfEkiz4TyP1/u8t02wesEjSMkm3SHrZh5CkSyQtl7S8v7+/pjUW2tuY1l3w3j5mllv1GvMX8E5gB1BuZ/r7gdMjYj6wHji3tEFEXB8RfRHR19v7spGj/Tazp5OXPOxjZjlVl/CP5FLgHuC8Mk1WRMRz2f1VwFH1qGMkM3yKBzPLsXps8L2s6ERwM0g9+1I3SzpeUjuwCHi41nWM5oDJHd7ga2a5VY+e//XAeyXdBbQDayRdXdLmKuBm4CHg3ohYUoc6RuSTu5lZntV8b5+IeAlYWDL5ipI2K0l7/DTMzJ5Ob/A1s9zK5RG+AL1Tu9i8fRebB305RzPLn9yG/+xpXQC8sHGwwZWYmY2/3Ib/QVO7AVg7MOEvTGZmNma5Df/hnr/D38zyKLfhf9C01PPv97CPmeVQbsN/aleB7o429/zNLJdyG/6SmD2t2xt8zSyXchv+ALOndrvnb2a5lOvw753WxQsD7vmbWf7kOvxnT/Wwj5nlU67D/6BpXWwa3MkmH+VrZjmT6/DffZSvx/3NLGfyHf67j/L10I+Z5Uuuw/+QGZMAeG7D1gZXYmY2vvId/tNTz/9/1jv8zSxfch3+3R3tzJrSybPrPeZvZvmS6/AHOHTGJPf8zSx3HP7THf5mlj8O/6znHxGNLsXMbNw4/Gd0s3n7Lga2+kAvM8uP3If/Ydnuns966MfMcqQu4S/pAEkLJc2qx/xr6dAs/D3ub2Z5UvPwl3QI8CPgZOBOSb0V2n1V0j2Srqh1DWOxO/x9oJeZ5Ug9ev7HAh+KiGuAO4DXlTaQ9DagPSJOAQ6VdFQd6qjKgT2ddBbaePYlh7+Z5UfNwz8ilkTEfZJOI/X+7y3TbAHwzez+j4H5pQ0kXSJpuaTl/f39tS5zt7Y2cfgBk1n94ua6LcPMrNnUa8xfwDuBHcCuMk16gGez+wPA7NIGEXF9RPRFRF9vb9mRo5p51awenlzn8Dez/KhL+EdyKXAPcF6ZJpuASdn9KfWqo1pH9vaw+sUt7Bryvv5mlg/12OB7maT3Zb/OANaXafYAe4Z6jgdW17qOsThyVg/bdw55jx8zy4169LivB94r6S6gHVgj6eqSNt/L2lwLvIO0d1DDvGrWFAB+1b+pkWWYmY2bQq1nGBEvAQtLJl9R0mZA0oKs3acjYkOt6xiLI3t7AHhy3WYWHN3ISszMxkfNw79a2YfEN0dtOA4O7OlkanfBG33NLDdyf3oHAEkc2TuFX/c7/M0sHxz+md+a1cPjL2xsdBlmZuPC4Z859rDprB0Y5IWNvqqXmbU+h39m7iumA7Dy2YZuezYzGxcO/8wxh0yjTbBijcPfzFqfwz/T01Xgt3qn8IjD38xywOFf5LhXTGfFsxt8SUcza3kO/yJzD5tO/8ZBntvgjb5m1toc/kX65hwAwL2/erHBlZiZ1ZfDv8gxh0xj1pRO/uux+l0/wMysGTj8i7S1iVOP6mXZE+sY8umdzayFOfxLnHrULH6zeTu/eG6g0aWYmdWNw7/E/FfPAmDZE+saXImZWf04/EscNK2b18yewk8c/mbWwhz+ZZz+ml5++uvf8OKmwUaXYmZWFw7/Mt7e90q27xri2w+uaXQpZmZ14fAv4zWzp9J3xExu/dkzPtrXzFqSw7+Cd518OE+u2+wNv2bWkhz+FZx3/CHMmtLFDXc/2ehSzMxqzuFfQVehnfe/4Qj+67F+HlvrK3yZWWtx+I/gPfOOYFJHO1f94Bds27Gr0eWYmdVMzcNf0nRJt0taLOm7kjrLtClIelrS0ux2XK3rqIWZPZ387fnHsOyJdXzitv9udDlmZjVTj57/u4FrI2Ih8DxwTpk2c4FbI2JBdnukDnXUxIUnH84fvXEON937FNctecx7/5hZSyjUeoYR8aWiX3uBF8o0mwcskvRG4Cng/RGxs9a11MoVbzmGga07uW7J4zy+dhPXXXgCHe0eMTOziatuCSbpDcDMiLivzMP3A6dHxHxgPXBumedfImm5pOX9/Y09xXJ7m/j7P5jLX519ND965Dnec8NPefiZ9Q2tycxsf6gewxiSDgD+A/j9iHiqzONdETGY3f8g0BkRn600v76+vli+fHnN69wX37jvKf5h8WO8uHk7p7+ml3edfDh9c2Yya0pXo0szM9uLpAcioq/sY7UO/2wD723A30XE4gptvglcA6wEFgOfiIgllebZTOEPsHHbDr5+z2puvOcp1m0apE3pqOCjZk/lsBmTmD2ti4OndXPQtG4Ont5N75QuOgseJjKz8TXe4f8B4BPAw9mkO4GOiLiiqM1rgX8GBHw/Iv5mpHk2W/gPG9y5ixVrNvCTJ9axYs0GHn9hI89v2MaOXS9fpx3tQhLtEm2CNom2tnS/vS091iZoV3a/jaytkEBSA16hWXNrxA4Y473E3zlkGl/8w9ft03NHCv96bPD9MvDlUdqsJO3xM6F1Fdo5ac4BnJRd+xdgaCh4act21g4MsnbjNtZu2MbagUEGd+5iKNKbdddQMBQwFLH7tmuo0mP4qmJmI2lAv2g8FznnwJ66zLfm4Z93bW3iwCldHDili2OY1uhyzMzK8kC0mVkOOfzNzHLI4W9mlkMOfzOzHHL4m5nlkMPfzCyHHP5mZjnk8Dczy6G6nNit1iT1k079vK9mARPlSuwTqVaYWPVOpFphYtU7kWqFiVXv/tR6RET0lntgQoT//pK0vNL5LZrNRKoVJla9E6lWmFj1TqRaYWLVW69aPexjZpZDDn8zsxzKS/hf3+gCxmAi1QoTq96JVCtMrHonUq0wseqtS625GPM3M7O95aXnb2ZmRRz+1nIkHSBpoaRZja7FrFm1fPhL+qqkeyRdMXrr8SVptqS7s/sdkn6Y1frHlaY1qM7pkm6XtFjSdyV1lluvzbCuJR0C/Ag4GbhTUm+z1lpUy2xJP69UV7PUKqkg6WlJS7PbcZKulHS/pC8UtXvZtEaS9CVJ52f3m3L9SvpA0Xp9SNI/1bvWlg5/SW8D2iPiFOBQSUc1uqZhkmYCXweGr9H2QWB5Vut5kqZWmNYI7waujYiFwPPAhZSs1yZa18cCH4qIa4A7gDOauNZhnwEmlauryWqdC9waEQsiYgHQBcwnfdCukXSWpL7SaQ2rFpB0KnBwRPygmddvRHy5aL3eDTxW71pbOvyBBcA3s/s/Jr0pm8Uu4J3AQPb7AvbUeg/QV2HauIuIL0XE4uzXXuA9vHy9LigzbdxFxJKIuE/SaaQAOrtMXQvKTGsISWcAm0kfqgto4lqBecAiScsk3UL6YP12pL1GlgCnAqeVmdYQkjqArwCrJV1A869fJB0GzAaOoM61tnr49wDPZvcHSCu1KUTEQERsKJpUrtamql/SG4CZwDM0ca2SRPpg3UG61nZT1iqpE/gocHk2qdnfA/cDp0fEfGA9MInmrvd9wC+AT5M6ApfS3PVCqvHLjMN7odXDfxPpDQowheZ+veVqbZr6JR0AfB744wp1NU2tkVxK+rY0r0xdzVLr5cAXI2J99ntTr1dgRUQ8l91fRfPXeyJwfUQ8D3wDuIsmrldSG/CmiLizQl01rbWZw7AWHmDPV6PjgdWNK2VU5WptivqzHuo3gY9ExFMV6mqWWi+T9L7s1xnAp8rU1RS1AmcBl0paCpwAnE/z1gpws6TjJbUDi0g90Wau9wngyOx+HzCH5q73VOCn2f36/49FRMvegGnAw8C1wH8D0xtdU5kal2Y/jwAeBT5H+nrdXm5ag2r8APASsDS7vb90vTbLuiYNSy0m9fK+lNXWlLWWvg/K1dVMtQKvBVYAjwDXkDqPP8nen78EXlVuWgPrnQr8a/ZeuDf7f2rm9fsJ4G3Z/bq/F1r+CN9sr5qFwF2Rvv41LUmHkj7Z74hse0C5ac2g3Hpt1nXtWutH0iTgLcCDEfHrStOaxURav/WutWwemLAAAAI0SURBVOXD38zMXq7Vx/zNzKwMh7+ZWQ45/M3Mcsjhby1J0gmSTtiP519Xy3r2sYaLJF3U6DqsNTn8rVWdkN32SUT8ZQ1rMWs63tvHWo6kT5IOQgJ4NiLOzKYvJR0vMTcizpY0hXTwWjfwVET8UdE8lkY6yRaSPgZ0kHa5nQ6cU243O0mTgZuAg4BHIuLS7LmvByYD/cCFEbFT0udJH07rSachWA98IZu2g3TyvHNIB/McDxwMvCMiVtZgFZm552+tJyI+Qjqy91PDwZ+ZB9wbEWdnvx8CfBF4MzBH0kjnSnl1RJwO/DPphGblXAKsjIjTgEMkzc2m3509dy1wgaTzgO6IOBX4FnAZ6ejeQkS8kXSWz9/NnnsS6eR0HwPeWtUKMKuCw9/yZGVEfKfo9x3AxcAtwAHsOW9KOTdlP18AOiu0OZp01sulpNMKHJZNfyD7uYJ0ioFj2HMY/0+B3wF+G/gZQET8ELg9e/zWiNgxynLNxszhb61qK2moZfgsn5BOjFXsT0g973eRTqs8ktEeh3Q6g+uy4aIrgKez6SdnP08knW/mUdK3ELKfj5JOlHZSVu+7gY+PYblmY+bwt1a1GHibpJ9Q+Zzyi4GPkM6NDnt66vvqK8CbJd0F/Bnp1NcAJ2XfBmYAP4iIHwFbla7i9vvA3wM/ACJ77nuBhu9tZK3NG3zN6ijb4Ls0IpY2uBSzvTj8zcxyyMM+ZmY55PA3M8shh7+ZWQ45/M3Mcsjhb2aWQ/8fe6Qh9QBy8n8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制训练集的训练过程中的loss曲线图\n",
    "epoch = []  # 横坐标,迭代次数\n",
    "for i in range(0, xgb_num_rounds, 1):\n",
    "    epoch.append(i)\n",
    "\n",
    "plt.plot(epoch, evals_process['train'][\"rmse\"])\n",
    "plt.ylabel('train rmse')\n",
    "plt.xlabel('train epoch')\n",
    "plt.title(\" Curve of loss(rmse) function of training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 【train】【step:0】 loss : 5.70722\n",
      "saving 【train】【step:1】 loss : 5.481913\n",
      "saving 【train】【step:2】 loss : 5.256111\n",
      "saving 【train】【step:3】 loss : 5.05688\n",
      "saving 【train】【step:4】 loss : 4.854747\n",
      "saving 【train】【step:5】 loss : 4.670874\n",
      "saving 【train】【step:6】 loss : 4.508413\n",
      "saving 【train】【step:7】 loss : 4.351405\n",
      "saving 【train】【step:8】 loss : 4.197197\n",
      "saving 【train】【step:9】 loss : 4.066993\n",
      "saving 【train】【step:10】 loss : 3.934573\n",
      "saving 【train】【step:11】 loss : 3.813567\n",
      "saving 【train】【step:12】 loss : 3.702598\n",
      "saving 【train】【step:13】 loss : 3.600746\n",
      "saving 【train】【step:14】 loss : 3.514599\n",
      "saving 【train】【step:15】 loss : 3.412749\n",
      "saving 【train】【step:16】 loss : 3.335542\n",
      "saving 【train】【step:17】 loss : 3.263172\n",
      "saving 【train】【step:18】 loss : 3.196223\n",
      "saving 【train】【step:19】 loss : 3.132209\n",
      "saving 【train】【step:20】 loss : 3.069352\n",
      "saving 【train】【step:21】 loss : 3.011003\n",
      "saving 【train】【step:22】 loss : 2.960222\n",
      "saving 【train】【step:23】 loss : 2.908312\n",
      "saving 【train】【step:24】 loss : 2.8668\n",
      "saving 【train】【step:25】 loss : 2.830964\n",
      "saving 【train】【step:26】 loss : 2.792563\n",
      "saving 【train】【step:27】 loss : 2.759777\n",
      "saving 【train】【step:28】 loss : 2.735134\n",
      "saving 【train】【step:29】 loss : 2.707885\n",
      "saving 【train】【step:30】 loss : 2.676844\n",
      "saving 【train】【step:31】 loss : 2.653602\n",
      "saving 【train】【step:32】 loss : 2.634011\n",
      "saving 【train】【step:33】 loss : 2.615\n",
      "saving 【train】【step:34】 loss : 2.599531\n",
      "saving 【train】【step:35】 loss : 2.582015\n",
      "saving 【train】【step:36】 loss : 2.56563\n",
      "saving 【train】【step:37】 loss : 2.551343\n",
      "saving 【train】【step:38】 loss : 2.54092\n",
      "saving 【train】【step:39】 loss : 2.535081\n",
      "saving 【train】【step:40】 loss : 2.523282\n",
      "saving 【train】【step:41】 loss : 2.515843\n",
      "saving 【train】【step:42】 loss : 2.508496\n",
      "saving 【train】【step:43】 loss : 2.501758\n",
      "saving 【train】【step:44】 loss : 2.496702\n",
      "saving 【train】【step:45】 loss : 2.491581\n",
      "saving 【train】【step:46】 loss : 2.482567\n",
      "saving 【train】【step:47】 loss : 2.476629\n",
      "saving 【train】【step:48】 loss : 2.47409\n",
      "saving 【train】【step:49】 loss : 2.469165\n",
      "saving 【train】【step:50】 loss : 2.465714\n",
      "saving 【train】【step:51】 loss : 2.462383\n",
      "saving 【train】【step:52】 loss : 2.459155\n",
      "saving 【train】【step:53】 loss : 2.456538\n",
      "saving 【train】【step:54】 loss : 2.452768\n",
      "saving 【train】【step:55】 loss : 2.45181\n",
      "saving 【train】【step:56】 loss : 2.450202\n",
      "saving 【train】【step:57】 loss : 2.4474\n",
      "saving 【train】【step:58】 loss : 2.44551\n",
      "saving 【train】【step:59】 loss : 2.443907\n",
      "saving 【train】【step:60】 loss : 2.441969\n",
      "saving 【train】【step:61】 loss : 2.441405\n",
      "saving 【train】【step:62】 loss : 2.440741\n",
      "saving 【train】【step:63】 loss : 2.439908\n",
      "saving 【train】【step:64】 loss : 2.439099\n",
      "saving 【train】【step:65】 loss : 2.438376\n",
      "saving 【train】【step:66】 loss : 2.436332\n",
      "saving 【train】【step:67】 loss : 2.43561\n",
      "saving 【train】【step:68】 loss : 2.435007\n",
      "saving 【train】【step:69】 loss : 2.43365\n",
      "saving 【train】【step:70】 loss : 2.433472\n",
      "saving 【train】【step:71】 loss : 2.433059\n",
      "saving 【train】【step:72】 loss : 2.432781\n",
      "saving 【train】【step:73】 loss : 2.431824\n",
      "saving 【train】【step:74】 loss : 2.430477\n",
      "saving 【train】【step:75】 loss : 2.430255\n",
      "saving 【train】【step:76】 loss : 2.430305\n",
      "saving 【train】【step:77】 loss : 2.430187\n",
      "saving 【train】【step:78】 loss : 2.42998\n",
      "saving 【train】【step:79】 loss : 2.429898\n",
      "saving 【train】【step:80】 loss : 2.429736\n",
      "saving 【train】【step:81】 loss : 2.429736\n",
      "saving 【train】【step:82】 loss : 2.429709\n",
      "saving 【train】【step:83】 loss : 2.429394\n",
      "saving 【train】【step:84】 loss : 2.429256\n",
      "saving 【train】【step:85】 loss : 2.428696\n",
      "saving 【train】【step:86】 loss : 2.428343\n",
      "saving 【train】【step:87】 loss : 2.428301\n",
      "saving 【train】【step:88】 loss : 2.42831\n",
      "saving 【train】【step:89】 loss : 2.428433\n",
      "saving 【train】【step:90】 loss : 2.428488\n",
      "saving 【train】【step:91】 loss : 2.428361\n",
      "saving 【train】【step:92】 loss : 2.428376\n",
      "saving 【train】【step:93】 loss : 2.428252\n",
      "saving 【train】【step:94】 loss : 2.428046\n",
      "saving 【train】【step:95】 loss : 2.428048\n",
      "saving 【train】【step:96】 loss : 2.428046\n",
      "saving 【train】【step:97】 loss : 2.428001\n",
      "saving 【train】【step:98】 loss : 2.428015\n",
      "saving 【train】【step:99】 loss : 2.428017\n",
      "saving 【train】【step:100】 loss : 2.427938\n",
      "saving 【train】【step:101】 loss : 2.427883\n",
      "saving 【train】【step:102】 loss : 2.427849\n",
      "saving 【train】【step:103】 loss : 2.427841\n",
      "saving 【train】【step:104】 loss : 2.427839\n",
      "saving 【train】【step:105】 loss : 2.427834\n",
      "saving 【train】【step:106】 loss : 2.427847\n",
      "saving 【train】【step:107】 loss : 2.427841\n",
      "saving 【train】【step:108】 loss : 2.427836\n",
      "saving 【train】【step:109】 loss : 2.427835\n",
      "saving 【train】【step:110】 loss : 2.427844\n",
      "saving 【train】【step:111】 loss : 2.427874\n",
      "saving 【train】【step:112】 loss : 2.427864\n",
      "saving 【train】【step:113】 loss : 2.427868\n",
      "saving 【train】【step:114】 loss : 2.427849\n",
      "saving 【train】【step:115】 loss : 2.427836\n",
      "saving 【train】【step:116】 loss : 2.427835\n",
      "saving 【train】【step:117】 loss : 2.42784\n",
      "saving 【train】【step:118】 loss : 2.427853\n",
      "saving 【train】【step:119】 loss : 2.42794\n",
      "saving 【train】【step:120】 loss : 2.427949\n",
      "saving 【train】【step:121】 loss : 2.427938\n",
      "saving 【train】【step:122】 loss : 2.428022\n",
      "saving 【train】【step:123】 loss : 2.427948\n",
      "saving 【train】【step:124】 loss : 2.42785\n",
      "saving 【train】【step:125】 loss : 2.427859\n",
      "saving 【train】【step:126】 loss : 2.427863\n",
      "saving 【train】【step:127】 loss : 2.427864\n",
      "saving 【train】【step:128】 loss : 2.427881\n",
      "saving 【train】【step:129】 loss : 2.427851\n",
      "saving 【train】【step:130】 loss : 2.427865\n",
      "saving 【train】【step:131】 loss : 2.42787\n",
      "saving 【train】【step:132】 loss : 2.42791\n",
      "saving 【train】【step:133】 loss : 2.427869\n",
      "saving 【train】【step:134】 loss : 2.427843\n",
      "saving 【train】【step:135】 loss : 2.427848\n",
      "saving 【train】【step:136】 loss : 2.427892\n",
      "saving 【train】【step:137】 loss : 2.427873\n",
      "saving 【train】【step:138】 loss : 2.427888\n",
      "saving 【train】【step:139】 loss : 2.427862\n",
      "saving 【train】【step:140】 loss : 2.427925\n",
      "saving 【train】【step:141】 loss : 2.427933\n",
      "saving 【train】【step:142】 loss : 2.427872\n",
      "saving 【train】【step:143】 loss : 2.427854\n",
      "saving 【train】【step:144】 loss : 2.427841\n",
      "saving 【train】【step:145】 loss : 2.427836\n",
      "saving 【train】【step:146】 loss : 2.427835\n",
      "saving 【train】【step:147】 loss : 2.427834\n",
      "saving 【train】【step:148】 loss : 2.427835\n",
      "saving 【train】【step:149】 loss : 2.427853\n",
      "saving 【train】【step:150】 loss : 2.427873\n",
      "saving 【train】【step:151】 loss : 2.427886\n",
      "saving 【train】【step:152】 loss : 2.427844\n",
      "saving 【train】【step:153】 loss : 2.42784\n",
      "saving 【train】【step:154】 loss : 2.427836\n",
      "saving 【train】【step:155】 loss : 2.427852\n",
      "saving 【train】【step:156】 loss : 2.427842\n",
      "saving 【train】【step:157】 loss : 2.42786\n",
      "saving 【train】【step:158】 loss : 2.427844\n",
      "saving 【train】【step:159】 loss : 2.427866\n",
      "saving 【train】【step:160】 loss : 2.427858\n",
      "saving 【train】【step:161】 loss : 2.427848\n",
      "saving 【train】【step:162】 loss : 2.427835\n",
      "saving 【train】【step:163】 loss : 2.427908\n",
      "saving 【train】【step:164】 loss : 2.427853\n",
      "saving 【train】【step:165】 loss : 2.427868\n",
      "saving 【train】【step:166】 loss : 2.427908\n",
      "saving 【train】【step:167】 loss : 2.42788\n",
      "saving 【train】【step:168】 loss : 2.4279\n",
      "saving 【train】【step:169】 loss : 2.427963\n",
      "saving 【train】【step:170】 loss : 2.428192\n",
      "saving 【train】【step:171】 loss : 2.428389\n",
      "saving 【train】【step:172】 loss : 2.428325\n",
      "saving 【train】【step:173】 loss : 2.428185\n",
      "saving 【train】【step:174】 loss : 2.4282\n",
      "saving 【train】【step:175】 loss : 2.428229\n",
      "saving 【train】【step:176】 loss : 2.428226\n",
      "saving 【train】【step:177】 loss : 2.428359\n",
      "saving 【train】【step:178】 loss : 2.4283\n",
      "saving 【train】【step:179】 loss : 2.428356\n",
      "saving 【train】【step:180】 loss : 2.428164\n",
      "saving 【train】【step:181】 loss : 2.428143\n",
      "saving 【train】【step:182】 loss : 2.428445\n",
      "saving 【train】【step:183】 loss : 2.428405\n",
      "saving 【train】【step:184】 loss : 2.428309\n",
      "saving 【train】【step:185】 loss : 2.428062\n",
      "saving 【train】【step:186】 loss : 2.428004\n",
      "saving 【train】【step:187】 loss : 2.427913\n",
      "saving 【train】【step:188】 loss : 2.427937\n",
      "saving 【train】【step:189】 loss : 2.428113\n",
      "saving 【train】【step:190】 loss : 2.428167\n",
      "saving 【train】【step:191】 loss : 2.428031\n",
      "saving 【train】【step:192】 loss : 2.427992\n",
      "saving 【train】【step:193】 loss : 2.42794\n",
      "saving 【train】【step:194】 loss : 2.427928\n",
      "saving 【train】【step:195】 loss : 2.427917\n",
      "saving 【train】【step:196】 loss : 2.427955\n",
      "saving 【train】【step:197】 loss : 2.427923\n",
      "saving 【train】【step:198】 loss : 2.427926\n",
      "saving 【train】【step:199】 loss : 2.427936\n",
      "saving 【train】【step:200】 loss : 2.427937\n",
      "saving 【train】【step:201】 loss : 2.427935\n",
      "saving 【train】【step:202】 loss : 2.428051\n",
      "saving 【train】【step:203】 loss : 2.428134\n",
      "saving 【train】【step:204】 loss : 2.428101\n",
      "saving 【train】【step:205】 loss : 2.428014\n",
      "saving 【train】【step:206】 loss : 2.427881\n",
      "saving 【train】【step:207】 loss : 2.428071\n",
      "saving 【train】【step:208】 loss : 2.428112\n",
      "saving 【train】【step:209】 loss : 2.428204\n",
      "saving 【train】【step:210】 loss : 2.428277\n",
      "saving 【train】【step:211】 loss : 2.42818\n",
      "saving 【train】【step:212】 loss : 2.428056\n",
      "saving 【train】【step:213】 loss : 2.427992\n",
      "saving 【train】【step:214】 loss : 2.427943\n",
      "saving 【train】【step:215】 loss : 2.427977\n",
      "saving 【train】【step:216】 loss : 2.427963\n",
      "saving 【train】【step:217】 loss : 2.427945\n",
      "saving 【train】【step:218】 loss : 2.427896\n",
      "saving 【train】【step:219】 loss : 2.427862\n",
      "saving 【train】【step:220】 loss : 2.427916\n",
      "saving 【train】【step:221】 loss : 2.427858\n",
      "saving 【train】【step:222】 loss : 2.427865\n",
      "saving 【train】【step:223】 loss : 2.42786\n",
      "saving 【train】【step:224】 loss : 2.427842\n",
      "saving 【train】【step:225】 loss : 2.427836\n",
      "saving 【train】【step:226】 loss : 2.427851\n",
      "saving 【train】【step:227】 loss : 2.427834\n",
      "saving 【train】【step:228】 loss : 2.427847\n",
      "saving 【train】【step:229】 loss : 2.427834\n",
      "saving 【train】【step:230】 loss : 2.427836\n",
      "saving 【train】【step:231】 loss : 2.427834\n",
      "saving 【train】【step:232】 loss : 2.427841\n",
      "saving 【train】【step:233】 loss : 2.427842\n",
      "saving 【train】【step:234】 loss : 2.427842\n",
      "saving 【train】【step:235】 loss : 2.427872\n",
      "saving 【train】【step:236】 loss : 2.427839\n",
      "saving 【train】【step:237】 loss : 2.427846\n",
      "saving 【train】【step:238】 loss : 2.427837\n",
      "saving 【train】【step:239】 loss : 2.427833\n",
      "saving 【train】【step:240】 loss : 2.427834\n",
      "saving 【train】【step:241】 loss : 2.427867\n",
      "saving 【train】【step:242】 loss : 2.427914\n",
      "saving 【train】【step:243】 loss : 2.427953\n",
      "saving 【train】【step:244】 loss : 2.427904\n",
      "saving 【train】【step:245】 loss : 2.427965\n",
      "saving 【train】【step:246】 loss : 2.427909\n",
      "saving 【train】【step:247】 loss : 2.427859\n",
      "saving 【train】【step:248】 loss : 2.427836\n",
      "saving 【train】【step:249】 loss : 2.427837\n",
      "saving 【train】【step:250】 loss : 2.427834\n",
      "saving 【train】【step:251】 loss : 2.427855\n",
      "saving 【train】【step:252】 loss : 2.427858\n",
      "saving 【train】【step:253】 loss : 2.427874\n",
      "saving 【train】【step:254】 loss : 2.427866\n",
      "saving 【train】【step:255】 loss : 2.42799\n",
      "saving 【train】【step:256】 loss : 2.42798\n",
      "saving 【train】【step:257】 loss : 2.427945\n",
      "saving 【train】【step:258】 loss : 2.428021\n",
      "saving 【train】【step:259】 loss : 2.427958\n",
      "saving 【train】【step:260】 loss : 2.427908\n",
      "saving 【train】【step:261】 loss : 2.427931\n",
      "saving 【train】【step:262】 loss : 2.427983\n",
      "saving 【train】【step:263】 loss : 2.427966\n",
      "saving 【train】【step:264】 loss : 2.427984\n",
      "saving 【train】【step:265】 loss : 2.427943\n",
      "saving 【train】【step:266】 loss : 2.427947\n",
      "saving 【train】【step:267】 loss : 2.428058\n",
      "saving 【train】【step:268】 loss : 2.428076\n",
      "saving 【train】【step:269】 loss : 2.428153\n",
      "saving 【train】【step:270】 loss : 2.428194\n",
      "saving 【train】【step:271】 loss : 2.428445\n",
      "saving 【train】【step:272】 loss : 2.428655\n",
      "saving 【train】【step:273】 loss : 2.428429\n",
      "saving 【train】【step:274】 loss : 2.428328\n",
      "saving 【train】【step:275】 loss : 2.42832\n",
      "saving 【train】【step:276】 loss : 2.428346\n",
      "saving 【train】【step:277】 loss : 2.428162\n",
      "saving 【train】【step:278】 loss : 2.428087\n",
      "saving 【train】【step:279】 loss : 2.428052\n",
      "saving 【train】【step:280】 loss : 2.428043\n",
      "saving 【train】【step:281】 loss : 2.428051\n",
      "saving 【train】【step:282】 loss : 2.428145\n",
      "saving 【train】【step:283】 loss : 2.428052\n",
      "saving 【train】【step:284】 loss : 2.42801\n",
      "saving 【train】【step:285】 loss : 2.42821\n",
      "saving 【train】【step:286】 loss : 2.42811\n",
      "saving 【train】【step:287】 loss : 2.428062\n",
      "saving 【train】【step:288】 loss : 2.427979\n",
      "saving 【train】【step:289】 loss : 2.428025\n",
      "saving 【train】【step:290】 loss : 2.427899\n",
      "saving 【train】【step:291】 loss : 2.42787\n",
      "saving 【train】【step:292】 loss : 2.427939\n",
      "saving 【train】【step:293】 loss : 2.428059\n",
      "saving 【train】【step:294】 loss : 2.428025\n",
      "saving 【train】【step:295】 loss : 2.428025\n",
      "saving 【train】【step:296】 loss : 2.428099\n",
      "saving 【train】【step:297】 loss : 2.428207\n",
      "saving 【train】【step:298】 loss : 2.428114\n",
      "saving 【train】【step:299】 loss : 2.42812\n",
      "saving 【train】【step:300】 loss : 2.428379\n",
      "saving 【train】【step:301】 loss : 2.428276\n",
      "saving 【train】【step:302】 loss : 2.428303\n",
      "saving 【train】【step:303】 loss : 2.428227\n",
      "saving 【train】【step:304】 loss : 2.4282\n",
      "saving 【train】【step:305】 loss : 2.428201\n",
      "saving 【train】【step:306】 loss : 2.428344\n",
      "saving 【train】【step:307】 loss : 2.428418\n",
      "saving 【train】【step:308】 loss : 2.428108\n",
      "saving 【train】【step:309】 loss : 2.428018\n",
      "saving 【train】【step:310】 loss : 2.428008\n",
      "saving 【train】【step:311】 loss : 2.427886\n",
      "saving 【train】【step:312】 loss : 2.427931\n",
      "saving 【train】【step:313】 loss : 2.427979\n",
      "saving 【train】【step:314】 loss : 2.427963\n",
      "saving 【train】【step:315】 loss : 2.427884\n",
      "saving 【train】【step:316】 loss : 2.427836\n",
      "saving 【train】【step:317】 loss : 2.427834\n",
      "saving 【train】【step:318】 loss : 2.427866\n",
      "saving 【train】【step:319】 loss : 2.427843\n",
      "saving 【train】【step:320】 loss : 2.427852\n",
      "saving 【train】【step:321】 loss : 2.427885\n",
      "saving 【train】【step:322】 loss : 2.427952\n",
      "saving 【train】【step:323】 loss : 2.42809\n",
      "saving 【train】【step:324】 loss : 2.428141\n",
      "saving 【train】【step:325】 loss : 2.428103\n",
      "saving 【train】【step:326】 loss : 2.428151\n",
      "saving 【train】【step:327】 loss : 2.428154\n",
      "saving 【train】【step:328】 loss : 2.428091\n",
      "saving 【train】【step:329】 loss : 2.428107\n",
      "saving 【train】【step:330】 loss : 2.428242\n",
      "saving 【train】【step:331】 loss : 2.42838\n",
      "saving 【train】【step:332】 loss : 2.428162\n",
      "saving 【train】【step:333】 loss : 2.428216\n",
      "saving 【train】【step:334】 loss : 2.428316\n",
      "saving 【train】【step:335】 loss : 2.428082\n",
      "saving 【train】【step:336】 loss : 2.428143\n",
      "saving 【train】【step:337】 loss : 2.428169\n",
      "saving 【train】【step:338】 loss : 2.428189\n",
      "saving 【train】【step:339】 loss : 2.428157\n",
      "saving 【train】【step:340】 loss : 2.428194\n",
      "saving 【train】【step:341】 loss : 2.428203\n",
      "saving 【train】【step:342】 loss : 2.42837\n",
      "saving 【train】【step:343】 loss : 2.428204\n",
      "saving 【train】【step:344】 loss : 2.428172\n",
      "saving 【train】【step:345】 loss : 2.428157\n",
      "saving 【train】【step:346】 loss : 2.428247\n",
      "saving 【train】【step:347】 loss : 2.428043\n",
      "saving 【train】【step:348】 loss : 2.428108\n",
      "saving 【train】【step:349】 loss : 2.42807\n",
      "saving 【train】【step:350】 loss : 2.428221\n",
      "saving 【train】【step:351】 loss : 2.428216\n",
      "saving 【train】【step:352】 loss : 2.428169\n",
      "saving 【train】【step:353】 loss : 2.428162\n",
      "saving 【train】【step:354】 loss : 2.428273\n",
      "saving 【train】【step:355】 loss : 2.428369\n",
      "saving 【train】【step:356】 loss : 2.428355\n",
      "saving 【train】【step:357】 loss : 2.428434\n",
      "saving 【train】【step:358】 loss : 2.428316\n",
      "saving 【train】【step:359】 loss : 2.42842\n",
      "saving 【train】【step:360】 loss : 2.428174\n",
      "saving 【train】【step:361】 loss : 2.428086\n",
      "saving 【train】【step:362】 loss : 2.427909\n",
      "saving 【train】【step:363】 loss : 2.427934\n",
      "saving 【train】【step:364】 loss : 2.427872\n",
      "saving 【train】【step:365】 loss : 2.427855\n",
      "saving 【train】【step:366】 loss : 2.427895\n",
      "saving 【train】【step:367】 loss : 2.427894\n",
      "saving 【train】【step:368】 loss : 2.427859\n",
      "saving 【train】【step:369】 loss : 2.427835\n",
      "saving 【train】【step:370】 loss : 2.427835\n",
      "saving 【train】【step:371】 loss : 2.427833\n",
      "saving 【train】【step:372】 loss : 2.427859\n",
      "saving 【train】【step:373】 loss : 2.427835\n",
      "saving 【train】【step:374】 loss : 2.427837\n",
      "saving 【train】【step:375】 loss : 2.427843\n",
      "saving 【train】【step:376】 loss : 2.427865\n",
      "saving 【train】【step:377】 loss : 2.427842\n",
      "saving 【train】【step:378】 loss : 2.427841\n",
      "saving 【train】【step:379】 loss : 2.427874\n",
      "saving 【train】【step:380】 loss : 2.42787\n",
      "saving 【train】【step:381】 loss : 2.427932\n",
      "saving 【train】【step:382】 loss : 2.427881\n",
      "saving 【train】【step:383】 loss : 2.427926\n",
      "saving 【train】【step:384】 loss : 2.427943\n",
      "saving 【train】【step:385】 loss : 2.427906\n",
      "saving 【train】【step:386】 loss : 2.42795\n",
      "saving 【train】【step:387】 loss : 2.427976\n",
      "saving 【train】【step:388】 loss : 2.427978\n",
      "saving 【train】【step:389】 loss : 2.428048\n",
      "saving 【train】【step:390】 loss : 2.42817\n",
      "saving 【train】【step:391】 loss : 2.428147\n",
      "saving 【train】【step:392】 loss : 2.428054\n",
      "saving 【train】【step:393】 loss : 2.428003\n",
      "saving 【train】【step:394】 loss : 2.428011\n",
      "saving 【train】【step:395】 loss : 2.428021\n",
      "saving 【train】【step:396】 loss : 2.427905\n",
      "saving 【train】【step:397】 loss : 2.427858\n",
      "saving 【train】【step:398】 loss : 2.427856\n",
      "saving 【train】【step:399】 loss : 2.427835\n",
      "saving 【train】【step:400】 loss : 2.427849\n",
      "saving 【train】【step:401】 loss : 2.427834\n",
      "saving 【train】【step:402】 loss : 2.427835\n",
      "saving 【train】【step:403】 loss : 2.427864\n",
      "saving 【train】【step:404】 loss : 2.427836\n",
      "saving 【train】【step:405】 loss : 2.42784\n",
      "saving 【train】【step:406】 loss : 2.427836\n",
      "saving 【train】【step:407】 loss : 2.427842\n",
      "saving 【train】【step:408】 loss : 2.427834\n",
      "saving 【train】【step:409】 loss : 2.427835\n",
      "saving 【train】【step:410】 loss : 2.427843\n",
      "saving 【train】【step:411】 loss : 2.427857\n",
      "saving 【train】【step:412】 loss : 2.427845\n",
      "saving 【train】【step:413】 loss : 2.427911\n",
      "saving 【train】【step:414】 loss : 2.428053\n",
      "saving 【train】【step:415】 loss : 2.428021\n",
      "saving 【train】【step:416】 loss : 2.427984\n",
      "saving 【train】【step:417】 loss : 2.427895\n",
      "saving 【train】【step:418】 loss : 2.427846\n",
      "saving 【train】【step:419】 loss : 2.427883\n",
      "saving 【train】【step:420】 loss : 2.427876\n",
      "saving 【train】【step:421】 loss : 2.427856\n",
      "saving 【train】【step:422】 loss : 2.427835\n",
      "saving 【train】【step:423】 loss : 2.427834\n",
      "saving 【train】【step:424】 loss : 2.427844\n",
      "saving 【train】【step:425】 loss : 2.427863\n",
      "saving 【train】【step:426】 loss : 2.427858\n",
      "saving 【train】【step:427】 loss : 2.427834\n",
      "saving 【train】【step:428】 loss : 2.427835\n",
      "saving 【train】【step:429】 loss : 2.427834\n",
      "saving 【train】【step:430】 loss : 2.427916\n",
      "saving 【train】【step:431】 loss : 2.427904\n",
      "saving 【train】【step:432】 loss : 2.427957\n",
      "saving 【train】【step:433】 loss : 2.427975\n",
      "saving 【train】【step:434】 loss : 2.427958\n",
      "saving 【train】【step:435】 loss : 2.427925\n",
      "saving 【train】【step:436】 loss : 2.427903\n",
      "saving 【train】【step:437】 loss : 2.428012\n",
      "saving 【train】【step:438】 loss : 2.427927\n",
      "saving 【train】【step:439】 loss : 2.427931\n",
      "saving 【train】【step:440】 loss : 2.427879\n",
      "saving 【train】【step:441】 loss : 2.427875\n",
      "saving 【train】【step:442】 loss : 2.427834\n",
      "saving 【train】【step:443】 loss : 2.427872\n",
      "saving 【train】【step:444】 loss : 2.427838\n",
      "saving 【train】【step:445】 loss : 2.427841\n",
      "saving 【train】【step:446】 loss : 2.427834\n",
      "saving 【train】【step:447】 loss : 2.427833\n",
      "saving 【train】【step:448】 loss : 2.427841\n",
      "saving 【train】【step:449】 loss : 2.427858\n",
      "saving 【train】【step:450】 loss : 2.42785\n",
      "saving 【train】【step:451】 loss : 2.427847\n",
      "saving 【train】【step:452】 loss : 2.427848\n",
      "saving 【train】【step:453】 loss : 2.427834\n",
      "saving 【train】【step:454】 loss : 2.427834\n",
      "saving 【train】【step:455】 loss : 2.427844\n",
      "saving 【train】【step:456】 loss : 2.427834\n",
      "saving 【train】【step:457】 loss : 2.427834\n",
      "saving 【train】【step:458】 loss : 2.427843\n",
      "saving 【train】【step:459】 loss : 2.427874\n",
      "saving 【train】【step:460】 loss : 2.427922\n",
      "saving 【train】【step:461】 loss : 2.428079\n",
      "saving 【train】【step:462】 loss : 2.428096\n",
      "saving 【train】【step:463】 loss : 2.42801\n",
      "saving 【train】【step:464】 loss : 2.427971\n",
      "saving 【train】【step:465】 loss : 2.427923\n",
      "saving 【train】【step:466】 loss : 2.427861\n",
      "saving 【train】【step:467】 loss : 2.427883\n",
      "saving 【train】【step:468】 loss : 2.427903\n",
      "saving 【train】【step:469】 loss : 2.427859\n",
      "saving 【train】【step:470】 loss : 2.427871\n",
      "saving 【train】【step:471】 loss : 2.427854\n",
      "saving 【train】【step:472】 loss : 2.427834\n",
      "saving 【train】【step:473】 loss : 2.427845\n",
      "saving 【train】【step:474】 loss : 2.427897\n",
      "saving 【train】【step:475】 loss : 2.427892\n",
      "saving 【train】【step:476】 loss : 2.427861\n",
      "saving 【train】【step:477】 loss : 2.427835\n",
      "saving 【train】【step:478】 loss : 2.427835\n",
      "saving 【train】【step:479】 loss : 2.427837\n",
      "saving 【train】【step:480】 loss : 2.427838\n",
      "saving 【train】【step:481】 loss : 2.427834\n",
      "saving 【train】【step:482】 loss : 2.427834\n",
      "saving 【train】【step:483】 loss : 2.427834\n",
      "saving 【train】【step:484】 loss : 2.427852\n",
      "saving 【train】【step:485】 loss : 2.427846\n",
      "saving 【train】【step:486】 loss : 2.427871\n",
      "saving 【train】【step:487】 loss : 2.427895\n",
      "saving 【train】【step:488】 loss : 2.427904\n",
      "saving 【train】【step:489】 loss : 2.427906\n",
      "saving 【train】【step:490】 loss : 2.427866\n",
      "saving 【train】【step:491】 loss : 2.427875\n",
      "saving 【train】【step:492】 loss : 2.427888\n",
      "saving 【train】【step:493】 loss : 2.427944\n",
      "saving 【train】【step:494】 loss : 2.427862\n",
      "saving 【train】【step:495】 loss : 2.427967\n",
      "saving 【train】【step:496】 loss : 2.42788\n",
      "saving 【train】【step:497】 loss : 2.427955\n",
      "saving 【train】【step:498】 loss : 2.428056\n",
      "saving 【train】【step:499】 loss : 2.428035\n",
      "saving 【train】【step:500】 loss : 2.428219\n",
      "saving 【train】【step:501】 loss : 2.42821\n",
      "saving 【train】【step:502】 loss : 2.428238\n",
      "saving 【train】【step:503】 loss : 2.428188\n",
      "saving 【train】【step:504】 loss : 2.428269\n",
      "saving 【train】【step:505】 loss : 2.428127\n",
      "saving 【train】【step:506】 loss : 2.4281\n",
      "saving 【train】【step:507】 loss : 2.428087\n",
      "saving 【train】【step:508】 loss : 2.428339\n",
      "saving 【train】【step:509】 loss : 2.428518\n",
      "saving 【train】【step:510】 loss : 2.428242\n",
      "saving 【train】【step:511】 loss : 2.42836\n",
      "saving 【train】【step:512】 loss : 2.428263\n",
      "saving 【train】【step:513】 loss : 2.428248\n",
      "saving 【train】【step:514】 loss : 2.428157\n",
      "saving 【train】【step:515】 loss : 2.428384\n",
      "saving 【train】【step:516】 loss : 2.428303\n",
      "saving 【train】【step:517】 loss : 2.428065\n",
      "saving 【train】【step:518】 loss : 2.427941\n",
      "saving 【train】【step:519】 loss : 2.427967\n",
      "saving 【train】【step:520】 loss : 2.428053\n",
      "saving 【train】【step:521】 loss : 2.42805\n",
      "saving 【train】【step:522】 loss : 2.428008\n",
      "saving 【train】【step:523】 loss : 2.427923\n",
      "saving 【train】【step:524】 loss : 2.427913\n",
      "saving 【train】【step:525】 loss : 2.427936\n",
      "saving 【train】【step:526】 loss : 2.427962\n",
      "saving 【train】【step:527】 loss : 2.428006\n",
      "saving 【train】【step:528】 loss : 2.427938\n",
      "saving 【train】【step:529】 loss : 2.428019\n",
      "saving 【train】【step:530】 loss : 2.427967\n",
      "saving 【train】【step:531】 loss : 2.427938\n",
      "saving 【train】【step:532】 loss : 2.427884\n",
      "saving 【train】【step:533】 loss : 2.427842\n",
      "saving 【train】【step:534】 loss : 2.427837\n",
      "saving 【train】【step:535】 loss : 2.427836\n",
      "saving 【train】【step:536】 loss : 2.42787\n",
      "saving 【train】【step:537】 loss : 2.42784\n",
      "saving 【train】【step:538】 loss : 2.42785\n",
      "saving 【train】【step:539】 loss : 2.427845\n",
      "saving 【train】【step:540】 loss : 2.427844\n",
      "saving 【train】【step:541】 loss : 2.427834\n",
      "saving 【train】【step:542】 loss : 2.427835\n",
      "saving 【train】【step:543】 loss : 2.427834\n",
      "saving 【train】【step:544】 loss : 2.427841\n",
      "saving 【train】【step:545】 loss : 2.427894\n",
      "saving 【train】【step:546】 loss : 2.427916\n",
      "saving 【train】【step:547】 loss : 2.42787\n",
      "saving 【train】【step:548】 loss : 2.427962\n",
      "saving 【train】【step:549】 loss : 2.427899\n",
      "saving 【train】【step:550】 loss : 2.427845\n",
      "saving 【train】【step:551】 loss : 2.427835\n",
      "saving 【train】【step:552】 loss : 2.427835\n",
      "saving 【train】【step:553】 loss : 2.427834\n",
      "saving 【train】【step:554】 loss : 2.427833\n",
      "saving 【train】【step:555】 loss : 2.427835\n",
      "saving 【train】【step:556】 loss : 2.42785\n",
      "saving 【train】【step:557】 loss : 2.427888\n",
      "saving 【train】【step:558】 loss : 2.427899\n",
      "saving 【train】【step:559】 loss : 2.427952\n",
      "saving 【train】【step:560】 loss : 2.427994\n",
      "saving 【train】【step:561】 loss : 2.428019\n",
      "saving 【train】【step:562】 loss : 2.428161\n",
      "saving 【train】【step:563】 loss : 2.42815\n",
      "saving 【train】【step:564】 loss : 2.428066\n",
      "saving 【train】【step:565】 loss : 2.428118\n",
      "saving 【train】【step:566】 loss : 2.42804\n",
      "saving 【train】【step:567】 loss : 2.427969\n",
      "saving 【train】【step:568】 loss : 2.427865\n",
      "saving 【train】【step:569】 loss : 2.427855\n",
      "saving 【train】【step:570】 loss : 2.427846\n",
      "saving 【train】【step:571】 loss : 2.427848\n",
      "saving 【train】【step:572】 loss : 2.427856\n",
      "saving 【train】【step:573】 loss : 2.427834\n",
      "saving 【train】【step:574】 loss : 2.42784\n",
      "saving 【train】【step:575】 loss : 2.427834\n",
      "saving 【train】【step:576】 loss : 2.427836\n",
      "saving 【train】【step:577】 loss : 2.427834\n",
      "saving 【train】【step:578】 loss : 2.427835\n",
      "saving 【train】【step:579】 loss : 2.427874\n",
      "saving 【train】【step:580】 loss : 2.427911\n",
      "saving 【train】【step:581】 loss : 2.427914\n",
      "saving 【train】【step:582】 loss : 2.427841\n",
      "saving 【train】【step:583】 loss : 2.427838\n",
      "saving 【train】【step:584】 loss : 2.427834\n",
      "saving 【train】【step:585】 loss : 2.427835\n",
      "saving 【train】【step:586】 loss : 2.427834\n",
      "saving 【train】【step:587】 loss : 2.427834\n",
      "saving 【train】【step:588】 loss : 2.42784\n",
      "saving 【train】【step:589】 loss : 2.427845\n",
      "saving 【train】【step:590】 loss : 2.427851\n",
      "saving 【train】【step:591】 loss : 2.427866\n",
      "saving 【train】【step:592】 loss : 2.427874\n",
      "saving 【train】【step:593】 loss : 2.42785\n",
      "saving 【train】【step:594】 loss : 2.427835\n",
      "saving 【train】【step:595】 loss : 2.427837\n",
      "saving 【train】【step:596】 loss : 2.427835\n",
      "saving 【train】【step:597】 loss : 2.427845\n",
      "saving 【train】【step:598】 loss : 2.427834\n",
      "saving 【train】【step:599】 loss : 2.42784\n",
      "saving 【train】【step:600】 loss : 2.427836\n",
      "saving 【train】【step:601】 loss : 2.427834\n",
      "saving 【train】【step:602】 loss : 2.427834\n",
      "saving 【train】【step:603】 loss : 2.427849\n",
      "saving 【train】【step:604】 loss : 2.427846\n",
      "saving 【train】【step:605】 loss : 2.42785\n",
      "saving 【train】【step:606】 loss : 2.427835\n",
      "saving 【train】【step:607】 loss : 2.42786\n",
      "saving 【train】【step:608】 loss : 2.427857\n",
      "saving 【train】【step:609】 loss : 2.427838\n",
      "saving 【train】【step:610】 loss : 2.427834\n",
      "saving 【train】【step:611】 loss : 2.427836\n",
      "saving 【train】【step:612】 loss : 2.427835\n",
      "saving 【train】【step:613】 loss : 2.427853\n",
      "saving 【train】【step:614】 loss : 2.42784\n",
      "saving 【train】【step:615】 loss : 2.427834\n",
      "saving 【train】【step:616】 loss : 2.427834\n",
      "saving 【train】【step:617】 loss : 2.427834\n",
      "saving 【train】【step:618】 loss : 2.427851\n",
      "saving 【train】【step:619】 loss : 2.427866\n",
      "saving 【train】【step:620】 loss : 2.427835\n",
      "saving 【train】【step:621】 loss : 2.427833\n",
      "saving 【train】【step:622】 loss : 2.427836\n",
      "saving 【train】【step:623】 loss : 2.427851\n",
      "saving 【train】【step:624】 loss : 2.427835\n",
      "saving 【train】【step:625】 loss : 2.427834\n",
      "saving 【train】【step:626】 loss : 2.42785\n",
      "saving 【train】【step:627】 loss : 2.427835\n",
      "saving 【train】【step:628】 loss : 2.427837\n",
      "saving 【train】【step:629】 loss : 2.427834\n",
      "saving 【train】【step:630】 loss : 2.427835\n",
      "saving 【train】【step:631】 loss : 2.427927\n",
      "saving 【train】【step:632】 loss : 2.427875\n",
      "saving 【train】【step:633】 loss : 2.427954\n",
      "saving 【train】【step:634】 loss : 2.428122\n",
      "saving 【train】【step:635】 loss : 2.428013\n",
      "saving 【train】【step:636】 loss : 2.428038\n",
      "saving 【train】【step:637】 loss : 2.427976\n",
      "saving 【train】【step:638】 loss : 2.428004\n",
      "saving 【train】【step:639】 loss : 2.427987\n",
      "saving 【train】【step:640】 loss : 2.428125\n",
      "saving 【train】【step:641】 loss : 2.428015\n",
      "saving 【train】【step:642】 loss : 2.428012\n",
      "saving 【train】【step:643】 loss : 2.428037\n",
      "saving 【train】【step:644】 loss : 2.427896\n",
      "saving 【train】【step:645】 loss : 2.427864\n",
      "saving 【train】【step:646】 loss : 2.427857\n",
      "saving 【train】【step:647】 loss : 2.427905\n",
      "saving 【train】【step:648】 loss : 2.427934\n",
      "saving 【train】【step:649】 loss : 2.427926\n",
      "saving 【train】【step:650】 loss : 2.427949\n",
      "saving 【train】【step:651】 loss : 2.427947\n",
      "saving 【train】【step:652】 loss : 2.428035\n",
      "saving 【train】【step:653】 loss : 2.428083\n",
      "saving 【train】【step:654】 loss : 2.427985\n",
      "saving 【train】【step:655】 loss : 2.427869\n",
      "saving 【train】【step:656】 loss : 2.427917\n",
      "saving 【train】【step:657】 loss : 2.427977\n",
      "saving 【train】【step:658】 loss : 2.427871\n",
      "saving 【train】【step:659】 loss : 2.427894\n",
      "saving 【train】【step:660】 loss : 2.427927\n",
      "saving 【train】【step:661】 loss : 2.427876\n",
      "saving 【train】【step:662】 loss : 2.427842\n",
      "saving 【train】【step:663】 loss : 2.427838\n",
      "saving 【train】【step:664】 loss : 2.427863\n",
      "saving 【train】【step:665】 loss : 2.427879\n",
      "saving 【train】【step:666】 loss : 2.427853\n",
      "saving 【train】【step:667】 loss : 2.427869\n",
      "saving 【train】【step:668】 loss : 2.427842\n",
      "saving 【train】【step:669】 loss : 2.427863\n",
      "saving 【train】【step:670】 loss : 2.427835\n",
      "saving 【train】【step:671】 loss : 2.427835\n",
      "saving 【train】【step:672】 loss : 2.427835\n",
      "saving 【train】【step:673】 loss : 2.42784\n",
      "saving 【train】【step:674】 loss : 2.427887\n",
      "saving 【train】【step:675】 loss : 2.427987\n",
      "saving 【train】【step:676】 loss : 2.427893\n",
      "saving 【train】【step:677】 loss : 2.427897\n",
      "saving 【train】【step:678】 loss : 2.427963\n",
      "saving 【train】【step:679】 loss : 2.428051\n",
      "saving 【train】【step:680】 loss : 2.427994\n",
      "saving 【train】【step:681】 loss : 2.42792\n",
      "saving 【train】【step:682】 loss : 2.427881\n",
      "saving 【train】【step:683】 loss : 2.427958\n",
      "saving 【train】【step:684】 loss : 2.427957\n",
      "saving 【train】【step:685】 loss : 2.427948\n",
      "saving 【train】【step:686】 loss : 2.427906\n",
      "saving 【train】【step:687】 loss : 2.427935\n",
      "saving 【train】【step:688】 loss : 2.427915\n",
      "saving 【train】【step:689】 loss : 2.428039\n",
      "saving 【train】【step:690】 loss : 2.428076\n",
      "saving 【train】【step:691】 loss : 2.428107\n",
      "saving 【train】【step:692】 loss : 2.427949\n",
      "saving 【train】【step:693】 loss : 2.42796\n",
      "saving 【train】【step:694】 loss : 2.42801\n",
      "saving 【train】【step:695】 loss : 2.427978\n",
      "saving 【train】【step:696】 loss : 2.427958\n",
      "saving 【train】【step:697】 loss : 2.428051\n",
      "saving 【train】【step:698】 loss : 2.428004\n",
      "saving 【train】【step:699】 loss : 2.428011\n"
     ]
    }
   ],
   "source": [
    "#保存训练集在训练过程中的loss值，用于绘制loss变化曲线图\n",
    "for i in range(0, xgb_num_rounds, 1):\n",
    "    base.save_norm_by_step(model_name='train', norm_name='loss',norm_value=np.float(evals_process['train'][\"rmse\"][i]),step=i)\n",
    "    #print(evals_process['train'][\"rmse\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#绘制验证集在训练过程中的loss曲线图\n",
    "epoch = []  # 横坐标,迭代次数\n",
    "for i in range(0, xgb_num_rounds, 1):\n",
    "    epoch.append(i)\n",
    "\n",
    "plt.plot(epoch, evals_process['test'][\"rmse\"])\n",
    "# plt.plot([1,3,3,4], [1,4,9,16])\n",
    "plt.ylabel('val rmse')\n",
    "plt.xlabel('val epoch')\n",
    "plt.title(\" Curve of loss(rmse) function of valing set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 【train】【step:0】 loss : 5.761348\n",
      "saving 【train】【step:1】 loss : 5.530096\n",
      "saving 【train】【step:2】 loss : 5.297737\n",
      "saving 【train】【step:3】 loss : 5.092144\n",
      "saving 【train】【step:4】 loss : 4.882916\n",
      "saving 【train】【step:5】 loss : 4.691939\n",
      "saving 【train】【step:6】 loss : 4.52261\n",
      "saving 【train】【step:7】 loss : 4.358354\n",
      "saving 【train】【step:8】 loss : 4.19636\n",
      "saving 【train】【step:9】 loss : 4.058988\n",
      "saving 【train】【step:10】 loss : 3.918642\n",
      "saving 【train】【step:11】 loss : 3.789748\n",
      "saving 【train】【step:12】 loss : 3.670927\n",
      "saving 【train】【step:13】 loss : 3.561275\n",
      "saving 【train】【step:14】 loss : 3.468027\n",
      "saving 【train】【step:15】 loss : 3.357108\n",
      "saving 【train】【step:16】 loss : 3.272471\n",
      "saving 【train】【step:17】 loss : 3.192646\n",
      "saving 【train】【step:18】 loss : 3.118322\n",
      "saving 【train】【step:19】 loss : 3.046772\n",
      "saving 【train】【step:20】 loss : 2.976\n",
      "saving 【train】【step:21】 loss : 2.909783\n",
      "saving 【train】【step:22】 loss : 2.851692\n",
      "saving 【train】【step:23】 loss : 2.791805\n",
      "saving 【train】【step:24】 loss : 2.7435\n",
      "saving 【train】【step:25】 loss : 2.701465\n",
      "saving 【train】【step:26】 loss : 2.656033\n",
      "saving 【train】【step:27】 loss : 2.616885\n",
      "saving 【train】【step:28】 loss : 2.587217\n",
      "saving 【train】【step:29】 loss : 2.55414\n",
      "saving 【train】【step:30】 loss : 2.516065\n",
      "saving 【train】【step:31】 loss : 2.487242\n",
      "saving 【train】【step:32】 loss : 2.46271\n",
      "saving 【train】【step:33】 loss : 2.438668\n",
      "saving 【train】【step:34】 loss : 2.418912\n",
      "saving 【train】【step:35】 loss : 2.396305\n",
      "saving 【train】【step:36】 loss : 2.374896\n",
      "saving 【train】【step:37】 loss : 2.355992\n",
      "saving 【train】【step:38】 loss : 2.342038\n",
      "saving 【train】【step:39】 loss : 2.334156\n",
      "saving 【train】【step:40】 loss : 2.318062\n",
      "saving 【train】【step:41】 loss : 2.307789\n",
      "saving 【train】【step:42】 loss : 2.297536\n",
      "saving 【train】【step:43】 loss : 2.288023\n",
      "saving 【train】【step:44】 loss : 2.280811\n",
      "saving 【train】【step:45】 loss : 2.273431\n",
      "saving 【train】【step:46】 loss : 2.260235\n",
      "saving 【train】【step:47】 loss : 2.251373\n",
      "saving 【train】【step:48】 loss : 2.247535\n",
      "saving 【train】【step:49】 loss : 2.239998\n",
      "saving 【train】【step:50】 loss : 2.234634\n",
      "saving 【train】【step:51】 loss : 2.229382\n",
      "saving 【train】【step:52】 loss : 2.224211\n",
      "saving 【train】【step:53】 loss : 2.219953\n",
      "saving 【train】【step:54】 loss : 2.213698\n",
      "saving 【train】【step:55】 loss : 2.212083\n",
      "saving 【train】【step:56】 loss : 2.209344\n",
      "saving 【train】【step:57】 loss : 2.204481\n",
      "saving 【train】【step:58】 loss : 2.201126\n",
      "saving 【train】【step:59】 loss : 2.198224\n",
      "saving 【train】【step:60】 loss : 2.194635\n",
      "saving 【train】【step:61】 loss : 2.193571\n",
      "saving 【train】【step:62】 loss : 2.192307\n",
      "saving 【train】【step:63】 loss : 2.190702\n",
      "saving 【train】【step:64】 loss : 2.189118\n",
      "saving 【train】【step:65】 loss : 2.187683\n",
      "saving 【train】【step:66】 loss : 2.183492\n",
      "saving 【train】【step:67】 loss : 2.181954\n",
      "saving 【train】【step:68】 loss : 2.180644\n",
      "saving 【train】【step:69】 loss : 2.177589\n",
      "saving 【train】【step:70】 loss : 2.177176\n",
      "saving 【train】【step:71】 loss : 2.176201\n",
      "saving 【train】【step:72】 loss : 2.175534\n",
      "saving 【train】【step:73】 loss : 2.173153\n",
      "saving 【train】【step:74】 loss : 2.169492\n",
      "saving 【train】【step:75】 loss : 2.168839\n",
      "saving 【train】【step:76】 loss : 2.168989\n",
      "saving 【train】【step:77】 loss : 2.168634\n",
      "saving 【train】【step:78】 loss : 2.168003\n",
      "saving 【train】【step:79】 loss : 2.167746\n",
      "saving 【train】【step:80】 loss : 2.167232\n",
      "saving 【train】【step:81】 loss : 2.167233\n",
      "saving 【train】【step:82】 loss : 2.167145\n",
      "saving 【train】【step:83】 loss : 2.166093\n",
      "saving 【train】【step:84】 loss : 2.16561\n",
      "saving 【train】【step:85】 loss : 2.16345\n",
      "saving 【train】【step:86】 loss : 2.161806\n",
      "saving 【train】【step:87】 loss : 2.161583\n",
      "saving 【train】【step:88】 loss : 2.161634\n",
      "saving 【train】【step:89】 loss : 2.162259\n",
      "saving 【train】【step:90】 loss : 2.162519\n",
      "saving 【train】【step:91】 loss : 2.161896\n",
      "saving 【train】【step:92】 loss : 2.161975\n",
      "saving 【train】【step:93】 loss : 2.161317\n",
      "saving 【train】【step:94】 loss : 2.160006\n",
      "saving 【train】【step:95】 loss : 2.160016\n",
      "saving 【train】【step:96】 loss : 2.160003\n",
      "saving 【train】【step:97】 loss : 2.159646\n",
      "saving 【train】【step:98】 loss : 2.159768\n",
      "saving 【train】【step:99】 loss : 2.159782\n",
      "saving 【train】【step:100】 loss : 2.159078\n",
      "saving 【train】【step:101】 loss : 2.158436\n",
      "saving 【train】【step:102】 loss : 2.157832\n",
      "saving 【train】【step:103】 loss : 2.157608\n",
      "saving 【train】【step:104】 loss : 2.157537\n",
      "saving 【train】【step:105】 loss : 2.157027\n",
      "saving 【train】【step:106】 loss : 2.15642\n",
      "saving 【train】【step:107】 loss : 2.156587\n",
      "saving 【train】【step:108】 loss : 2.15677\n",
      "saving 【train】【step:109】 loss : 2.156855\n",
      "saving 【train】【step:110】 loss : 2.156506\n",
      "saving 【train】【step:111】 loss : 2.155957\n",
      "saving 【train】【step:112】 loss : 2.156093\n",
      "saving 【train】【step:113】 loss : 2.156032\n",
      "saving 【train】【step:114】 loss : 2.156362\n",
      "saving 【train】【step:115】 loss : 2.156771\n",
      "saving 【train】【step:116】 loss : 2.157274\n",
      "saving 【train】【step:117】 loss : 2.15756\n",
      "saving 【train】【step:118】 loss : 2.157916\n",
      "saving 【train】【step:119】 loss : 2.159101\n",
      "saving 【train】【step:120】 loss : 2.159189\n",
      "saving 【train】【step:121】 loss : 2.159083\n",
      "saving 【train】【step:122】 loss : 2.15982\n",
      "saving 【train】【step:123】 loss : 2.159179\n",
      "saving 【train】【step:124】 loss : 2.157844\n",
      "saving 【train】【step:125】 loss : 2.158046\n",
      "saving 【train】【step:126】 loss : 2.158107\n",
      "saving 【train】【step:127】 loss : 2.158137\n",
      "saving 【train】【step:128】 loss : 2.158402\n",
      "saving 【train】【step:129】 loss : 2.157862\n",
      "saving 【train】【step:130】 loss : 2.158149\n",
      "saving 【train】【step:131】 loss : 2.158239\n",
      "saving 【train】【step:132】 loss : 2.15878\n",
      "saving 【train】【step:133】 loss : 2.158226\n",
      "saving 【train】【step:134】 loss : 2.157646\n",
      "saving 【train】【step:135】 loss : 2.157804\n",
      "saving 【train】【step:136】 loss : 2.158554\n",
      "saving 【train】【step:137】 loss : 2.158278\n",
      "saving 【train】【step:138】 loss : 2.158499\n",
      "saving 【train】【step:139】 loss : 2.158095\n",
      "saving 【train】【step:140】 loss : 2.158942\n",
      "saving 【train】【step:141】 loss : 2.159028\n",
      "saving 【train】【step:142】 loss : 2.158266\n",
      "saving 【train】【step:143】 loss : 2.157948\n",
      "saving 【train】【step:144】 loss : 2.157583\n",
      "saving 【train】【step:145】 loss : 2.157377\n",
      "saving 【train】【step:146】 loss : 2.157302\n",
      "saving 【train】【step:147】 loss : 2.157184\n",
      "saving 【train】【step:148】 loss : 2.156871\n",
      "saving 【train】【step:149】 loss : 2.15628\n",
      "saving 【train】【step:150】 loss : 2.155972\n",
      "saving 【train】【step:151】 loss : 2.155809\n",
      "saving 【train】【step:152】 loss : 2.156484\n",
      "saving 【train】【step:153】 loss : 2.156612\n",
      "saving 【train】【step:154】 loss : 2.156787\n",
      "saving 【train】【step:155】 loss : 2.156308\n",
      "saving 【train】【step:156】 loss : 2.156542\n",
      "saving 【train】【step:157】 loss : 2.156151\n",
      "saving 【train】【step:158】 loss : 2.156503\n",
      "saving 【train】【step:159】 loss : 2.156057\n",
      "saving 【train】【step:160】 loss : 2.156201\n",
      "saving 【train】【step:161】 loss : 2.156391\n",
      "saving 【train】【step:162】 loss : 2.156832\n",
      "saving 【train】【step:163】 loss : 2.155573\n",
      "saving 【train】【step:164】 loss : 2.156279\n",
      "saving 【train】【step:165】 loss : 2.156028\n",
      "saving 【train】【step:166】 loss : 2.155571\n",
      "saving 【train】【step:167】 loss : 2.155871\n",
      "saving 【train】【step:168】 loss : 2.155647\n",
      "saving 【train】【step:169】 loss : 2.155125\n",
      "saving 【train】【step:170】 loss : 2.153992\n",
      "saving 【train】【step:171】 loss : 2.15336\n",
      "saving 【train】【step:172】 loss : 2.153547\n",
      "saving 【train】【step:173】 loss : 2.154019\n",
      "saving 【train】【step:174】 loss : 2.153962\n",
      "saving 【train】【step:175】 loss : 2.153859\n",
      "saving 【train】【step:176】 loss : 2.15387\n",
      "saving 【train】【step:177】 loss : 2.153447\n",
      "saving 【train】【step:178】 loss : 2.153623\n",
      "saving 【train】【step:179】 loss : 2.153455\n",
      "saving 【train】【step:180】 loss : 2.154103\n",
      "saving 【train】【step:181】 loss : 2.154186\n",
      "saving 【train】【step:182】 loss : 2.15321\n",
      "saving 【train】【step:183】 loss : 2.153317\n",
      "saving 【train】【step:184】 loss : 2.153597\n",
      "saving 【train】【step:185】 loss : 2.154552\n",
      "saving 【train】【step:186】 loss : 2.154868\n",
      "saving 【train】【step:187】 loss : 2.155526\n",
      "saving 【train】【step:188】 loss : 2.155325\n",
      "saving 【train】【step:189】 loss : 2.154312\n",
      "saving 【train】【step:190】 loss : 2.15409\n",
      "saving 【train】【step:191】 loss : 2.154709\n",
      "saving 【train】【step:192】 loss : 2.154941\n",
      "saving 【train】【step:193】 loss : 2.155296\n",
      "saving 【train】【step:194】 loss : 2.155398\n",
      "saving 【train】【step:195】 loss : 2.155488\n",
      "saving 【train】【step:196】 loss : 2.155187\n",
      "saving 【train】【step:197】 loss : 2.155435\n",
      "saving 【train】【step:198】 loss : 2.155409\n",
      "saving 【train】【step:199】 loss : 2.155335\n",
      "saving 【train】【step:200】 loss : 2.155322\n",
      "saving 【train】【step:201】 loss : 2.155335\n",
      "saving 【train】【step:202】 loss : 2.154605\n",
      "saving 【train】【step:203】 loss : 2.154224\n",
      "saving 【train】【step:204】 loss : 2.154368\n",
      "saving 【train】【step:205】 loss : 2.154807\n",
      "saving 【train】【step:206】 loss : 2.155864\n",
      "saving 【train】【step:207】 loss : 2.154508\n",
      "saving 【train】【step:208】 loss : 2.154319\n",
      "saving 【train】【step:209】 loss : 2.153949\n",
      "saving 【train】【step:210】 loss : 2.153698\n",
      "saving 【train】【step:211】 loss : 2.154041\n",
      "saving 【train】【step:212】 loss : 2.154585\n",
      "saving 【train】【step:213】 loss : 2.154937\n",
      "saving 【train】【step:214】 loss : 2.155275\n",
      "saving 【train】【step:215】 loss : 2.155032\n",
      "saving 【train】【step:216】 loss : 2.155132\n",
      "saving 【train】【step:217】 loss : 2.15526\n",
      "saving 【train】【step:218】 loss : 2.155689\n",
      "saving 【train】【step:219】 loss : 2.156132\n",
      "saving 【train】【step:220】 loss : 2.155502\n",
      "saving 【train】【step:221】 loss : 2.156194\n",
      "saving 【train】【step:222】 loss : 2.156076\n",
      "saving 【train】【step:223】 loss : 2.15616\n",
      "saving 【train】【step:224】 loss : 2.156554\n",
      "saving 【train】【step:225】 loss : 2.156764\n",
      "saving 【train】【step:226】 loss : 2.157881\n",
      "saving 【train】【step:227】 loss : 2.15725\n",
      "saving 【train】【step:228】 loss : 2.157783\n",
      "saving 【train】【step:229】 loss : 2.156961\n",
      "saving 【train】【step:230】 loss : 2.157403\n",
      "saving 【train】【step:231】 loss : 2.157076\n",
      "saving 【train】【step:232】 loss : 2.156574\n",
      "saving 【train】【step:233】 loss : 2.156549\n",
      "saving 【train】【step:234】 loss : 2.156542\n",
      "saving 【train】【step:235】 loss : 2.155981\n",
      "saving 【train】【step:236】 loss : 2.156656\n",
      "saving 【train】【step:237】 loss : 2.156444\n",
      "saving 【train】【step:238】 loss : 2.156728\n",
      "saving 【train】【step:239】 loss : 2.15707\n",
      "saving 【train】【step:240】 loss : 2.156953\n",
      "saving 【train】【step:241】 loss : 2.156045\n",
      "saving 【train】【step:242】 loss : 2.155519\n",
      "saving 【train】【step:243】 loss : 2.155196\n",
      "saving 【train】【step:244】 loss : 2.155607\n",
      "saving 【train】【step:245】 loss : 2.155116\n",
      "saving 【train】【step:246】 loss : 2.155558\n",
      "saving 【train】【step:247】 loss : 2.156173\n",
      "saving 【train】【step:248】 loss : 2.156758\n",
      "saving 【train】【step:249】 loss : 2.156712\n",
      "saving 【train】【step:250】 loss : 2.157177\n",
      "saving 【train】【step:251】 loss : 2.156245\n",
      "saving 【train】【step:252】 loss : 2.156191\n",
      "saving 【train】【step:253】 loss : 2.155946\n",
      "saving 【train】【step:254】 loss : 2.15606\n",
      "saving 【train】【step:255】 loss : 2.154951\n",
      "saving 【train】【step:256】 loss : 2.155011\n",
      "saving 【train】【step:257】 loss : 2.155257\n",
      "saving 【train】【step:258】 loss : 2.154769\n",
      "saving 【train】【step:259】 loss : 2.155163\n",
      "saving 【train】【step:260】 loss : 2.155572\n",
      "saving 【train】【step:261】 loss : 2.155368\n",
      "saving 【train】【step:262】 loss : 2.154995\n",
      "saving 【train】【step:263】 loss : 2.155105\n",
      "saving 【train】【step:264】 loss : 2.154989\n",
      "saving 【train】【step:265】 loss : 2.155276\n",
      "saving 【train】【step:266】 loss : 2.155247\n",
      "saving 【train】【step:267】 loss : 2.154572\n",
      "saving 【train】【step:268】 loss : 2.154482\n",
      "saving 【train】【step:269】 loss : 2.154147\n",
      "saving 【train】【step:270】 loss : 2.153987\n",
      "saving 【train】【step:271】 loss : 2.153212\n",
      "saving 【train】【step:272】 loss : 2.15272\n",
      "saving 【train】【step:273】 loss : 2.153253\n",
      "saving 【train】【step:274】 loss : 2.153538\n",
      "saving 【train】【step:275】 loss : 2.153563\n",
      "saving 【train】【step:276】 loss : 2.153484\n",
      "saving 【train】【step:277】 loss : 2.15411\n",
      "saving 【train】【step:278】 loss : 2.15443\n",
      "saving 【train】【step:279】 loss : 2.154601\n",
      "saving 【train】【step:280】 loss : 2.154651\n",
      "saving 【train】【step:281】 loss : 2.154606\n",
      "saving 【train】【step:282】 loss : 2.154178\n",
      "saving 【train】【step:283】 loss : 2.1546\n",
      "saving 【train】【step:284】 loss : 2.154828\n",
      "saving 【train】【step:285】 loss : 2.153928\n",
      "saving 【train】【step:286】 loss : 2.154326\n",
      "saving 【train】【step:287】 loss : 2.154551\n",
      "saving 【train】【step:288】 loss : 2.155023\n",
      "saving 【train】【step:289】 loss : 2.154745\n",
      "saving 【train】【step:290】 loss : 2.155662\n",
      "saving 【train】【step:291】 loss : 2.156008\n",
      "saving 【train】【step:292】 loss : 2.155302\n",
      "saving 【train】【step:293】 loss : 2.154567\n",
      "saving 【train】【step:294】 loss : 2.154747\n",
      "saving 【train】【step:295】 loss : 2.154747\n",
      "saving 【train】【step:296】 loss : 2.154378\n",
      "saving 【train】【step:297】 loss : 2.15394\n",
      "saving 【train】【step:298】 loss : 2.154309\n",
      "saving 【train】【step:299】 loss : 2.154284\n",
      "saving 【train】【step:300】 loss : 2.15339\n",
      "saving 【train】【step:301】 loss : 2.153701\n",
      "saving 【train】【step:302】 loss : 2.153614\n",
      "saving 【train】【step:303】 loss : 2.153866\n",
      "saving 【train】【step:304】 loss : 2.153964\n",
      "saving 【train】【step:305】 loss : 2.153961\n",
      "saving 【train】【step:306】 loss : 2.153491\n",
      "saving 【train】【step:307】 loss : 2.153281\n",
      "saving 【train】【step:308】 loss : 2.154336\n",
      "saving 【train】【step:309】 loss : 2.154784\n",
      "saving 【train】【step:310】 loss : 2.154841\n",
      "saving 【train】【step:311】 loss : 2.155809\n",
      "saving 【train】【step:312】 loss : 2.155368\n",
      "saving 【train】【step:313】 loss : 2.155018\n",
      "saving 【train】【step:314】 loss : 2.155128\n",
      "saving 【train】【step:315】 loss : 2.155826\n",
      "saving 【train】【step:316】 loss : 2.156788\n",
      "saving 【train】【step:317】 loss : 2.157144\n",
      "saving 【train】【step:318】 loss : 2.158171\n",
      "saving 【train】【step:319】 loss : 2.157652\n",
      "saving 【train】【step:320】 loss : 2.157905\n",
      "saving 【train】【step:321】 loss : 2.158455\n",
      "saving 【train】【step:322】 loss : 2.159218\n",
      "saving 【train】【step:323】 loss : 2.160315\n",
      "saving 【train】【step:324】 loss : 2.160655\n",
      "saving 【train】【step:325】 loss : 2.160402\n",
      "saving 【train】【step:326】 loss : 2.160714\n",
      "saving 【train】【step:327】 loss : 2.160736\n",
      "saving 【train】【step:328】 loss : 2.160326\n",
      "saving 【train】【step:329】 loss : 2.160428\n",
      "saving 【train】【step:330】 loss : 2.16126\n",
      "saving 【train】【step:331】 loss : 2.161996\n",
      "saving 【train】【step:332】 loss : 2.160781\n",
      "saving 【train】【step:333】 loss : 2.161112\n",
      "saving 【train】【step:334】 loss : 2.161666\n",
      "saving 【train】【step:335】 loss : 2.16026\n",
      "saving 【train】【step:336】 loss : 2.160663\n",
      "saving 【train】【step:337】 loss : 2.16083\n",
      "saving 【train】【step:338】 loss : 2.160946\n",
      "saving 【train】【step:339】 loss : 2.160753\n",
      "saving 【train】【step:340】 loss : 2.160979\n",
      "saving 【train】【step:341】 loss : 2.16103\n",
      "saving 【train】【step:342】 loss : 2.161945\n",
      "saving 【train】【step:343】 loss : 2.16104\n",
      "saving 【train】【step:344】 loss : 2.160847\n",
      "saving 【train】【step:345】 loss : 2.160753\n",
      "saving 【train】【step:346】 loss : 2.161288\n",
      "saving 【train】【step:347】 loss : 2.159982\n",
      "saving 【train】【step:348】 loss : 2.160437\n",
      "saving 【train】【step:349】 loss : 2.160174\n",
      "saving 【train】【step:350】 loss : 2.161135\n",
      "saving 【train】【step:351】 loss : 2.161106\n",
      "saving 【train】【step:352】 loss : 2.16083\n",
      "saving 【train】【step:353】 loss : 2.160783\n",
      "saving 【train】【step:354】 loss : 2.161432\n",
      "saving 【train】【step:355】 loss : 2.161936\n",
      "saving 【train】【step:356】 loss : 2.161868\n",
      "saving 【train】【step:357】 loss : 2.162262\n",
      "saving 【train】【step:358】 loss : 2.161665\n",
      "saving 【train】【step:359】 loss : 2.162194\n",
      "saving 【train】【step:360】 loss : 2.160862\n",
      "saving 【train】【step:361】 loss : 2.160287\n",
      "saving 【train】【step:362】 loss : 2.158763\n",
      "saving 【train】【step:363】 loss : 2.159042\n",
      "saving 【train】【step:364】 loss : 2.158276\n",
      "saving 【train】【step:365】 loss : 2.157956\n",
      "saving 【train】【step:366】 loss : 2.1586\n",
      "saving 【train】【step:367】 loss : 2.158587\n",
      "saving 【train】【step:368】 loss : 2.158042\n",
      "saving 【train】【step:369】 loss : 2.156852\n",
      "saving 【train】【step:370】 loss : 2.156812\n",
      "saving 【train】【step:371】 loss : 2.157102\n",
      "saving 【train】【step:372】 loss : 2.158034\n",
      "saving 【train】【step:373】 loss : 2.157322\n",
      "saving 【train】【step:374】 loss : 2.157415\n",
      "saving 【train】【step:375】 loss : 2.156531\n",
      "saving 【train】【step:376】 loss : 2.156079\n",
      "saving 【train】【step:377】 loss : 2.15655\n",
      "saving 【train】【step:378】 loss : 2.156593\n",
      "saving 【train】【step:379】 loss : 2.155948\n",
      "saving 【train】【step:380】 loss : 2.156009\n",
      "saving 【train】【step:381】 loss : 2.155361\n",
      "saving 【train】【step:382】 loss : 2.155868\n",
      "saving 【train】【step:383】 loss : 2.155408\n",
      "saving 【train】【step:384】 loss : 2.155271\n",
      "saving 【train】【step:385】 loss : 2.155595\n",
      "saving 【train】【step:386】 loss : 2.155223\n",
      "saving 【train】【step:387】 loss : 2.155041\n",
      "saving 【train】【step:388】 loss : 2.15503\n",
      "saving 【train】【step:389】 loss : 2.154621\n",
      "saving 【train】【step:390】 loss : 2.154076\n",
      "saving 【train】【step:391】 loss : 2.154169\n",
      "saving 【train】【step:392】 loss : 2.154591\n",
      "saving 【train】【step:393】 loss : 2.154874\n",
      "saving 【train】【step:394】 loss : 2.154821\n",
      "saving 【train】【step:395】 loss : 2.154768\n",
      "saving 【train】【step:396】 loss : 2.155599\n",
      "saving 【train】【step:397】 loss : 2.156185\n",
      "saving 【train】【step:398】 loss : 2.156223\n",
      "saving 【train】【step:399】 loss : 2.156855\n",
      "saving 【train】【step:400】 loss : 2.156377\n",
      "saving 【train】【step:401】 loss : 2.157022\n",
      "saving 【train】【step:402】 loss : 2.157266\n",
      "saving 【train】【step:403】 loss : 2.158127\n",
      "saving 【train】【step:404】 loss : 2.157396\n",
      "saving 【train】【step:405】 loss : 2.157575\n",
      "saving 【train】【step:406】 loss : 2.15736\n",
      "saving 【train】【step:407】 loss : 2.156539\n",
      "saving 【train】【step:408】 loss : 2.157231\n",
      "saving 【train】【step:409】 loss : 2.157308\n",
      "saving 【train】【step:410】 loss : 2.157663\n",
      "saving 【train】【step:411】 loss : 2.157995\n",
      "saving 【train】【step:412】 loss : 2.156465\n",
      "saving 【train】【step:413】 loss : 2.155541\n",
      "saving 【train】【step:414】 loss : 2.154598\n",
      "saving 【train】【step:415】 loss : 2.154768\n",
      "saving 【train】【step:416】 loss : 2.154986\n",
      "saving 【train】【step:417】 loss : 2.155702\n",
      "saving 【train】【step:418】 loss : 2.156439\n",
      "saving 【train】【step:419】 loss : 2.155836\n",
      "saving 【train】【step:420】 loss : 2.155921\n",
      "saving 【train】【step:421】 loss : 2.156227\n",
      "saving 【train】【step:422】 loss : 2.157331\n",
      "saving 【train】【step:423】 loss : 2.157009\n",
      "saving 【train】【step:424】 loss : 2.157695\n",
      "saving 【train】【step:425】 loss : 2.158115\n",
      "saving 【train】【step:426】 loss : 2.158026\n",
      "saving 【train】【step:427】 loss : 2.15713\n",
      "saving 【train】【step:428】 loss : 2.156821\n",
      "saving 【train】【step:429】 loss : 2.157161\n",
      "saving 【train】【step:430】 loss : 2.155503\n",
      "saving 【train】【step:431】 loss : 2.155611\n",
      "saving 【train】【step:432】 loss : 2.155173\n",
      "saving 【train】【step:433】 loss : 2.155048\n",
      "saving 【train】【step:434】 loss : 2.155165\n",
      "saving 【train】【step:435】 loss : 2.15542\n",
      "saving 【train】【step:436】 loss : 2.155617\n",
      "saving 【train】【step:437】 loss : 2.154821\n",
      "saving 【train】【step:438】 loss : 2.155399\n",
      "saving 【train】【step:439】 loss : 2.155372\n",
      "saving 【train】【step:440】 loss : 2.155888\n",
      "saving 【train】【step:441】 loss : 2.155943\n",
      "saving 【train】【step:442】 loss : 2.157161\n",
      "saving 【train】【step:443】 loss : 2.155982\n",
      "saving 【train】【step:444】 loss : 2.156703\n",
      "saving 【train】【step:445】 loss : 2.157611\n",
      "saving 【train】【step:446】 loss : 2.157007\n",
      "saving 【train】【step:447】 loss : 2.157087\n",
      "saving 【train】【step:448】 loss : 2.156594\n",
      "saving 【train】【step:449】 loss : 2.156196\n",
      "saving 【train】【step:450】 loss : 2.156359\n",
      "saving 【train】【step:451】 loss : 2.156411\n",
      "saving 【train】【step:452】 loss : 2.156398\n",
      "saving 【train】【step:453】 loss : 2.157072\n",
      "saving 【train】【step:454】 loss : 2.156894\n",
      "saving 【train】【step:455】 loss : 2.157698\n",
      "saving 【train】【step:456】 loss : 2.157155\n",
      "saving 【train】【step:457】 loss : 2.156962\n",
      "saving 【train】【step:458】 loss : 2.156532\n",
      "saving 【train】【step:459】 loss : 2.155955\n",
      "saving 【train】【step:460】 loss : 2.155446\n",
      "saving 【train】【step:461】 loss : 2.15447\n",
      "saving 【train】【step:462】 loss : 2.15439\n",
      "saving 【train】【step:463】 loss : 2.154829\n",
      "saving 【train】【step:464】 loss : 2.155074\n",
      "saving 【train】【step:465】 loss : 2.155441\n",
      "saving 【train】【step:466】 loss : 2.156144\n",
      "saving 【train】【step:467】 loss : 2.15584\n",
      "saving 【train】【step:468】 loss : 2.155618\n",
      "saving 【train】【step:469】 loss : 2.156184\n",
      "saving 【train】【step:470】 loss : 2.155997\n",
      "saving 【train】【step:471】 loss : 2.156264\n",
      "saving 【train】【step:472】 loss : 2.157203\n",
      "saving 【train】【step:473】 loss : 2.157711\n",
      "saving 【train】【step:474】 loss : 2.158625\n",
      "saving 【train】【step:475】 loss : 2.15856\n",
      "saving 【train】【step:476】 loss : 2.158078\n",
      "saving 【train】【step:477】 loss : 2.15733\n",
      "saving 【train】【step:478】 loss : 2.156813\n",
      "saving 【train】【step:479】 loss : 2.156719\n",
      "saving 【train】【step:480】 loss : 2.156691\n",
      "saving 【train】【step:481】 loss : 2.156967\n",
      "saving 【train】【step:482】 loss : 2.157021\n",
      "saving 【train】【step:483】 loss : 2.156915\n",
      "saving 【train】【step:484】 loss : 2.157901\n",
      "saving 【train】【step:485】 loss : 2.156437\n",
      "saving 【train】【step:486】 loss : 2.156\n",
      "saving 【train】【step:487】 loss : 2.155709\n",
      "saving 【train】【step:488】 loss : 2.155612\n",
      "saving 【train】【step:489】 loss : 2.155594\n",
      "saving 【train】【step:490】 loss : 2.15606\n",
      "saving 【train】【step:491】 loss : 2.155944\n",
      "saving 【train】【step:492】 loss : 2.155779\n",
      "saving 【train】【step:493】 loss : 2.155268\n",
      "saving 【train】【step:494】 loss : 2.15613\n",
      "saving 【train】【step:495】 loss : 2.155098\n",
      "saving 【train】【step:496】 loss : 2.155875\n",
      "saving 【train】【step:497】 loss : 2.155183\n",
      "saving 【train】【step:498】 loss : 2.154581\n",
      "saving 【train】【step:499】 loss : 2.154691\n",
      "saving 【train】【step:500】 loss : 2.153895\n",
      "saving 【train】【step:501】 loss : 2.153929\n",
      "saving 【train】【step:502】 loss : 2.153828\n",
      "saving 【train】【step:503】 loss : 2.154008\n",
      "saving 【train】【step:504】 loss : 2.153723\n",
      "saving 【train】【step:505】 loss : 2.154253\n",
      "saving 【train】【step:506】 loss : 2.154372\n",
      "saving 【train】【step:507】 loss : 2.154429\n",
      "saving 【train】【step:508】 loss : 2.153503\n",
      "saving 【train】【step:509】 loss : 2.153029\n",
      "saving 【train】【step:510】 loss : 2.153813\n",
      "saving 【train】【step:511】 loss : 2.153445\n",
      "saving 【train】【step:512】 loss : 2.153743\n",
      "saving 【train】【step:513】 loss : 2.153793\n",
      "saving 【train】【step:514】 loss : 2.154128\n",
      "saving 【train】【step:515】 loss : 2.153376\n",
      "saving 【train】【step:516】 loss : 2.153614\n",
      "saving 【train】【step:517】 loss : 2.154536\n",
      "saving 【train】【step:518】 loss : 2.155288\n",
      "saving 【train】【step:519】 loss : 2.155102\n",
      "saving 【train】【step:520】 loss : 2.154597\n",
      "saving 【train】【step:521】 loss : 2.154613\n",
      "saving 【train】【step:522】 loss : 2.154841\n",
      "saving 【train】【step:523】 loss : 2.155437\n",
      "saving 【train】【step:524】 loss : 2.155529\n",
      "saving 【train】【step:525】 loss : 2.155327\n",
      "saving 【train】【step:526】 loss : 2.155139\n",
      "saving 【train】【step:527】 loss : 2.154852\n",
      "saving 【train】【step:528】 loss : 2.155313\n",
      "saving 【train】【step:529】 loss : 2.154781\n",
      "saving 【train】【step:530】 loss : 2.155099\n",
      "saving 【train】【step:531】 loss : 2.155313\n",
      "saving 【train】【step:532】 loss : 2.155824\n",
      "saving 【train】【step:533】 loss : 2.156546\n",
      "saving 【train】【step:534】 loss : 2.156731\n",
      "saving 【train】【step:535】 loss : 2.156801\n",
      "saving 【train】【step:536】 loss : 2.156014\n",
      "saving 【train】【step:537】 loss : 2.156609\n",
      "saving 【train】【step:538】 loss : 2.157836\n",
      "saving 【train】【step:539】 loss : 2.157714\n",
      "saving 【train】【step:540】 loss : 2.156495\n",
      "saving 【train】【step:541】 loss : 2.157184\n",
      "saving 【train】【step:542】 loss : 2.157329\n",
      "saving 【train】【step:543】 loss : 2.157072\n",
      "saving 【train】【step:544】 loss : 2.156579\n",
      "saving 【train】【step:545】 loss : 2.155712\n",
      "saving 【train】【step:546】 loss : 2.155499\n",
      "saving 【train】【step:547】 loss : 2.156005\n",
      "saving 【train】【step:548】 loss : 2.155136\n",
      "saving 【train】【step:549】 loss : 2.155659\n",
      "saving 【train】【step:550】 loss : 2.156456\n",
      "saving 【train】【step:551】 loss : 2.156806\n",
      "saving 【train】【step:552】 loss : 2.156853\n",
      "saving 【train】【step:553】 loss : 2.15694\n",
      "saving 【train】【step:554】 loss : 2.157102\n",
      "saving 【train】【step:555】 loss : 2.15734\n",
      "saving 【train】【step:556】 loss : 2.157847\n",
      "saving 【train】【step:557】 loss : 2.158498\n",
      "saving 【train】【step:558】 loss : 2.158641\n",
      "saving 【train】【step:559】 loss : 2.159219\n",
      "saving 【train】【step:560】 loss : 2.159596\n",
      "saving 【train】【step:561】 loss : 2.159797\n",
      "saving 【train】【step:562】 loss : 2.160777\n",
      "saving 【train】【step:563】 loss : 2.160711\n",
      "saving 【train】【step:564】 loss : 2.160147\n",
      "saving 【train】【step:565】 loss : 2.160507\n",
      "saving 【train】【step:566】 loss : 2.159957\n",
      "saving 【train】【step:567】 loss : 2.159375\n",
      "saving 【train】【step:568】 loss : 2.158149\n",
      "saving 【train】【step:569】 loss : 2.157957\n",
      "saving 【train】【step:570】 loss : 2.157756\n",
      "saving 【train】【step:571】 loss : 2.15779\n",
      "saving 【train】【step:572】 loss : 2.157988\n",
      "saving 【train】【step:573】 loss : 2.157245\n",
      "saving 【train】【step:574】 loss : 2.157558\n",
      "saving 【train】【step:575】 loss : 2.15722\n",
      "saving 【train】【step:576】 loss : 2.157391\n",
      "saving 【train】【step:577】 loss : 2.15713\n",
      "saving 【train】【step:578】 loss : 2.15688\n",
      "saving 【train】【step:579】 loss : 2.155952\n",
      "saving 【train】【step:580】 loss : 2.155541\n",
      "saving 【train】【step:581】 loss : 2.155518\n",
      "saving 【train】【step:582】 loss : 2.156579\n",
      "saving 【train】【step:583】 loss : 2.157486\n",
      "saving 【train】【step:584】 loss : 2.157213\n",
      "saving 【train】【step:585】 loss : 2.157305\n",
      "saving 【train】【step:586】 loss : 2.157047\n",
      "saving 【train】【step:587】 loss : 2.157255\n",
      "saving 【train】【step:588】 loss : 2.156618\n",
      "saving 【train】【step:589】 loss : 2.156465\n",
      "saving 【train】【step:590】 loss : 2.156325\n",
      "saving 【train】【step:591】 loss : 2.15607\n",
      "saving 【train】【step:592】 loss : 2.155955\n",
      "saving 【train】【step:593】 loss : 2.156341\n",
      "saving 【train】【step:594】 loss : 2.15682\n",
      "saving 【train】【step:595】 loss : 2.156716\n",
      "saving 【train】【step:596】 loss : 2.156893\n",
      "saving 【train】【step:597】 loss : 2.156474\n",
      "saving 【train】【step:598】 loss : 2.157159\n",
      "saving 【train】【step:599】 loss : 2.156611\n",
      "saving 【train】【step:600】 loss : 2.156799\n",
      "saving 【train】【step:601】 loss : 2.156952\n",
      "saving 【train】【step:602】 loss : 2.157148\n",
      "saving 【train】【step:603】 loss : 2.157817\n",
      "saving 【train】【step:604】 loss : 2.157759\n",
      "saving 【train】【step:605】 loss : 2.157852\n",
      "saving 【train】【step:606】 loss : 2.156842\n",
      "saving 【train】【step:607】 loss : 2.156163\n",
      "saving 【train】【step:608】 loss : 2.156205\n",
      "saving 【train】【step:609】 loss : 2.156711\n",
      "saving 【train】【step:610】 loss : 2.15724\n",
      "saving 【train】【step:611】 loss : 2.15675\n",
      "saving 【train】【step:612】 loss : 2.156867\n",
      "saving 【train】【step:613】 loss : 2.156296\n",
      "saving 【train】【step:614】 loss : 2.15663\n",
      "saving 【train】【step:615】 loss : 2.157053\n",
      "saving 【train】【step:616】 loss : 2.15702\n",
      "saving 【train】【step:617】 loss : 2.157109\n",
      "saving 【train】【step:618】 loss : 2.156323\n",
      "saving 【train】【step:619】 loss : 2.156069\n",
      "saving 【train】【step:620】 loss : 2.156823\n",
      "saving 【train】【step:621】 loss : 2.157086\n",
      "saving 【train】【step:622】 loss : 2.157397\n",
      "saving 【train】【step:623】 loss : 2.157877\n",
      "saving 【train】【step:624】 loss : 2.157325\n",
      "saving 【train】【step:625】 loss : 2.157253\n",
      "saving 【train】【step:626】 loss : 2.156356\n",
      "saving 【train】【step:627】 loss : 2.157343\n",
      "saving 【train】【step:628】 loss : 2.157461\n",
      "saving 【train】【step:629】 loss : 2.156931\n",
      "saving 【train】【step:630】 loss : 2.157337\n",
      "saving 【train】【step:631】 loss : 2.158959\n",
      "saving 【train】【step:632】 loss : 2.158316\n",
      "saving 【train】【step:633】 loss : 2.159242\n",
      "saving 【train】【step:634】 loss : 2.160527\n",
      "saving 【train】【step:635】 loss : 2.159748\n",
      "saving 【train】【step:636】 loss : 2.159942\n",
      "saving 【train】【step:637】 loss : 2.159434\n",
      "saving 【train】【step:638】 loss : 2.159672\n",
      "saving 【train】【step:639】 loss : 2.159534\n",
      "saving 【train】【step:640】 loss : 2.160553\n",
      "saving 【train】【step:641】 loss : 2.159761\n",
      "saving 【train】【step:642】 loss : 2.159739\n",
      "saving 【train】【step:643】 loss : 2.159934\n",
      "saving 【train】【step:644】 loss : 2.15861\n",
      "saving 【train】【step:645】 loss : 2.158131\n",
      "saving 【train】【step:646】 loss : 2.158006\n",
      "saving 【train】【step:647】 loss : 2.158718\n",
      "saving 【train】【step:648】 loss : 2.159041\n",
      "saving 【train】【step:649】 loss : 2.158959\n",
      "saving 【train】【step:650】 loss : 2.159185\n",
      "saving 【train】【step:651】 loss : 2.159169\n",
      "saving 【train】【step:652】 loss : 2.159925\n",
      "saving 【train】【step:653】 loss : 2.16027\n",
      "saving 【train】【step:654】 loss : 2.159515\n",
      "saving 【train】【step:655】 loss : 2.158212\n",
      "saving 【train】【step:656】 loss : 2.158853\n",
      "saving 【train】【step:657】 loss : 2.159443\n",
      "saving 【train】【step:658】 loss : 2.158256\n",
      "saving 【train】【step:659】 loss : 2.15858\n",
      "saving 【train】【step:660】 loss : 2.158973\n",
      "saving 【train】【step:661】 loss : 2.158337\n",
      "saving 【train】【step:662】 loss : 2.157638\n",
      "saving 【train】【step:663】 loss : 2.157482\n",
      "saving 【train】【step:664】 loss : 2.158117\n",
      "saving 【train】【step:665】 loss : 2.158374\n",
      "saving 【train】【step:666】 loss : 2.157913\n",
      "saving 【train】【step:667】 loss : 2.158211\n",
      "saving 【train】【step:668】 loss : 2.157637\n",
      "saving 【train】【step:669】 loss : 2.158108\n",
      "saving 【train】【step:670】 loss : 2.157335\n",
      "saving 【train】【step:671】 loss : 2.15732\n",
      "saving 【train】【step:672】 loss : 2.157302\n",
      "saving 【train】【step:673】 loss : 2.157558\n",
      "saving 【train】【step:674】 loss : 2.15849\n",
      "saving 【train】【step:675】 loss : 2.159536\n",
      "saving 【train】【step:676】 loss : 2.158566\n",
      "saving 【train】【step:677】 loss : 2.158623\n",
      "saving 【train】【step:678】 loss : 2.159327\n",
      "saving 【train】【step:679】 loss : 2.160041\n",
      "saving 【train】【step:680】 loss : 2.159595\n",
      "saving 【train】【step:681】 loss : 2.158894\n",
      "saving 【train】【step:682】 loss : 2.158398\n",
      "saving 【train】【step:683】 loss : 2.159271\n",
      "saving 【train】【step:684】 loss : 2.159265\n",
      "saving 【train】【step:685】 loss : 2.159184\n",
      "saving 【train】【step:686】 loss : 2.15873\n",
      "saving 【train】【step:687】 loss : 2.159053\n",
      "saving 【train】【step:688】 loss : 2.158832\n",
      "saving 【train】【step:689】 loss : 2.159952\n",
      "saving 【train】【step:690】 loss : 2.16022\n",
      "saving 【train】【step:691】 loss : 2.160432\n",
      "saving 【train】【step:692】 loss : 2.159191\n",
      "saving 【train】【step:693】 loss : 2.159294\n",
      "saving 【train】【step:694】 loss : 2.159722\n",
      "saving 【train】【step:695】 loss : 2.159453\n",
      "saving 【train】【step:696】 loss : 2.159271\n",
      "saving 【train】【step:697】 loss : 2.160039\n",
      "saving 【train】【step:698】 loss : 2.159672\n",
      "saving 【train】【step:699】 loss : 2.159731\n"
     ]
    }
   ],
   "source": [
    "#全量数据保存\n",
    "#保存测试集集在训练过程中的loss值，用于绘制loss变化曲线图\n",
    "for i in range(0, xgb_num_rounds, 1):\n",
    "    base.save_norm_by_step(model_name='validation', norm_name='loss',norm_value=np.float(evals_process['test'][\"rmse\"][i]),step=i)\n",
    "    #print(evals_process['test'][\"rmse\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train kappa score is: 0.0\n",
      "Train accuracy score is: 0.15\n",
      "Test kappa score is: 0.0\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(xgtrain, ntree_limit=model.best_iteration)\n",
    "print('Train kappa score is:', eval_wrapper(train_preds, train['response']))\n",
    "print('Train accuracy score is:', acc(train[\"response\"], train_preds))\n",
    "\n",
    "test_preds = model.predict(xgtest, ntree_limit=model.best_iteration)\n",
    "print('Test kappa score is:', eval_wrapper( test_preds, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全量数据指标保存\n",
    "#base.save_norm(model_name='xgbregression', norm_name='auc',norm_value=np.float(acc(train[\"response\"], train_preds)), operate_type='train')   \n",
    "#base.save_norm(model_name='xgbregression', norm_name='Quadratic_Weighted_Kappa',norm_value=np.float(eval_wrapper(train_preds, train['response'])), operate_type='train')              \n",
    "#base.save_norm(model_name='xgbregression', norm_name='Quadratic_Weighted_Kappa',norm_value=np.float(eval_wrapper( test_preds, test_label)), operate_type='test')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 13\n"
     ]
    }
   ],
   "source": [
    "train_preds = np.clip(train_preds, -0.99, 8.99)\n",
    "test_preds = np.clip(test_preds, -0.99, 8.99)\n",
    "\n",
    "# 设置偏移量，并使用fmin_powell寻找最佳值\n",
    "offsets = np.ones(num_classes) * -0.3\n",
    "offset_train_preds = np.vstack((train_preds, train_preds, train['response'].values))\n",
    "for j in range(num_classes):\n",
    "    train_offset = lambda x: -apply_offset(offset_train_preds, x, j)\n",
    "    #def train_offset(x):\n",
    "    #   -apply_offset(offset_train_preds, x, j)\n",
    "    offsets[j] = fmin_powell(train_offset, offsets[j])  \n",
    "\n",
    "# 将在训练集上的偏移量应用在测试集上\n",
    "data = np.vstack((test_preds, test_preds, test['response'].values))\n",
    "for j in range(num_classes):\n",
    "    data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j] \n",
    "\n",
    "final_test_preds = np.round(np.clip(data[1], 1, 8)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 【test】 Quadratic_Weighted_Kappa : 1e-05\n"
     ]
    }
   ],
   "source": [
    "base.save_norm(model_name='model1', norm_name='Quadratic_Weighted_Kappa',norm_value=np.float(eval_wrapper( final_test_preds, test_label))+0.00001, operate_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前环境 [调试环境] 禁止上传到oss 文件系统 \n",
      "当前环境 [调试环境] 禁止上传到oss 文件系统 \n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "# 保存 offset 数组\n",
    "pickle.dump(offsets, open(\"final_offset.list\", \"wb\"))\n",
    "# 保存 xgboost 模型\n",
    "pickle.dump(model, open(\"xgboost.model\", \"wb\"))\n",
    "\n",
    "# 将 offset 数组上传至 oss \n",
    "wfio.upload_to_oss(\"final_offset.list\", \"./final_offset.list\")\n",
    "# 将 xgboost 模型上传至 oss \n",
    "wfio.upload_to_oss(\"xgboost.model\", \"./xgboost.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}