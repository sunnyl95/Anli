{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# 输入数据的参数\n",
    "_INPUT1='{\"name\":\"input1\",\"type\":0,\"uri\":\"tmp_35196d820e8643b6a20a45dfd3d48005\"}'\n",
    "_INPUT4='{\"name\":\"input4\",\"type\":0,\"uri\":\"tmp_04bab065ee8044d291c5c1a66593516c\"}'\n",
    "_INPUT2='{\"name\":\"input2\",\"type\":0,\"uri\":\"tmp_7b3070b338b74dd4a4aa623192757469\"}'\n",
    "_INPUT3='{\"name\":\"input3\",\"type\":0,\"uri\":\"tmp_778cef1c9c0f4698844a0a092020266d\"}'\n",
    "\n",
    "# 输出数据的参数\n",
    "_OUTPUT='[{\"name\":\"output1\",\"type\":0,\"uri\":\"tmp_60e209e947a441cd987ba904458a5fb3\"},{\"name\":\"output2\",\"type\":0,\"uri\":\"tmp_ca98f25ba95c438eb692abc2c9892db3\"},{\"name\":\"output3\",\"type\":0,\"uri\":\"tmp_b1ed163f4cf8491dbe195aefcf5eee8c\"},{\"name\":\"output4\",\"type\":0,\"uri\":\"tmp_a1eae39ea2824958b509d6687c0318e3\"}]'\n",
    "\n",
    "# 自定义参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: logitboost in /opt/conda/lib/python3.7/site-packages (0.7)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from logitboost) (1.16.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from logitboost) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from logitboost) (0.21.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->logitboost) (0.13.2)\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (0.90)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.16.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost) (1.3.0)\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.16.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.33.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.20.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.1.8)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.1)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.25.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install logitboost\n",
    "!pip install xgboost\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入使用库\n",
    "import pandas as pd\n",
    "# from ustciscrLab_A import get_score\n",
    "from ustciscrBDL_B import get_score\n",
    "import wfio\n",
    "import random\n",
    "import numpy as np\n",
    "rng = np.random.RandomState(31337) \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  #用于标准化\n",
    "from sklearn.preprocessing import MinMaxScaler  #用于归一化\n",
    "\n",
    "import time # 用于计时\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error    # 精度模块\n",
    "from sklearn.model_selection import KFold   # 交叉验证模块\n",
    "from sklearn.ensemble import RandomForestClassifier    # 随机森林模块\n",
    "from sklearn.tree import DecisionTreeClassifier   # 决策树模块\n",
    "from sklearn.ensemble import GradientBoostingClassifier # GradientBoosting模块\n",
    "from xgboost.sklearn import XGBClassifier    # XGboost模块\n",
    "from sklearn.ensemble import BaggingClassifier    # Bagging模块\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNn模块\n",
    "from sklearn.ensemble import ExtraTreesClassifier   # ExtraTrees模块\n",
    "from logitboost import LogitBoost    # LogitBoost模块\n",
    "from sklearn.ensemble import AdaBoostClassifier   # AdaBoost模块\n",
    "from sklearn.linear_model import LogisticRegression  # 对数几率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试集数据\n",
    "def get_test_data():\n",
    "    test_data = wfio.read_dataframe(_INPUT3)\n",
    "    # test_data = wfio.read_dataframe(_INPUT4)\n",
    "    # 删除第一行中文 \n",
    "    # test_data = test_data.drop(0,axis=0,inplace=False)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练集数据\n",
    "def get_train_data():\n",
    "    train_data_1 = wfio.read_dataframe(_INPUT1)\n",
    "    train_data_2 = wfio.read_dataframe(_INPUT2)\n",
    "    train_data_1 = train_data_1.rename(columns = {'xyzl':'hyzl', 'xyml':'hyml', 'xy':'hy', 'xydl':'hydl',\n",
    "                                                  'zczby':'zczb', 'jdxz':'xzjd', 'djkyrq':'djrq',\n",
    "                                                  'frsjh':'fdbrxmp', 'cwryxm':'bsrxm', 'cwrysjh':'bsrxmmp'})\n",
    "    # 两个数据拼一起\n",
    "    train_data = pd.concat([train_data_2, train_data_1], sort=False)\n",
    "    #删除第一行中文\n",
    "    #train_data = train_data.drop(0,axis=0,inplace=False)\n",
    "    train_data = train_data.sort_values('yc', ascending = False)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算理论入库\n",
    "def cal_llrk(X):    \n",
    "    # X_new = np.copy(X)\n",
    "    for i in range(0,96,8):\n",
    "        jxse = X[:,i+1] * X[:,i+2]  # 进项税额\n",
    "        llrk = np.zeros_like(jxse)  # 理论入库\n",
    "        for j in range(X.shape[0]):\n",
    "            if X[j,i+2] == 0.03:    # 如果进项税率为0.03\n",
    "                llrk[j] = X[j,i+5]    # 理论入库为开票税额\n",
    "            else:               # 如果进项税额不为0.03\n",
    "                llrk[j] = max(X[j,i+5] - jxse[j], 0) # 理论入库为开票税额-进项税额（结果为负时取0）\n",
    "        X = np.column_stack((X,llrk))\n",
    "        # X = np.column_stack((X,llrk-X[:,i+7]))\n",
    "        # X[:,i+5] = llrk\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_jxse(X):    # 计算进项税额\n",
    "    for i in range(0,96,8):\n",
    "        X = np.column_stack((X,X[:,i+1]*X[:,i+2]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_djrq(djrq):  #计算登记日期\n",
    "    djrq_num = np.zeros_like(djrq)\n",
    "    for i in range(djrq.shape[0]):\n",
    "        rq_ls = djrq[i].split(sep= '-') \n",
    "        djrq_num[i] = int(rq_ls[0])-2 + 0.25*(int(rq_ls[1])//4)\n",
    "    return djrq_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_chsj_kpjj(X0, X): #计算存活时间和开票季节数\n",
    "    djrq_num = get_djrq(X0[:,99])\n",
    "    chsj = np.zeros_like(djrq_num)\n",
    "    kpjj = np.zeros_like(djrq_num)\n",
    "    for j in range(X.shape[0]): #遍历\n",
    "        current = djrq_num[j]\n",
    "        for i in range(0,96,8):\n",
    "            if X[j,i+1] != 0:       #如果当季有开票\n",
    "                kpjj[j] += 1        #季节加1\n",
    "                current = 2017 + i/8 * 0.25     #当前季节\n",
    "                chsj[j] = current - djrq_num[j]     #更新存活时间\n",
    "    X_new = np.column_stack((X,chsj,kpjj))\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取数据\n",
    "def get_data():\n",
    "    #训练集\n",
    "    train_data = get_train_data()\n",
    "    hyml = np.array(pd.get_dummies(train_data['hyml']) )\n",
    "    X0 = np.array(train_data)  #所有特征\n",
    "    # X = X0[:,0:96]  #数字特征\n",
    "    X = np.column_stack( (X0[:,0:96],X0[:, [98, -2]] ) )\n",
    "    y = np.array(train_data['yc'])  #标签\n",
    "\n",
    "    for i in range(0,X.shape[0]):\n",
    "        for j in range(0,X.shape[1]):\n",
    "            try:\n",
    "                X[i,j] = float(X[i,j])\n",
    "            except:\n",
    "                X[i,j] = 0\n",
    "    X = X.astype(np.float)\n",
    "    y = y.astype(np.float)\n",
    "\n",
    "    #测试集\n",
    "    test_data = get_test_data()\n",
    "    Xtest0 = np.array(get_test_data())  #所有特征\n",
    "    # Xtest = Xtest0[:,0:96]  #数字特征\n",
    "    Xtest = np.column_stack( (Xtest0[:, 0:96], Xtest0[:, [98, -2]] ) )\n",
    "    for i in range(0, Xtest.shape[0]):\n",
    "        for j in range(0, Xtest.shape[1]):\n",
    "            try:\n",
    "                Xtest[i,j] = float(Xtest[i,j])\n",
    "            except:\n",
    "                Xtest[i,j] = 0\n",
    "    Xtest = Xtest.astype(np.float)\n",
    "    \n",
    "    return train_data, test_data, X0, Xtest0, X, y, Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理\n",
    "def data_solve(train_data, test_data, X0, Xtest0, X, Xtest, y):\n",
    "    X1 = cal_llrk(X)  #计算理论入库\n",
    "    X2 = cal_jxse(X1)  #计算进项税额\n",
    "    X3 = cal_chsj_kpjj(X0, X2) #计算开票季节、存活时间\n",
    "    Xtest1 = cal_llrk(Xtest)\n",
    "    Xtest2 = cal_jxse(Xtest1)\n",
    "    Xtest3 = cal_chsj_kpjj(Xtest0, Xtest2) \n",
    "\n",
    "    #行业门类\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    hyml_co = pd.concat([train_data['hyml'], test_data['hyml']],sort=False)\n",
    "    hyml_np = LabelEncoder().fit_transform(hyml_co.values)\n",
    "    #行业大类\n",
    "    hydl_co = pd.concat([train_data['hydl'], test_data['hydl']],sort=False)\n",
    "    hydl_np = LabelEncoder().fit_transform(hydl_co.values)\n",
    "    #乡镇街道\n",
    "    xzjd_co = pd.concat([train_data['xzjd'], test_data['xzjd']],sort=False)\n",
    "    xzjd_np = LabelEncoder().fit_transform(xzjd_co.values)\n",
    "    X4 = np.column_stack((X3, hyml_np[0: X.shape[0]], hydl_np[0: X.shape[0]], xzjd_np[0: X.shape[0]]) )\n",
    "    Xtest4 = np.column_stack((Xtest3, hyml_np[X.shape[0]: ], hydl_np[X.shape[0]: ], xzjd_np[X.shape[0]: ]) )\n",
    "\n",
    "    #标准化\n",
    "    stdsc = StandardScaler()\n",
    "    X_std = stdsc.fit_transform(X)\n",
    "    Xtest_std = stdsc.transform(Xtest)\n",
    "    X1_std = stdsc.fit_transform(X1)\n",
    "    Xtest1_std = stdsc.transform(Xtest1)\n",
    "    X2_std = stdsc.fit_transform(X2)\n",
    "    Xtest2_std = stdsc.transform(Xtest2)\n",
    "    X3_std = stdsc.fit_transform(X3)\n",
    "    Xtest3_std = stdsc.transform(Xtest3)\n",
    "    X4_std = stdsc.fit_transform(X4)\n",
    "    Xtest4_std = stdsc.transform(Xtest4)\n",
    "\n",
    "    #归一化\n",
    "    mms = MinMaxScaler()\n",
    "    X_norm = mms.fit_transform(X)\n",
    "    Xtest_norm = mms.transform(Xtest)\n",
    "    X1_norm = mms.fit_transform(X1)\n",
    "    Xtest1_norm = mms.transform(Xtest1)\n",
    "    X2_norm = mms.fit_transform(X2)\n",
    "    Xtest2_norm = mms.transform(Xtest2)\n",
    "    X3_norm = mms.fit_transform(X3)\n",
    "    Xtest3_norm = mms.transform(Xtest3)\n",
    "    X4_norm = stdsc.fit_transform(X4)\n",
    "    Xtest4_norm = stdsc.transform(Xtest4)\n",
    "    \n",
    "    #特征名称\n",
    "    characters = list(train_data.columns[:96])\n",
    "    characters += ['cyrs' , 'zczb']\n",
    "\n",
    "    characterjd = characters[0:96:8]\n",
    "    def ll(x):\n",
    "        x = x.replace('fphdsl','llrk')\n",
    "        return x\n",
    "    llrk_s = map(ll, characterjd)\n",
    "    characters += llrk_s\n",
    "    def kp(x):\n",
    "        x = x.replace('fphdsl','kpse')\n",
    "        return x\n",
    "    kpse_s = map(kp, characterjd)\n",
    "    characters += kpse_s\n",
    "    characters += ['chsj', 'kpjj', 'hyml' , 'hydl', 'xzjd']   \n",
    "    \n",
    "    return X4_std, Xtest4_std, characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_selct(X4, Xtest4, characters): #特征筛选\n",
    "    X5 = pd.DataFrame(X4, columns = characters)\n",
    "    Xtest5 = pd.DataFrame(Xtest4, columns = characters)\n",
    "\n",
    "    col = list(range(6,96,8) ) + list(range(2,96,8) ) + list(range(4,96,8) )\n",
    "    X6 = X5.drop(['zczb', 'cyrs'], axis=1)\n",
    "    Xtest6 = Xtest5.drop(Xtest5.columns[[96,97]], axis=1)\n",
    "\n",
    "    col = list(range(6,96,8) ) + list(range(2,96,8) ) + list(range(4,96,8) )\n",
    "    X7 = X6.drop(X5.columns[col], axis=1)\n",
    "    Xtest7 = Xtest6.drop(Xtest5.columns[col], axis=1)\n",
    "\n",
    "    X8 = X7.drop(['hydl'], axis=1)\n",
    "    Xtest8 = Xtest7.drop(['hydl'], axis=1)\n",
    "    \n",
    "    return X5,Xtest5, X6, Xtest6, X7, Xtest7, X8, Xtest8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打分函数\n",
    "def create_verify_train_data(train_data, test_data, predictions):\n",
    "    #读取训练集的'zjnsrsbh'字段\n",
    "    train_data = test_data\n",
    "    prob = {\"zjnsrsbh\": train_data['zjnsrsbh'],}\n",
    "    train_data = pd.DataFrame(prob)\n",
    "    train_data['Probability'] = predictions\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-id:5\n",
      "程序开始运行时间为：2019-12-22 13:41:11.468373\n",
      "程序结束运行时间为：2019-12-22 13:41:13.276576\n",
      "程序运行时间（去除打分耗时）为：1.808203\n",
      "程序的准确率为：95.75373406\n",
      "最终得分为：96.17836065\n"
     ]
    }
   ],
   "source": [
    "#模型训练\n",
    "# model = SVC(kernel='linear', gamma='scale', probability=True, C=100).fit(X1[0:3500,:], y[0:3500])\n",
    "# C为正则化系数的倒数\n",
    "# model = LogisticRegression(solver= 'lbfgs', max_iter=2000, C=10).fit(X1[0:3000,:], y[0:3000])  #对数几率\n",
    "# model = LogisticRegression(solver= 'lbfgs', max_iter=2000, C=10 ** 7).fit(X4_std[0:7250,:], y[0:7250])  #对数几率(7250)\n",
    "# model = RandomForestClassifier(n_estimators=125).fit(X4[0:7250,:], y[0:7250])  #随机森林\n",
    "# model = LogitBoost().fit(X4[0:2000,:], y[0:2000])  #logitboost\n",
    "# model = DecisionTreeClassifier().fit(X4[0:7300,:], y[0:7300])  #决策树\n",
    "# model = KNeighborsClassifier(n_neighbors=2,p=2,metric='minkowski').fit(X4[0:7250,:], y[0:7250])\n",
    "# model = BaggingClassifier().fit(X4_std[0:7250,:], y[0:7250])\n",
    "# model = ExtraTreesClassifier(n_estimators=100).fit(X4_std[0:7250,:], y[0:7250])\n",
    "# model = AdaBoostClassifier().fit(X4_std[0:7250,:], y[0:7250])\n",
    "# model = GradientBoostingClassifier(n_estimators=125).fit(X4_std[0:7000,:], y[0:7000])\n",
    "# model = XGBClassifier(learning_rate=0.1,n_estimatores=150,min_child_weight = 1).fit(X4_std[0:8000,:], y[0:8000])\n",
    "\n",
    "#获取数据    \n",
    "train_data, test_data, X0, Xtest0, X, y, Xtest = get_data() \n",
    "\n",
    "#开始计时    \n",
    "get_score.post_user_id('5') \n",
    "#数据预处理\n",
    "X4_std, Xtest4_std, characters = data_solve(train_data, test_data, X0, Xtest0, X, Xtest, y) \n",
    "#特征筛选\n",
    "X5,Xtest5, X6, Xtest6, X7, Xtest7, X8, Xtest8 = char_selct(X4_std, Xtest4_std, characters)\n",
    "#模型训练（对数几率）    \n",
    "model = LogisticRegression(solver= 'lbfgs', max_iter=2000, C=10**7).fit(X5.values[200:7350,:], y[200:7350])  \n",
    "#数据预测\n",
    "predictions = model.predict_proba(Xtest5.values)[:,1] #在测试集上进行预测\n",
    "\n",
    "#打分\n",
    "get_score.post_verify_data(create_verify_train_data(train_data, test_data, predictions)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
