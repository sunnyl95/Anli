{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# 输入数据的参数\n",
    "_INPUT1='{\"name\":\"input1\",\"type\":0,\"uri\":\"tmp_2d89787c992c411eba59c89b454b0b6b\"}'\n",
    "_INPUT2='{\"name\":\"input2\",\"type\":0,\"uri\":\"tmp_3debe6d3c07740a0bf5ac878429c9e67\"}'\n",
    "_INPUT3='{\"name\":\"input3\",\"type\":0,\"uri\":\"tmp_29ff19f2389248fe99b1f33aa4d923f0\"}'\n",
    "\n",
    "# 输出数据的参数\n",
    "_OUTPUT='[{\"name\":\"output1\",\"type\":0,\"uri\":\"tmp_40d41d51625d41bb9c260e722bad8d29\"},{\"name\":\"output2\",\"type\":0,\"uri\":\"tmp_829ae4e1d5ce4989a8bc7e350e649686\"},{\"name\":\"output3\",\"type\":0,\"uri\":\"tmp_dd2bf7ee308e47e8a9c72c354e981910\"},{\"name\":\"output4\",\"type\":0,\"uri\":\"tmp_0627f327349a4aea8b8d2cb5f85582d7\"}]'\n",
    "\n",
    "# 自定义参数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import wfio\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import sys   \n",
    "import re\n",
    "from ustciscrBDL_B import get_score\n",
    "import sklearn.tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.externals import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取训练集数据\n",
    "def get_train_data():\n",
    "    train_data1 = wfio.read_dataframe(_INPUT1)\n",
    "    train_data2 = wfio.read_dataframe(_INPUT2)\n",
    "    return train_data1.append(train_data2,ignore_index=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取测试集数据\n",
    "def get_test_data():\n",
    "    test_data = wfio.read_dataframe(_INPUT3)\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "season=['2017q1','2017q2','2017q3','2017q4',\n",
    "        '2018q1','2018q2','2018q3','2018q4',\n",
    "        '2019q1','2019q2','2019q3','2019q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取浮点数整数部分的长度\n",
    "def num_length(num):\n",
    "    return len(str(int(num)))\n",
    "\n",
    "#字符串转浮点数（异常矫正）\n",
    "def str2float(str):\n",
    "    try:\n",
    "        return float(str)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 生僻字风险度\n",
    "def is_rare_name(string):\n",
    "    risk=0\n",
    "    pattern = re.compile(u\"[~!@#$%^&* ]\")\n",
    "    match = pattern.search(string)\n",
    "    if match:\n",
    "        risk+=1\n",
    "\n",
    "    try:\n",
    "        string.encode(\"gb2312\")\n",
    "    except UnicodeEncodeError:\n",
    "        risk+=1\n",
    "    return risk\n",
    "\n",
    "#登记开业时间转数字\n",
    "def datestr2num(str):\n",
    "    try:\n",
    "        str=str.split('-')\n",
    "        str[2]=str[2].split(' ')[0]\n",
    "        num=(2019-int(str[0]))*365+(12-int(str[1]))*30+(30-int(str[2]))\n",
    "        return num\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(dataframe,label=False):\n",
    "    feature_dict={}\n",
    "    \n",
    "    keys=['fphdsl','jxje','jxsl','kpje','kps','kpse','rkse','kpsl'] # 开票数据、纳税数据\n",
    "    \n",
    "    for s in season:\n",
    "        feature_dict[s+\"_full_amount\"]=[]   #开票顶额\n",
    "        feature_dict[s+\"_full_percent\"]=[]   #开票顶额度\n",
    "        #纳税开票情况\n",
    "        for k in keys:\n",
    "            feature_dict[s+k]=[]\n",
    "        feature_dict[s+'jxse']=[]\n",
    "        \n",
    "    for s in range(len(season)-1):\n",
    "        feature_dict[season[s]+\"_increase\"]=[]  #开票金额增量\n",
    "        \n",
    "    feature_dict[\"bsrxm_repeat\"]=[] #重复注册bsrxm\n",
    "    bsrxm_repeat=dataframe['bsrxm'].duplicated()\n",
    "    \n",
    "    feature_dict[\"fddbrxm_repeat\"]=[] #重复注册fddbrxm\n",
    "    fddbrxm_repeat=dataframe['fddbrxm'].duplicated()\n",
    "    \n",
    "    feature_dict[\"bsrxmmp_repeat\"]=[] #重复注册bsrxmmp\n",
    "    bsrxmmp_repeat=dataframe['bsrxmmp'].duplicated()\n",
    "    \n",
    "    feature_dict[\"fdbrxmp_repeat\"]=[] #重复注册fdbrxmp\n",
    "    fdbrxmp_repeat=dataframe['fdbrxmp'].duplicated()\n",
    "    \n",
    "    feature_dict[\"zcdz_repeat\"]=[] #重复注册zcdz\n",
    "    zcdz_repeat=dataframe['zcdz'].duplicated()\n",
    "    \n",
    "    feature_dict['djrq']=[] #登记日期\n",
    "    \n",
    "    feature_dict['gwhy']=[] #高危行业风险度\n",
    "    hy_list=['hy','hydl','hyml','hyzl','jyfw']\n",
    "    xy_list=['xy','xydl','xyml','xyzl','jyfw']\n",
    "    gwhy_keys=[\"商\",\"贸\",'建材','批发','零售','咨询','鉴证','人力资源','服务','纺织','服饰','加工','中药','种植']\n",
    "    \n",
    "    feature_dict['name']=[] #命名规范\n",
    "    \n",
    "    feature_dict['location']=[] #公司地址风险度\n",
    "    addr_pos=['小区','花园']\n",
    "    addr_neg=[\"商\",'办公','工']\n",
    "    \n",
    "    feature_dict['cyrs']=[] #从业人数\n",
    "    \n",
    "    feature_dict['zczb']=[] #注册资本\n",
    "    \n",
    "    if label:# 提取训练集需要'yc'\n",
    "        feature_dict['yc']=[]\n",
    "   \n",
    "        \n",
    "    for i in range(dataframe.shape[0]):\n",
    "        \n",
    "        for s in season:\n",
    "            \n",
    "            #开票顶额\n",
    "            feature_dict[s+\"_full_amount\"].append(num_length(str2float(dataframe[s+\"kpje\"].iloc[i])))\n",
    "            \n",
    "            #开票顶额度\n",
    "            feature_dict[s+\"_full_percent\"].append(str2float(dataframe[s+\"kpje\"].iloc[i])/10**num_length(str2float(dataframe[s+\"kpje\"].iloc[i])))\n",
    "            \n",
    "            \n",
    "#             keys=['fphdsl','kps','jxje','kpje','kpse','rkse'] # 开票数据、纳税数据\n",
    "            #纳税情况\n",
    "            for k in keys:\n",
    "                feature_dict[s+k].append(str2float(dataframe[s+k].iloc[i]))\n",
    "                \n",
    "            feature_dict[s+'jxse'].append(str2float(dataframe[s+'jxje'].iloc[i])*str2float(dataframe[s+'jxsl'].iloc[i]))\n",
    "            \n",
    "            \n",
    "    \n",
    "        for s in range(len(season)-1):\n",
    "            #开票金额增量\n",
    "            feature_dict[season[s]+\"_increase\"].append(str2float(dataframe[season[s+1]+'kpje'].iloc[i])-str2float(dataframe[season[s]+'kpje']))\n",
    "        \n",
    "        #重复注册bsrxm\n",
    "        feature_dict[\"bsrxm_repeat\"].append(float(bsrxm_repeat.iloc[i]))\n",
    "        \n",
    "        #重复注册fddbrxm\n",
    "        feature_dict[\"fddbrxm_repeat\"].append(float(fddbrxm_repeat.iloc[i])) \n",
    "        \n",
    "        #重复注册bsrxmmp\n",
    "        feature_dict[\"bsrxmmp_repeat\"].append(float(bsrxmmp_repeat.iloc[i]))\n",
    "\n",
    "        #重复注册fdbrxmp\n",
    "        feature_dict[\"fdbrxmp_repeat\"].append(float(fdbrxmp_repeat.iloc[i]))\n",
    "        \n",
    "        #重复注册zcdz\n",
    "        feature_dict[\"zcdz_repeat\"].append(float(zcdz_repeat.iloc[i]))\n",
    "        \n",
    "        #登记日期\n",
    "        feature_dict[\"djrq\"].append(datestr2num(dataframe['djrq']))\n",
    "        \n",
    "        #高危行业风险度\n",
    "        risk=0\n",
    "        try:\n",
    "            for hy in hy_list:\n",
    "                for w in gwhy_keys:\n",
    "                    if w in dataframe[hy].iloc[i]:\n",
    "                        risk+=1\n",
    "        except:\n",
    "            for hy in xy_list:\n",
    "                for w in gwhy_keys:\n",
    "                    if w in dataframe[hy].iloc[i]:\n",
    "                        risk+=1\n",
    "        feature_dict['gwhy'].append(risk)\n",
    "        \n",
    "        #公司命名风险度\n",
    "        feature_dict['name'].append(is_rare_name(dataframe['nsrmc'].iloc[i]))\n",
    "    \n",
    "        # 地址风险度\n",
    "        risk=0\n",
    "        for l in ['scjydz','zcdz']:\n",
    "            for p in addr_pos:\n",
    "                if p not in dataframe[l].iloc[i]:\n",
    "                    risk+=1\n",
    "            for n in addr_neg:\n",
    "                if n in dataframe[l].iloc[i]:\n",
    "                    risk+=1\n",
    "        feature_dict['location'].append(risk)\n",
    "        \n",
    "        # 从业人数\n",
    "        feature_dict['cyrs'].append(str2float(dataframe['cyrs'].iloc[i]))\n",
    "        \n",
    "        #注册资本\n",
    "        if 'zczby' in dataframe.keys():\n",
    "            try:\n",
    "                if math.isnan(float(dataframe['zczby'].iloc[i])):\n",
    "                    feature_dict['zczb'].append(0)\n",
    "                else:\n",
    "                    feature_dict['zczb'].append(float(dataframe['zczby'].iloc[i]))\n",
    "            except:\n",
    "                feature_dict['zczb'].append(0)\n",
    "        else:\n",
    "            try:\n",
    "                if math.isnan(float(dataframe['zczb'].iloc[i])):\n",
    "                    feature_dict['zczb'].append(0)\n",
    "                else:\n",
    "                    feature_dict['zczb'].append(float(dataframe['zczb'].iloc[i]))\n",
    "            except:\n",
    "                feature_dict['zczb'].append(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #标签\n",
    "        if label:\n",
    "            feature_dict['yc'].append(int(dataframe['yc'].iloc[i]))\n",
    "            \n",
    "    return feature_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tf(x,label=False):\n",
    "    #x=data_normalize(x)\n",
    "    temp=list(x.values())\n",
    "    x=np.transpose(np.array(temp,np.float32))\n",
    "    if label is False:\n",
    "        return x\n",
    "    else: # 训练集模式返回标签\n",
    "        np.random.shuffle(x)\n",
    "        x1=x[:18000]\n",
    "        x2=x[18000:]\n",
    "        return np.delete(x1, -1, axis=1),np.delete(x2, -1, axis=1),x1[:,-1],x2[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('tree.pkl'):\n",
    "    train_data_=get_train_data()\n",
    "    feature_dict=feature_extract(train_data_,True)\n",
    "    train_feature,test_feature,train_label,test_label=data_tf(feature_dict,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:0.997\n",
      "Test score:0.996\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('tree.pkl'):\n",
    "    tree = DecisionTreeClassifier(criterion=\"entropy\",\n",
    "                                 splitter=\"best\",\n",
    "                                 max_depth=24,\n",
    "                                 min_samples_split=2,\n",
    "                                 min_samples_leaf=1,\n",
    "                                 min_weight_fraction_leaf=0.,\n",
    "                                 max_features=None,\n",
    "                                 random_state=None,\n",
    "                                 #max_leaf_nodes=26,\n",
    "                                 min_impurity_decrease=0.,\n",
    "                                 min_impurity_split=None,\n",
    "                                 class_weight=None,\n",
    "                                 presort=False\n",
    "                                 )\n",
    "    tree.fit(train_feature,train_label)\n",
    "    print('Train score:{:.3f}'.format(tree.score(train_feature,train_label)))\n",
    "    print('Test score:{:.3f}'.format(tree.score(test_feature,test_label)))\n",
    "    joblib.dump(tree,'tree.pkl')\n",
    "else:\n",
    "    tree=joblib.load('tree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=get_test_data()\n",
    "feature=feature_extract(test_data)\n",
    "feature=data_tf(feature,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verify_data_dt(feature,train_data):\n",
    "    \n",
    "    prob = {\n",
    "        \"zjnsrsbh\": train_data['zjnsrsbh']\n",
    "    }\n",
    "    \n",
    "    prob_list = []\n",
    "    train_data = pd.DataFrame(prob)\n",
    "    rows = train_data.shape[0]\n",
    "    train_data['Probability'] = tree.predict_proba(feature)[:,1]\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-id:5\n",
      "程序开始运行时间为：2019-12-22 13:33:57.792356\n",
      "程序结束运行时间为：2019-12-22 13:33:57.806553\n",
      "程序运行时间（去除打分耗时）为：0.014197\n",
      "程序的准确率为：93.43099483\n",
      "最终得分为：94.08789535\n"
     ]
    }
   ],
   "source": [
    "get_score.post_user_id('5')\n",
    "user_verify_data_dt = get_verify_data_dt(feature,test_data)\n",
    "get_score.post_verify_data(user_verify_data_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
