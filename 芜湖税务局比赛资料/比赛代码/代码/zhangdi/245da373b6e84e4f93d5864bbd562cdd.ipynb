{"nbformat_minor":2,"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","file_extension":".py","mimetype":"text/x-python","version":"3.7.3"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"cells":[{"outputs":[],"metadata":{"tags":["parameters"]},"execution_count":1,"source":["# 输入数据的参数\n","_INPUT1='{\"name\":\"input1\",\"type\":0,\"uri\":\"tmp_264b4774bc9f465d93e9eea324b1d68d\"}'\n","_INPUT2='{\"name\":\"input2\",\"type\":0,\"uri\":\"tmp_085815248a544be1b08640ed5f21add2\"}'\n","_INPUT3='{\"name\":\"input3\",\"type\":0,\"uri\":\"tmp_84173d900f1742d0843cdc7bdfa8b918\"}'\n","_INPUT4='{\"name\":\"input4\",\"type\":0,\"uri\":\"tmp_5d0dfccd54e14d1da83bacd2ed124ebc\"}'\n","\n","# 输出数据的参数\n","_OUTPUT='[{\"name\":\"output1\",\"type\":0,\"uri\":\"tmp_9fb392f2915f40769a3b05bf2bb6c61d\"},{\"name\":\"output2\",\"type\":0,\"uri\":\"tmp_c23c753942e147b286fd175d85b8f4ad\"},{\"name\":\"output3\",\"type\":0,\"uri\":\"tmp_3f9be2b080264594bee9992f3e14777f\"},{\"name\":\"output4\",\"type\":0,\"uri\":\"tmp_dddf7ab2bbce49c8aa5c1861fb40667f\"}]'\n","\n","# 自定义参数\n"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":2,"source":["import wfio\n","\n","import pandas as pd\n","import numpy as np\n","# 读取并返回dataframe对象\n","# :param as_spark: 为True返回pyspark.sql.DataFrame对象，为False返回pandas.DataFrame对象，默认为False\n","train_data1 = wfio.read_dataframe(_INPUT2)\n","train_data2 = wfio.read_dataframe(_INPUT3)\n","probe_data1 = wfio.read_dataframe(_INPUT4)\n"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":3,"source":["train_data1.columns = ['2017Q1发票核定数量', '2017Q1进项金额', '2017Q1进项税率', '2017Q1开票金额', '2017Q1开票数', '2017Q1开票税额', '2017Q1开票税率', '2017Q1入库税额', '2017Q2发票核定数量', '2017Q2进项金额', '2017Q2进项税率', '2017Q2开票金额', '2017Q2开票数', '2017Q2开票税额', '2017Q2开票税率', '2017Q2入库税额', '2017Q3发票核定数量', '2017Q3进项金额', '2017Q3进项税率', '2017Q3开票金额', '2017Q3开票数', '2017Q3开票税额', '2017Q3开票税率', '2017Q3入库税额', '2017Q4发票核定数量', '2017Q4进项金额', '2017Q4进项税率', '2017Q4开票金额', '2017Q4开票数', '2017Q4开票税额', '2017Q4开票税率', '2017Q4入库税额', '2018Q1发票核定数量', '2018Q1进项金额', '2018Q1进项税率', '2018Q1开票金额', '2018Q1开票数', '2018Q1开票税额', '2018Q1开票税率', '2018Q1入库税额', '2018Q2发票核定数量', '2018Q2进项金额', '2018Q2进项税率', '2018Q2开票金额', '2018Q2开票数', '2018Q2开票税额', '2018Q2开票税率', '2018Q2入库税额', '2018Q3发票核定数量', '2018Q3进项金额', '2018Q3进项税率', '2018Q3开票金额', '2018Q3开票数', '2018Q3开票税额', '2018Q3开票税率', '2018Q3入库税额', '2018Q4发票核定数量', '2018Q4进项金额', '2018Q4进项税率', '2018Q4开票金额', '2018Q4开票数', '2018Q4开票税额', '2018Q4开票税率', '2018Q4入库税额', '2019Q1发票核定数量', '2019Q1进项金额', '2019Q1进项税率', '2019Q1开票金额', '2019Q1开票数', '2019Q1开票税额', '2019Q1开票税率', '2019Q1入库税额', '2019Q2发票核定数量', '2019Q2进项金额', '2019Q2进项税率', '2019Q2开票金额', '2019Q2开票数', '2019Q2开票税额', '2019Q2开票税率', '2019Q2入库税额', '2019Q3发票核定数量', '2019Q3进项金额', '2019Q3进项税率', '2019Q3开票金额', '2019Q3开票数', '2019Q3开票税额', '2019Q3开票税率', '2019Q3入库税额', '2019Q4发票核定数量', '2019Q4进项金额', '2019Q4进项税率', '2019Q4开票金额', '2019Q4开票数', '2019Q4开票税额', '2019Q4开票税率', '2019Q4入库税额', '财务人员手机号', '财务人员姓名', '从业人数', '登记开业日期', '法定代表人姓名', '法人手机号', '街道乡镇', '经营范围', '纳税人名称', '生产经营地址', '行业', '行业大类', '行业门类', '行业中类',\"异常\",'注册地址', '注册资本（元）', '主键:纳税人识别号']                     \n","train_data2.columns = ['2017Q1发票核定数量', '2017Q1进项金额', '2017Q1进项税率', '2017Q1开票金额', '2017Q1开票数', '2017Q1开票税额', '2017Q1开票税率', '2017Q1入库税额', '2017Q2发票核定数量', '2017Q2进项金额', '2017Q2进项税率', '2017Q2开票金额', '2017Q2开票数', '2017Q2开票税额', '2017Q2开票税率', '2017Q2入库税额', '2017Q3发票核定数量', '2017Q3进项金额', '2017Q3进项税率', '2017Q3开票金额', '2017Q3开票数', '2017Q3开票税额', '2017Q3开票税率', '2017Q3入库税额', '2017Q4发票核定数量', '2017Q4进项金额', '2017Q4进项税率', '2017Q4开票金额', '2017Q4开票数', '2017Q4开票税额', '2017Q4开票税率', '2017Q4入库税额', '2018Q1发票核定数量', '2018Q1进项金额', '2018Q1进项税率', '2018Q1开票金额', '2018Q1开票数', '2018Q1开票税额', '2018Q1开票税率', '2018Q1入库税额', '2018Q2发票核定数量', '2018Q2进项金额', '2018Q2进项税率', '2018Q2开票金额', '2018Q2开票数', '2018Q2开票税额', '2018Q2开票税率', '2018Q2入库税额', '2018Q3发票核定数量', '2018Q3进项金额', '2018Q3进项税率', '2018Q3开票金额', '2018Q3开票数', '2018Q3开票税额', '2018Q3开票税率', '2018Q3入库税额', '2018Q4发票核定数量', '2018Q4进项金额', '2018Q4进项税率', '2018Q4开票金额', '2018Q4开票数', '2018Q4开票税额', '2018Q4开票税率', '2018Q4入库税额', '2019Q1发票核定数量', '2019Q1进项金额', '2019Q1进项税率', '2019Q1开票金额', '2019Q1开票数', '2019Q1开票税额', '2019Q1开票税率', '2019Q1入库税额', '2019Q2发票核定数量', '2019Q2进项金额', '2019Q2进项税率', '2019Q2开票金额', '2019Q2开票数', '2019Q2开票税额', '2019Q2开票税率', '2019Q2入库税额', '2019Q3发票核定数量', '2019Q3进项金额', '2019Q3进项税率', '2019Q3开票金额', '2019Q3开票数', '2019Q3开票税额', '2019Q3开票税率', '2019Q3入库税额', '2019Q4发票核定数量', '2019Q4进项金额', '2019Q4进项税率', '2019Q4开票金额', '2019Q4开票数', '2019Q4开票税额', '2019Q4开票税率', '2019Q4入库税额', '财务人员姓名','财务人员手机号',  '从业人数', '登记开业日期',  '法人手机号', '法定代表人姓名','行业', '行业大类', '行业门类', '行业中类', '经营范围', '纳税人名称', '生产经营地址','街道乡镇', \"异常\",'注册地址', '注册资本（元）', '主键:纳税人识别号']                     \n","probe_data = probe_data1.copy()\n","\n","probe_data.columns = ['2017Q1发票核定数量', '2017Q1进项金额', '2017Q1进项税率', '2017Q1开票金额', '2017Q1开票数', '2017Q1开票税额', '2017Q1开票税率', '2017Q1入库税额',\n","                      '2017Q2发票核定数量', '2017Q2进项金额', '2017Q2进项税率', '2017Q2开票金额', '2017Q2开票数', '2017Q2开票税额', \n","                      '2017Q2开票税率', '2017Q2入库税额', '2017Q3发票核定数量', '2017Q3进项金额', '2017Q3进项税率', '2017Q3开票金额', '2017Q3开票数', '2017Q3开票税额', \n","                      '2017Q3开票税率', '2017Q3入库税额', '2017Q4发票核定数量', '2017Q4进项金额', '2017Q4进项税率', '2017Q4开票金额', '2017Q4开票数', '2017Q4开票税额',\n","                      '2017Q4开票税率', '2017Q4入库税额', '2018Q1发票核定数量', '2018Q1进项金额', '2018Q1进项税率', '2018Q1开票金额', '2018Q1开票数', '2018Q1开票税额',\n","                      '2018Q1开票税率', '2018Q1入库税额', '2018Q2发票核定数量', '2018Q2进项金额', '2018Q2进项税率', '2018Q2开票金额', '2018Q2开票数', '2018Q2开票税额', \n","                      '2018Q2开票税率', '2018Q2入库税额', '2018Q3发票核定数量', '2018Q3进项金额', '2018Q3进项税率', '2018Q3开票金额', '2018Q3开票数', '2018Q3开票税额',\n","                      '2018Q3开票税率', '2018Q3入库税额', '2018Q4发票核定数量', '2018Q4进项金额', '2018Q4进项税率', '2018Q4开票金额', '2018Q4开票数', '2018Q4开票税额', \n","                      '2018Q4开票税率', '2018Q4入库税额', '2019Q1发票核定数量', '2019Q1进项金额', '2019Q1进项税率', '2019Q1开票金额', '2019Q1开票数', '2019Q1开票税额',\n","                      '2019Q1开票税率', '2019Q1入库税额', '2019Q2发票核定数量', '2019Q2进项金额', '2019Q2进项税率', '2019Q2开票金额', '2019Q2开票数', '2019Q2开票税额',\n","                      '2019Q2开票税率', '2019Q2入库税额', '2019Q3发票核定数量', '2019Q3进项金额', '2019Q3进项税率', '2019Q3开票金额', '2019Q3开票数', '2019Q3开票税额',\n","                      '2019Q3开票税率', '2019Q3入库税额', '2019Q4发票核定数量', '2019Q4进项金额', '2019Q4进项税率', '2019Q4开票金额', '2019Q4开票数', '2019Q4开票税额',\n","                      '2019Q4开票税率', '2019Q4入库税额', \n","                      '财务人员姓名', '财务人员手机号', '从业人数', '登记开业日期', '法人手机号', '法定代表人姓名',  '行业', '行业大类', \n","                      '行业门类', '行业中类','经营范围', '纳税人名称', '生产经营地址', '街道乡镇','注册地址', '注册资本（元）', '主键:纳税人识别号']          "],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stderr","text":["/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n","of pandas will change to not sort by default.\n","\n","To accept the future behavior, pass 'sort=False'.\n","\n","To retain the current behavior and silence the warning, pass 'sort=True'.\n","\n","  sort=sort)\n","/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"]}],"metadata":{},"execution_count":4,"source":["train_data1[\"登记开业日期\"] = pd.to_datetime(train_data1[\"登记开业日期\"]) - (pd.to_datetime('2018-02-16 00:00:00') - pd.to_datetime('2016-02-16 00:00:00'))\n","train_data1 = train_data1.append(train_data2).reset_index()\n","train_data = train_data1.copy()\n","train_data.drop(columns=[\"index\"],inplace=True)\n","\n","\n","train_data.replace(to_replace=r'\"\"\"\"\"\"\"\"\"\"\"\"\"\"',value=np.nan,inplace=True)\n","train_data.replace(to_replace=r\"迁移车购税\",value=np.nan,inplace=True)\n","train_data.replace(to_replace=r\"X\",value=np.nan,inplace=True)\n","train_data.replace(to_replace=r'^\\s*$',value=np.nan,regex=True,inplace=True)\n","# train_data = train_data.dropna()\n","\n","\n","train_data = train_data.dropna()\n","pureShape = np.array(train_data.shape)\n","\n","test_data = train_data[[\"异常\",\"主键:纳税人识别号\"]].reset_index()\n","test_data.drop(columns=[\"index\"],inplace=True)\n","train_data.drop(columns=[\"异常\"],inplace=True)\n","\n","train_data = train_data.append(probe_data).reset_index()\n","train_data.drop(columns=[\"index\"],inplace=True)\n","train_data[\"登记开业日期\"] = pd.to_datetime(train_data[\"登记开业日期\"])\n","\n","train_data.replace(to_replace=r'\"\"\"\"\"\"\"\"\"\"\"\"\"\"',value=np.nan,inplace=True)\n","train_data.replace(to_replace=r\"迁移车购税\",value=np.nan,inplace=True)\n","train_data.replace(to_replace=r\"X\",value=np.nan,inplace=True)\n","\n","\n","train_data.replace(to_replace=r'^\\s*$',value=np.nan,regex=True,inplace=True)\n","\n","Qcols = train_data[['2017Q1发票核定数量', '2017Q1进项金额', '2017Q1进项税率', '2017Q1开票金额', '2017Q1开票数', '2017Q1开票税额', '2017Q1开票税率', '2017Q1入库税额',\n","                      '2017Q2发票核定数量', '2017Q2进项金额', '2017Q2进项税率', '2017Q2开票金额', '2017Q2开票数', '2017Q2开票税额', \n","                      '2017Q2开票税率', '2017Q2入库税额', '2017Q3发票核定数量', '2017Q3进项金额', '2017Q3进项税率', '2017Q3开票金额', '2017Q3开票数', '2017Q3开票税额', \n","                      '2017Q3开票税率', '2017Q3入库税额', '2017Q4发票核定数量', '2017Q4进项金额', '2017Q4进项税率', '2017Q4开票金额', '2017Q4开票数', '2017Q4开票税额',\n","                      '2017Q4开票税率', '2017Q4入库税额', '2018Q1发票核定数量', '2018Q1进项金额', '2018Q1进项税率', '2018Q1开票金额', '2018Q1开票数', '2018Q1开票税额',\n","                      '2018Q1开票税率', '2018Q1入库税额', '2018Q2发票核定数量', '2018Q2进项金额', '2018Q2进项税率', '2018Q2开票金额', '2018Q2开票数', '2018Q2开票税额', \n","                      '2018Q2开票税率', '2018Q2入库税额', '2018Q3发票核定数量', '2018Q3进项金额', '2018Q3进项税率', '2018Q3开票金额', '2018Q3开票数', '2018Q3开票税额',\n","                      '2018Q3开票税率', '2018Q3入库税额', '2018Q4发票核定数量', '2018Q4进项金额', '2018Q4进项税率', '2018Q4开票金额', '2018Q4开票数', '2018Q4开票税额', \n","                      '2018Q4开票税率', '2018Q4入库税额', '2019Q1发票核定数量', '2019Q1进项金额', '2019Q1进项税率', '2019Q1开票金额', '2019Q1开票数', '2019Q1开票税额',\n","                      '2019Q1开票税率', '2019Q1入库税额', '2019Q2发票核定数量', '2019Q2进项金额', '2019Q2进项税率', '2019Q2开票金额', '2019Q2开票数', '2019Q2开票税额',\n","                      '2019Q2开票税率', '2019Q2入库税额', '2019Q3发票核定数量', '2019Q3进项金额', '2019Q3进项税率', '2019Q3开票金额', '2019Q3开票数', '2019Q3开票税额',\n","                      '2019Q3开票税率', '2019Q3入库税额', '2019Q4发票核定数量', '2019Q4进项金额', '2019Q4进项税率', '2019Q4开票金额', '2019Q4开票数', '2019Q4开票税额',\n","                      '2019Q4开票税率', '2019Q4入库税额', '从业人数','注册资本（元）',]].fillna(0.0).astype(\"float64\")\n","\n","Q1 = Qcols.quantile(0.001)\n","Q3 = Qcols.quantile(0.999)\n","IQR = Q3 - Q1\n","lbound = Q1 - 1.5 * IQR\n","hbound = Q3 + 1.5 * IQR\n","outliers = (Qcols > hbound) | (Qcols < lbound)\n","train_data[outliers] = np.nan\n","\n","train_data[['2017Q1发票核定数量', '2017Q1进项金额', '2017Q1进项税率', '2017Q1开票金额', '2017Q1开票数', '2017Q1开票税额', '2017Q1开票税率', '2017Q1入库税额',\n","                      '2017Q2发票核定数量', '2017Q2进项金额', '2017Q2进项税率', '2017Q2开票金额', '2017Q2开票数', '2017Q2开票税额', \n","                      '2017Q2开票税率', '2017Q2入库税额', '2017Q3发票核定数量', '2017Q3进项金额', '2017Q3进项税率', '2017Q3开票金额', '2017Q3开票数', '2017Q3开票税额', \n","                      '2017Q3开票税率', '2017Q3入库税额', '2017Q4发票核定数量', '2017Q4进项金额', '2017Q4进项税率', '2017Q4开票金额', '2017Q4开票数', '2017Q4开票税额',\n","                      '2017Q4开票税率', '2017Q4入库税额', '2018Q1发票核定数量', '2018Q1进项金额', '2018Q1进项税率', '2018Q1开票金额', '2018Q1开票数', '2018Q1开票税额',\n","                      '2018Q1开票税率', '2018Q1入库税额', '2018Q2发票核定数量', '2018Q2进项金额', '2018Q2进项税率', '2018Q2开票金额', '2018Q2开票数', '2018Q2开票税额', \n","                      '2018Q2开票税率', '2018Q2入库税额', '2018Q3发票核定数量', '2018Q3进项金额', '2018Q3进项税率', '2018Q3开票金额', '2018Q3开票数', '2018Q3开票税额',\n","                      '2018Q3开票税率', '2018Q3入库税额', '2018Q4发票核定数量', '2018Q4进项金额', '2018Q4进项税率', '2018Q4开票金额', '2018Q4开票数', '2018Q4开票税额', \n","                      '2018Q4开票税率', '2018Q4入库税额', '2019Q1发票核定数量', '2019Q1进项金额', '2019Q1进项税率', '2019Q1开票金额', '2019Q1开票数', '2019Q1开票税额',\n","                      '2019Q1开票税率', '2019Q1入库税额', '2019Q2发票核定数量', '2019Q2进项金额', '2019Q2进项税率', '2019Q2开票金额', '2019Q2开票数', '2019Q2开票税额',\n","                      '2019Q2开票税率', '2019Q2入库税额', '2019Q3发票核定数量', '2019Q3进项金额', '2019Q3进项税率', '2019Q3开票金额', '2019Q3开票数', '2019Q3开票税额',\n","                      '2019Q3开票税率', '2019Q3入库税额', '2019Q4发票核定数量', '2019Q4进项金额', '2019Q4进项税率', '2019Q4开票金额', '2019Q4开票数', '2019Q4开票税额',\n","                      '2019Q4开票税率', '2019Q4入库税额']] = train_data[['2017Q1发票核定数量', '2017Q1进项金额', '2017Q1进项税率', '2017Q1开票金额', '2017Q1开票数', '2017Q1开票税额', '2017Q1开票税率', '2017Q1入库税额',\n","                      '2017Q2发票核定数量', '2017Q2进项金额', '2017Q2进项税率', '2017Q2开票金额', '2017Q2开票数', '2017Q2开票税额', \n","                      '2017Q2开票税率', '2017Q2入库税额', '2017Q3发票核定数量', '2017Q3进项金额', '2017Q3进项税率', '2017Q3开票金额', '2017Q3开票数', '2017Q3开票税额', \n","                      '2017Q3开票税率', '2017Q3入库税额', '2017Q4发票核定数量', '2017Q4进项金额', '2017Q4进项税率', '2017Q4开票金额', '2017Q4开票数', '2017Q4开票税额',\n","                      '2017Q4开票税率', '2017Q4入库税额', '2018Q1发票核定数量', '2018Q1进项金额', '2018Q1进项税率', '2018Q1开票金额', '2018Q1开票数', '2018Q1开票税额',\n","                      '2018Q1开票税率', '2018Q1入库税额', '2018Q2发票核定数量', '2018Q2进项金额', '2018Q2进项税率', '2018Q2开票金额', '2018Q2开票数', '2018Q2开票税额', \n","                      '2018Q2开票税率', '2018Q2入库税额', '2018Q3发票核定数量', '2018Q3进项金额', '2018Q3进项税率', '2018Q3开票金额', '2018Q3开票数', '2018Q3开票税额',\n","                      '2018Q3开票税率', '2018Q3入库税额', '2018Q4发票核定数量', '2018Q4进项金额', '2018Q4进项税率', '2018Q4开票金额', '2018Q4开票数', '2018Q4开票税额', \n","                      '2018Q4开票税率', '2018Q4入库税额', '2019Q1发票核定数量', '2019Q1进项金额', '2019Q1进项税率', '2019Q1开票金额', '2019Q1开票数', '2019Q1开票税额',\n","                      '2019Q1开票税率', '2019Q1入库税额', '2019Q2发票核定数量', '2019Q2进项金额', '2019Q2进项税率', '2019Q2开票金额', '2019Q2开票数', '2019Q2开票税额',\n","                      '2019Q2开票税率', '2019Q2入库税额', '2019Q3发票核定数量', '2019Q3进项金额', '2019Q3进项税率', '2019Q3开票金额', '2019Q3开票数', '2019Q3开票税额',\n","                      '2019Q3开票税率', '2019Q3入库税额', '2019Q4发票核定数量', '2019Q4进项金额', '2019Q4进项税率', '2019Q4开票金额', '2019Q4开票数', '2019Q4开票税额',\n","                      '2019Q4开票税率', '2019Q4入库税额']].fillna(0.0).astype(\"float64\")\n","\n","nanmap = train_data.isnull()\n","\n","tempcol = { '从业人数', '注册资本（元）'}\n","# !pip install xgboost\n","# import xgboost as xgb\n","from sklearn.ensemble import RandomForestRegressor\n","\n","import random\n","\n","nancols = dict(np.sum(train_data.isnull()))\n","regrmem = {}\n","flg = True\n","for i in range(1):\n","    tempcol = list(tempcol)\n","    random.shuffle(list(tempcol))\n","    for col in tempcol:\n","        \n","        temp = set(tempcol)\n","        a = list(temp-{col})\n","        mask = nanmap[col]\n","        if nancols[col] == 0:\n","            continue\n","        if col not in regrmem:\n","            tempX =  train_data[a].fillna(0.0).astype(\"float64\").values\n","            tempy =  train_data[col].fillna(0.0).astype(\"float64\").values\n","#             regr = xgb.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=160, silent=False, objective='reg:gamma')\n","            regr = RandomForestRegressor(max_depth=3, random_state=0)\n","            regr.fit(tempX, tempy)\n","            regrmem[col] = regr\n","        else :\n","            regr = regrmem[col]\n","        limb = train_data.loc[mask][a].copy()\n","        if flg:\n","            for col0 in limb.columns:\n","                if nancols[col0] == 0:\n","                    continue\n","                limb.loc[:,col0] = limb[col0].fillna(np.median(train_data[col0].fillna(0.0).astype(\"float64\").values))\n","            flg = False\n","        pred = regr.predict(limb.fillna(0.0).astype(\"float64\").values)\n","        train_data.loc[mask,col] = pred\n","        \n","\n","\n","\n","def fill(a,b):\n","    train_data.loc[nanmap[a],a] = train_data.loc[nanmap[a],b]\n","\n","fill(\"财务人员姓名\",\"财务人员手机号\")\n","fill(\"法定代表人姓名\",\"法人手机号\")\n","fill(\"经营范围\",\"行业\")\n","\n","import time\n","from random import randint\n","def func(x):\n","    return randint(0,int(time.time())) % 999999\n","\n","train_data.loc[nanmap[\"生产经营地址\"],\"生产经营地址\"] = train_data.loc[nanmap[\"生产经营地址\"],\"生产经营地址\"].apply(func)\n","train_data.loc[nanmap[\"注册地址\"],\"注册地址\"] = train_data.loc[nanmap[\"注册地址\"],\"注册地址\"].apply(func)\n","train_data.loc[nanmap[\"街道乡镇\"],\"街道乡镇\"] = \"芜湖市\"\n","\n","# train_data.loc[nanmap[\"从业人数\"],\"从业人数\"] = train_data.loc[~nanmap[\"从业人数\"],\"从业人数\"].median()\n","# train_data.loc[nanmap[\"注册资本（元）\"],\"注册资本（元）\"] = train_data.loc[~nanmap[\"注册资本（元）\"],\"注册资本（元）\"].median()\n","\n","train_data = train_data.fillna(0.0)\n","\n","pureShape = pureShape[0]\n"],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (2.4)\n","Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx) (4.4.0)\n"]}],"metadata":{},"execution_count":5,"source":["!pip install networkx\n","tester = {} #测试集中\"纳税人识别号\"到\"是否异常\"的映射\n","for item in test_data.values:\n","    tester[item[1]] = int(item[0])\n","NSRSBH = {} #训练集中\"纳税人识别号\"到\"行号\"的映射\n","for ix,item in enumerate(train_data[\"主键:纳税人识别号\"].values):\n","    NSRSBH[item] = int(ix)\n","fake = train_data.iloc[:pureShape,:][test_data[\"异常\"] == \"1\"]"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":6,"source":["def cut(x):\n","    return str(x).replace(\"。\",\" \").replace(\"，\",\" \").replace(\"、\",\" \").replace(\"\\\"\",\"\").split(\" \")\n","names = [\"行业门类\",\"行业大类\",\"行业中类\",\"行业\"]\n","highRisk = {}\n","for name in names:\n","    temp = {}\n","    for item in fake[name].values:\n","        if item in temp:\n","            temp[item] += 1\n","        else :\n","            temp[item] = 1\n","    for item in temp:\n","        temp[item] /= len(fake)\n","    highRisk[name] = temp\n","temp = {}\n","count = 0\n","for ix in fake[\"经营范围\"].values:\n","    for item in cut(ix):\n","        count += 1\n","        if item in temp:\n","            temp[item] += 1\n","        else :\n","            temp[item] = 1\n","for item in temp:\n","        temp[item] /= len(fake)\n","highRisk[\"经营范围\"] = temp\n","busyItems = {}\n","for i in train_data[[\"主键:纳税人识别号\",\"经营范围\"]].values:\n","    busyItems[i[0]] = len(cut(i[1]))"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":7,"source":["friends = train_data[[\"财务人员姓名\",\"法定代表人姓名\"]].values\n","dicts = {}\n","persons = {}\n","\n","for item in friends:\n","    temp = tuple(item)\n","\n","    if temp[0] not in persons:\n","        persons[temp[0]] = [1,0]\n","    else :\n","        persons[temp[0]][0] += 1\n","    if temp[1] not in persons:\n","        persons[temp[1]] = [0,1]\n","    else :\n","        persons[temp[0]][1] += 1\n","    tempR = temp[::-1]\n","    if temp in dicts:\n","        dicts[temp] += 1\n","    elif tempR in dicts:\n","        dicts[tempR] += 1\n","    elif  temp not in dicts and tempR not in dicts:\n","        dicts[temp] = 1\n","\n","vertex = persons.keys()\n","\n","import networkx as nx\n","from networkx.algorithms import community,shortest_path_length\n","graph = nx.Graph()\n","graph.add_nodes_from(list(vertex))\n","graph.add_edges_from(list(dicts.keys()))\n","\n","comm_gen = community.label_propagation_communities(graph)\n","\n","\n","companymapper = {} # 个人反查团伙编号\n","\n","company = [] #团伙名单\n","count = 0\n","for i in comm_gen:\n","    for j in i:\n","        companymapper[j] = count\n","    count += 1\n","    company.append(tuple(i))\n","\n","\n","\n","malicious = {} #犯罪可能性\n","crims = {}\n","badguy = list(fake[\"财务人员姓名\"])+list(fake[\"法定代表人姓名\"])\n","for i in badguy:\n","    if i in crims:\n","       crims[i] += 1\n","    else :\n","         crims[i] = 1\n","def get_crims(i):\n","    if i in crims:\n","        return crims[i] - 1\n","    else:\n","        return 0\n","\n","for crim in crims:\n","    friend = company[companymapper[crim]]\n","    for name in friend:\n","        if name not in malicious:\n","            malicious[name] = shortest_path_length(graph,name,crim)\n","        else:\n","            malicious[name] = min(malicious[name],shortest_path_length(graph,name,crim))\n","highRisk[\"人员\"] = list(crims)\n","\n","telnum = {} #统计手机号\n","for temp in [[\"财务人员姓名\",\"财务人员手机号\"],[\"法定代表人姓名\",\"法人手机号\"]]:\n","    for item in train_data[temp].values:\n","        if item[0] in telnum:\n","            telnum[item[0]][\"sum\"] += 1\n","            telnum[item[0]][\"nums\"].append(item[1])\n","        else:\n","            telnum[item[0]] = {\"sum\":1,\"nums\":[item[1],]}\n","for person in persons:\n","    persons[person].append(telnum[person][\"sum\"])"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":8,"source":["sign_times = {}\n","capitals = {}\n","friend_companies = {}\n","for i in train_data[[\"财务人员姓名\",\"法定代表人姓名\",\"注册资本（元）\",\"登记开业日期\"]].fillna(0.0).values:\n","    if i[2] == \"\":\n","        i[2] = 0.0\n","    company_temp = tuple(company[companymapper[i[0]]])\n","    if i[0] in capitals:\n","        capitals[i[0]].append(i[2])\n","    else:\n","        capitals[i[0]] = [i[2],]\n","    if i[1] in capitals:\n","        capitals[i[1]].append(i[2])\n","    else:\n","        capitals[i[1]] = [i[2],]\n","    if company_temp in capitals:\n","        capitals[company_temp].append(i[2])\n","    else:\n","        capitals[company_temp]= [i[2],]\n","    if company_temp in friend_companies:\n","        friend_companies[company_temp] += 1\n","    else:\n","        friend_companies[company_temp] = 1 \n","    if i[0] in sign_times:\n","        sign_times[i[0]].append(i[3])\n","    else:\n","        sign_times[i[0]] = [i[3],]\n","    if i[1] in sign_times:\n","        sign_times[i[1]].append(i[3])\n","    else:\n","        sign_times[i[1]] = [i[3],]\n","    if company_temp in sign_times:\n","        sign_times[company_temp].append(i[3])\n","    else:\n","        sign_times[company_temp]= [i[3],]"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":9,"source":["\n","\n","wrongInhabite_addrs = set()\n","def iswrongInhabite(addr):\n","    addr = str(addr)\n","    if addr in wrongInhabite_addrs:\n","        return 1\n","    for item in (\"小区\",\"公寓\",\"花园\",\"社区\",\"村\",\"栋\",\"幢\",\"室\"):\n","        if addr.find(item) != -1:\n","            wrongInhabite_addrs.add(addr)\n","            return 1\n","    return 0\n","\n","address = {}\n","wrongInhabite = {}\n","for i in train_data[[\"注册地址\",\"生产经营地址\",\"主键:纳税人识别号\"]].values:\n","    if i[0] in address:\n","        address[i[0]] += 1\n","    else :\n","        address[i[0]] = 1\n","    if i[0] != i[1]:\n","        if i[1] in address:\n","            address[i[1]] += 1\n","        else :\n","            address[i[1]] = 1\n","    if i[0] == i[1]:\n","        wrongInhabite[i[2]] = iswrongInhabite(i[0])\n","    else:\n","        wrongInhabite[i[2]] = max(iswrongInhabite(i[0]),iswrongInhabite(i[1]))\n","\n","entity_data = train_data[[\"主键:纳税人识别号\",]]\n","\n","# entity_data[\"住宅办公\"] = train_data[\"主键:纳税人识别号\"].map(wrongInhabite)\n","# entity_data[\"注册地址重复\"] = train_data[\"注册地址\"].map(address)\n","# entity_data[\"生产经营地址重复\"] = train_data[\"生产经营地址\"].map(address)\n","# entity_data[\"行业门类风险\"] = train_data[\"行业门类\"].map(highRisk[\"行业门类\"])\n","# entity_data[\"行业大类风险\"] = train_data[\"行业大类\"].map(highRisk[\"行业大类\"])\n","# entity_data[\"行业中类风险\"] = train_data[\"行业中类\"].map(highRisk[\"行业中类\"])\n","# entity_data[\"行业风险\"] = train_data[\"行业\"].map(highRisk[\"行业\"])\n","# entity_data[\"经营范围项数\"] = train_data[\"经营范围\"].apply(lambda x : len(cut(x)))\n","# entity_data[\"关联公司数\"] = train_data[\"法定代表人姓名\"].apply(lambda x:friend_companies[company[companymapper[x]]])\n","entity_data = entity_data.fillna(0.0)"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":10,"source":["# degree_centralities = nx.degree_centrality(graph)\n","risks = {}\n","\n","for item in train_data[[\"财务人员姓名\",\"法定代表人姓名\",\"行业大类\"]].values:\n","    company_temp = tuple(company[companymapper[item[0]]])\n","    if item[2] in highRisk[\"行业大类\"]:\n","        if item[0] in risks:\n","            risks[item[0]].append(highRisk[\"行业大类\"][item[2]]) \n","        else :\n","            risks[item[0]] = [highRisk[\"行业大类\"][item[2]],]\n","        if item[1] in risks :\n","            risks[item[1]].append(highRisk[\"行业大类\"][item[2]]) \n","        else:\n","            risks[item[1]] = [highRisk[\"行业大类\"][item[2]],]\n","        if company_temp in risks:\n","            risks[company_temp].append(highRisk[\"行业大类\"][item[2]]) \n","        else:\n","             risks[company_temp] = [highRisk[\"行业大类\"][item[2]],]\n","\n","companySignTimes = {}\n","\n","\n","for person in persons:\n","    company_temp = tuple(company[companymapper[person]])\n","    company_capital = pd.DataFrame(capitals[company_temp]).fillna(0.0).astype(\"float64\").values\n","    person_capital = pd.DataFrame(capitals[person]).fillna(0.0).astype(\"float64\").values\n","    persons[person].append(len(company_temp))\n","    persons[person].append(friend_companies[company_temp])# 团队涉及公司数\n","    person_sign_times = pd.to_datetime(sign_times[person])\n","\n","    if len(person_sign_times) == 1:\n","        persons[person].append(365.0)\n","    else:\n","        persons[person].append((np.max(person_sign_times)-np.min(person_sign_times)).days/len(person_sign_times))\n","    if company_temp in companySignTimes:\n","        persons[person].append(companySignTimes[company_temp])\n","    else:\n","        company_sign_times = pd.to_datetime(sign_times[company_temp])\n","\n","        if len(company_sign_times) == 1:\n","            companySignTime = 365.0\n","        else:\n","            companySignTime = (np.max(company_sign_times)-np.min(company_sign_times)).days/len(company_sign_times)   \n","        companySignTimes[company_temp] = companySignTime\n","        persons[person].append(companySignTime)\n","    persons[person].append(np.mean(person_capital))\n","    persons[person].append(np.median(person_capital))\n","    persons[person].append(np.var(person_capital) ** (1/2))\n","    persons[person].append(np.mean(company_capital))\n","    persons[person].append(np.median(company_capital))\n","    persons[person].append(np.var(company_capital)** (1/2)) \n","    if person in risks:\n","        persons[person].append(np.sum(risks[person]))\n","    else :\n","        persons[person].append(0.0)\n","    if company_temp in risks:\n","        persons[person].append(np.sum(risks[company_temp]))\n","    else:\n","        persons[person].append(0.0)\n","    if person in malicious:\n","        persons[person].append(np.e ** (- malicious[person] + get_crims(person)))\n","    else:\n","        persons[person].append(0.0)\n","    #persons[person].append(degree_centralities[person])\n","\n"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":11,"source":["df = pd.DataFrame(persons)\n","persons_df = pd.DataFrame(df.values.T, index=df.columns, columns=[\"担任法人次数\",\"担任财务次数\",\"手机号数\",\"团队规模\",\"团队涉及公司数\",\"个人涉及公司注册间隔\",\"团队涉及公司注册间隔\",\"个人均值\",\"个人中值\",\"个人标准差\",\"团队均值\",\"团队中值\",\"团队标准差\",\"个人风险\",\"团队风险\",\"涉嫌可能\"])#,\"点度中心性\"\n","persons_df[\"同时担任法人和财务\"] = (persons_df[\"担任法人次数\"] != 0) & (persons_df[\"担任财务次数\"] != 0)\n","persons_df[\"姓名\"] = persons_df.index"],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stderr","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:148: RuntimeWarning: divide by zero encountered in true_divide\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:148: RuntimeWarning: invalid value encountered in true_divide\n"]}],"metadata":{},"execution_count":12,"source":["\n","import datetime\n","def ZongShuBiLi(arr):\n","    maxcount=0\n","    size=0\n","    d=dict()\n","    for i in arr:\n","        if i>0:\n","            size+=1\n","            if i in d:\n","                d[i]+=1\n","            else:\n","                d[i]=1\n","    if size<3:\n","        return 0,0\n","    for i in d:\n","        if d[i]>maxcount:\n","            maxcount=d[i]\n","    return maxcount/size,maxcount/12\n","            \n","def fapiaopingjunjiner(col1,col2):\n","    '''\n","    @col1:string:本季开票数，col2:string:开票金额\n","    '''\n","    N=output.shape[0]\n","    p=output.shape[1]\n","    output.insert(output.shape[1],col1[0:-1]+'均值',[0]*N)\n","    for i in range(0,N) :\n","        try:\n","            if float(train_data.loc[i,col1])!=0.0:\n","\n","                output.iloc[i,p]=float(train_data.loc[i,col2])/float(train_data.loc[i,col1])\n","        except Exception as ex_results:\n","            pass\n","    return\n","def shuiErPinLv():\n","    '''@开票税率与进项税率众数所占的频率，将2次及以下的开票频率置位 0'''\n","    N=output.shape[0]\n","    p=output.shape[1]\n","    output.insert(p,'开票税率众数频率（占非零频率）',[0]*N)\n","    output.insert(p+1,'开票税率众数频率（占全部频率）',[0]*N)\n","    output.insert(p+2,'进项税率众数频率（占非零频率）',[0]*N)\n","    output.insert(p+3,'进项税率众数频率（占全部频率）',[0]*N)\n","    for i in range(0,N) :\n","        arr=train_data.loc[i,['2017Q1开票税率','2017Q2开票税率','2017Q3开票税率','2017Q4开票税率','2018Q1开票税率','2018Q2开票税率','2018Q3开票税率',\\\n","                     '2018Q4开票税率','2019Q1开票税率','2019Q2开票税率','2019Q3开票税率','2019Q4开票税率']].astype(\"float64\").values\n","        output.iloc[i,p],output.iloc[i,p+1]=ZongShuBiLi(arr)\n","        arr=train_data.loc[i,['2017Q1进项税率','2017Q2进项税率','2017Q3进项税率','2017Q4进项税率','2018Q1进项税率','2018Q2进项税率','2018Q3进项税率',\\\n","                     '2018Q4进项税率','2019Q1进项税率','2019Q2进项税率','2019Q3进项税率','2019Q4进项税率']].astype(\"float64\").values\n","        output.iloc[i,p+2],output.iloc[i,p+3]=ZongShuBiLi(arr)\n","    return\n","def aboutZhuCeZibenAndShiJian():\n","    '''纳税额、入账、发票与注册资本，纳税额、入账、发票与注册时间，注册资本/注册时间'''\n","    N=output.shape[0]\n","    p=output.shape[1]\n","    output.insert(p,'入库税额/注册资本',[0]*N)\n","    output.insert(p+1,'开票税额/注册资本',[0]*N)\n","    output.insert(p+2,'进项税额/注册资本',[0]*N)\n","    output.insert(p+3,'入库税额/注册时间',[0]*N)\n","    output.insert(p+4,'开票税额/注册时间',[0]*N)\n","    output.insert(p+5,'进项税额/注册时间',[0]*N)\n","    output.insert(p+6,'注册资本/注册时间',[0]*N)\n","    for i in range(0,N) :\n","        if float(output.loc[i,'注册资本（元）'])>0:\n","            output.iloc[i ,p],output.iloc[i ,p+1],output.iloc[i ,p+2]=output.loc[i,'总入库税额']/float(output.loc[i,'注册资本（元）']),output.loc[i,'总开票税额']/float(output.loc[i,'注册资本（元）']),output.loc[i,'总进项税额']/float(output.loc[i,'注册资本（元）'])\n","        if output.loc[i,'至2020年开业天数']>0:\n","            output.iloc[i ,p+3],output.iloc[i ,p+4],output.iloc[i ,p+5]=output.loc[i,'总入库税额']/output.loc[i,'至2020年开业天数'],output.loc[i,'总开票税额']/output.loc[i,'至2020年开业天数'],output.loc[i,'总进项税额']/output.loc[i,'至2020年开业天数']\n","            output.iloc[i ,p+6]=float(output.loc[i,'注册资本（元）'])/output.loc[i,'至2020年开业天数']\n","    return\n","def ruKuShuiErPerKaiPiaoShuiEr():\n","    '''@所有季度入库总税额与开票总税额的比例、进项税额'''\n","    N=output.shape[0]\n","    p=output.shape[1]\n","    output.insert(p,'入库税额/开票税额',[0]*N)\n","    output.insert(p+1,'总入库税额',[0]*N)\n","    output.insert(p+2,'总开票税额',[0]*N)\n","    output.insert(p+3,'总进项税额',[0]*N)\n","    for i in range(0,N) :\n","        arrkaipiao=train_data.loc[i,['2017Q1开票税额','2017Q2开票税额','2017Q3开票税额','2017Q4开票税额','2018Q1开票税额','2018Q2开票税额','2018Q3开票税额','2018Q4开票税额','2019Q1开票税额','2019Q2开票税额','2019Q3开票税额','2019Q4开票税额']].astype(\"float64\").values\n","        arrruku=train_data.loc[i,['2017Q1入库税额','2017Q2入库税额','2017Q3入库税额','2017Q4入库税额','2018Q1入库税额','2018Q2入库税额','2018Q3入库税额',\\\n","                     '2018Q4入库税额','2019Q1入库税额','2019Q2入库税额','2019Q3入库税额','2019Q4入库税额']].astype(\"float64\").values\n","        sumruku,sumkaipiao=arrruku.sum(),arrkaipiao.sum()\n","        output.iloc[i ,p+1],output.iloc[i ,p+2]=sumruku,sumkaipiao\n","        ####计算进项税额：（进项税率!=0.03）?进项金额*进项税率：0#####################\n","        arrjinxiangjiner=train_data.loc[i,['2017Q1进项金额','2017Q2进项金额','2017Q3进项金额','2017Q4进项金额','2018Q1进项金额','2018Q2进项金额','2018Q3进项金额',\\\n","                     '2018Q4进项金额','2019Q1进项金额','2019Q2进项金额','2019Q3进项金额','2019Q4进项金额']].astype(\"float64\").values\n","        arrjinxiangshuilv=train_data.loc[i,['2017Q1进项税率','2017Q2进项税率','2017Q3进项税率','2017Q4进项税率','2018Q1进项税率','2018Q2进项税率','2018Q3进项税率',\\\n","                     '2018Q4进项税率','2019Q1进项税率','2019Q2进项税率','2019Q3进项税率','2019Q4进项税率']].astype(\"float64\").values\n","        for j in range(12):\n","            if arrjinxiangjiner[j]>0 and abs(arrjinxiangshuilv[j]-0.03)<0.000001:\n","                output.iloc[i ,p+3]+=arrjinxiangjiner[j]*arrjinxiangshuilv[j]\n","        ###################end#############################\n","        if sumkaipiao!=0:\n","            output.iloc[i ,p]=sumruku/sumkaipiao\n","    return\n","def faPiaoHeDingWithKaiPiao():\n","    '''E_月（发票增量/发票定额），不统计没有开发票的月份，对从没开过发票企业，默认值为0'''\n","    N=output.shape[0]\n","    p=output.shape[1]\n","    output.insert(p,'发票增量/发票定额',[0]*N)\n","    for i in range(0,N) :\n","        arrheding=train_data.loc[i,['2017Q1发票核定数量','2017Q2发票核定数量','2017Q3发票核定数量','2017Q4发票核定数量','2018Q1发票核定数量','2018Q2发票核定数量','2018Q3发票核定数量',\\\n","                     '2018Q4发票核定数量','2019Q1发票核定数量','2019Q2发票核定数量','2019Q3发票核定数量','2019Q4发票核定数量']].astype(\"float64\").values\n","        arrkaipiao=train_data.loc[i,['2017Q1开票数','2017Q2开票数','2017Q3开票数','2017Q4开票数','2018Q1开票数','2018Q2开票数','2018Q3开票数',\\\n","                     '2018Q4开票数','2019Q1开票数','2019Q2开票数','2019Q3开票数','2019Q4开票数']].astype(\"float64\").values\n","        arrrate=np.array([],float)\n","        for j in range(12):\n","            if arrkaipiao[j]>0:\n","                if arrheding[j]<arrkaipiao[j]:\n","                    arrrate=np.append(arrrate,(arrkaipiao[j]-arrheding[j])/arrheding[j])\n","                else:\n","                    arrrate=np.append(arrrate,0)\n","        if arrrate.size>0 and np.sum(arrrate)>0:\n","            output.iloc[i ,p]=np.mean(arrrate)\n","    return \n","def kaiyeriqi():\n","    '''至2020年1.1开业总天数'''\n","    N=output.shape[0]\n","    p=output.shape[1]\n","    output.insert(p,'至2020年开业天数',[0]*N)\n","    endday = pd.to_datetime('2020/01/01 00:00:00')\n","    for i in range(0,N) :\n","        startday=train_data.loc[i,'登记开业日期']\n","        #strdate[0:4]=b\n","        output.iloc[i ,p]=(endday-startday).days\n","    return\n","def recentfapiaoday():\n","    '''上一次开票的时间至2020年元旦之间的天数，上一次开票至元旦的天数与开业天数的比值（猜想越小越好，处理没有开票的初值为1）'''\n","    N=output.shape[0]\n","    p=output.shape[1]\n","    output.insert(p,'至上一次开发票的天数',[0]*N)\n","    output.insert(p+1,'开发票的天数与开业时间的比值',[1]*N)\n","    endday=datetime.datetime.strptime('2020/01/01 00:00:00','%Y/%m/%d %H:%M:%S')\n","    for i in range(0,N) :\n","        for j in range(11,-1,-1):\n","            a=j//4\n","            b=j%4\n","            if float(train_data.loc[i,str(a+2017)+'Q'+str(b+1)+'开票金额'])!=0:\n","                startday=datetime.datetime.strptime(str(a+2017)+'/'+str(b*3+1)+'/15 00:00:00','%Y/%m/%d %H:%M:%S')\n","                output.iloc[i ,p]=(endday-startday).days\n","                output.iloc[i ,p+1]=(endday-startday).days/output.loc[i,'至2020年开业天数']\n","                break\n","    return\n","\n","output=train_data[['主键:纳税人识别号','行业','从业人数','注册地址','经营范围','行业门类','注册资本（元）','行业大类','法人手机号','街道乡镇','生产经营地址','法定代表人姓名','行业中类','财务人员手机号','财务人员姓名']].copy(deep=True)\n","output['注册资本（元）'] = output['注册资本（元）'].fillna(0.0).apply(lambda x: 0.0 if  x == \"\" else x)\n","output['从业人数'] = output['从业人数'].fillna(0.0).apply(lambda x: 0.0 if  x == \"\" else x)\n","\n","output.insert(output.shape[1],'10w*从业人数/注册资本',100000*output.loc[:,'从业人数'].astype(\"float64\").values/output.loc[:,'注册资本（元）'].astype(\"float64\").values)\n","#计算12个季度发票的平均金额\n","for i in range(12):\n","    a=i//4\n","    b=i%4\n","    fapiaopingjunjiner(str(a+2017)+'Q'+str(b+1)+'开票数',str(a+2017)+'Q'+str(b+1)+'开票金额')\n","    #output=pd.concat([output,df1],axis=1,keys='主键:纳税人识别号')\n","    #output.join(df1,on='主键:纳税人识别号')\n","    #output=pd.merge(output,df1,on='主键:纳税人识别号',how='inner')\n","\n","#计算在季度间平均每张发票金额的平均值\n","a=np.mean(output.loc[:,['2017Q1开票均值','2017Q2开票均值','2017Q3开票均值','2017Q4开票均值','2018Q1开票均值','2018Q2开票均值','2018Q3开票均值',\\\n","                     '2018Q4开票均值','2019Q1开票均值','2019Q2开票均值','2019Q3开票均值','2019Q4开票均值']].astype(\"float64\"),axis=1)\n","output.insert(output.shape[1],'开票平均金额的均值',a)\n","#计算发票平均金额标准差，要考虑到注册时间在17年以后的情况\n","a=np.std(output.loc[:,['2017Q1开票均值','2017Q2开票均值','2017Q3开票均值','2017Q4开票均值','2018Q1开票均值','2018Q2开票均值','2018Q3开票均值',\\\n","                     '2018Q4开票均值','2019Q1开票均值','2019Q2开票均值','2019Q3开票均值','2019Q4开票均值']].astype(\"float64\"),axis=1)\n","output.insert(output.shape[1],'开票平均金额的标准差',a)\n","#计算季度间开票金额的均值\n","a=np.mean(train_data.loc[:,['2017Q1开票金额','2017Q2开票金额','2017Q3开票金额','2017Q4开票金额','2018Q1开票金额','2018Q2开票金额','2018Q3开票金额',\\\n","                     '2018Q4开票金额','2019Q1开票金额','2019Q2开票金额','2019Q3开票金额','2019Q4开票金额']].astype(\"float64\"),axis=1)\n","output.insert(output.shape[1],'季度间开票金额的均值',a)\n","#计算季度间开票金额的标准差\n","a=np.std(train_data.loc[:,['2017Q1开票金额','2017Q2开票金额','2017Q3开票金额','2017Q4开票金额','2018Q1开票金额','2018Q2开票金额','2018Q3开票金额',\\\n","                     '2018Q4开票金额','2019Q1开票金额','2019Q2开票金额','2019Q3开票金额','2019Q4开票金额']].astype(\"float64\"),axis=1)\n","output.insert(output.shape[1],'季度间开票金额的标准差',a)\n","#计算开业日期\n","kaiyeriqi()\n","#距离上一次开发票的天数,及其与开业天数的比值\n","recentfapiaoday()\n","#开票税率与进项税率众数所占的频率\n","shuiErPinLv()\n","#所有季度入库总税额与开票总税额的比例\n","ruKuShuiErPerKaiPiaoShuiEr()\n","#发票核定数与开票数的差异\n","faPiaoHeDingWithKaiPiao()\n","#与注册资本和注册时间相关的比值\n","aboutZhuCeZibenAndShiJian()\n","aaa=1\n","\n","# train_data  =  train_data0.copy()"],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stderr","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  # Remove the CWD from sys.path while we load stuff.\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  # This is added back by InteractiveShellApp.init_path()\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  if sys.path[0] == '':\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  del sys.path[0]\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  \n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  from ipykernel import kernelapp as app\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","  app.launch_new_instance()\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n","/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"]}],"metadata":{},"execution_count":25,"source":["output1 = output[[\"主键:纳税人识别号\",\"法定代表人姓名\",\"财务人员姓名\",\"从业人数\",\"注册资本（元）\",\"10w*从业人数/注册资本\", '2017Q1开票均值', '2017Q2开票均值', '2017Q3开票均值', '2017Q4开票均值',\n","       '2018Q1开票均值', '2018Q2开票均值', '2018Q3开票均值', '2018Q4开票均值', '2019Q1开票均值',\n","       '2019Q2开票均值', '2019Q3开票均值', '2019Q4开票均值', '开票平均金额的均值', '开票平均金额的标准差',\n","       '季度间开票金额的均值', '季度间开票金额的标准差', '至2020年开业天数', '至上一次开发票的天数',\n","       '开发票的天数与开业时间的比值', '开票税率众数频率（占非零频率）', '开票税率众数频率（占全部频率）',\n","       '进项税率众数频率（占非零频率）', '进项税率众数频率（占全部频率）', '入库税额/开票税额', '总入库税额', '总开票税额',\n","       '总进项税额', '发票增量/发票定额', '入库税额/注册资本', '开票税额/注册资本', '进项税额/注册资本',\n","       '入库税额/注册时间', '开票税额/注册时间', '进项税额/注册时间', '注册资本/注册时间']]\n","\n","output1[\"住宅办公\"] = train_data[\"主键:纳税人识别号\"].map(wrongInhabite)\n","output1[\"注册地址重复\"] = train_data[\"注册地址\"].map(address)\n","output1[\"生产经营地址重复\"] = train_data[\"生产经营地址\"].map(address)\n","output1[\"行业门类风险\"] = train_data[\"行业门类\"].map(highRisk[\"行业门类\"])\n","output1[\"行业大类风险\"] = train_data[\"行业大类\"].map(highRisk[\"行业大类\"])\n","output1[\"行业中类风险\"] = train_data[\"行业中类\"].map(highRisk[\"行业中类\"])\n","output1[\"行业风险\"] = train_data[\"行业\"].map(highRisk[\"行业\"])\n","output1[\"经营范围项数\"] = train_data[\"经营范围\"].apply(lambda x : len(cut(x)))\n","output1[\"关联公司数\"] = train_data[\"法定代表人姓名\"].apply(lambda x:friend_companies[company[companymapper[x]]])\n","\n","output1 = output1.join(persons_df[['担任法人次数', '担任财务次数', '手机号数', '团队规模', '团队涉及公司数', '个人涉及公司注册间隔',\n","       '团队涉及公司注册间隔', '个人均值', '个人中值', '个人标准差', '团队均值', '团队中值', '团队标准差', '个人风险',\n","       '团队风险', '同时担任法人和财务']].astype(\"float64\"),on='法定代表人姓名')\n","output1 = output1.join(persons_df[['担任法人次数', '担任财务次数', '手机号数','个人涉及公司注册间隔','个人均值', '个人中值', '个人标准差','个人风险', '同时担任法人和财务']].astype(\"float64\"),on='财务人员姓名',rsuffix=\"_财务\")\n","output1.drop([\"法定代表人姓名\",\"财务人员姓名\"],axis= 1,inplace=True)\n","output1.fillna(0.0)\n","DATA0 = output1"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":26,"source":["\n","\n","convs = train_data[train_data.columns[0:96]].fillna(0.0).astype(\"float64\").copy()\n","\n","tik = 0.0\n","\n","quater = []\n","for i in [\"201\"+str(i) for i in range(7,10)]:\n","    for j in range(1,5):\n","        quater.append(i+'Q'+str(j))\n","for qua in quater:\n","    convs[qua+\"版面\"] = (convs[qua+\"开票金额\"] / convs[qua+\"开票数\"]).fillna(0.0).apply(lambda x:tik if x == np.inf else x).astype(\"float64\")\n","    convs[qua+\"进出比\"] = (convs[qua+\"开票金额\"] / convs[qua+\"进项金额\"]).fillna(0.0).apply(lambda x:tik if x == np.inf else x).astype(\"float64\")\n","    convs[qua+\"开入比\"] = (convs[qua+\"开票税额\"] / convs[qua+\"入库税额\"]).fillna(0.0).apply(lambda x:tik if x == np.inf else x).astype(\"float64\")\n","    convs[qua+\"进项税额\"] = (convs[qua+\"进项金额\"] * convs[qua+\"进项税率\"]).fillna(0.0).apply(lambda x:tik if x == np.inf else x).astype(\"float64\")\n","    convs[qua+\"进入比\"] = (convs[qua+\"进项税额\"] / convs[qua+\"入库税额\"]).fillna(0.0).apply(lambda x:tik if x == np.inf else x).astype(\"float64\")\n","    convs[qua+\"增量\"] = (convs[qua+\"开票数\"] / convs[qua+\"发票核定数量\"]).fillna(0.0).apply(lambda x:tik if x == np.inf else x).astype(\"float64\")\n","    convs[qua+\"进出税率比\"] = (convs[qua+\"进项税率\"] / convs[qua+\"开票税率\"]).fillna(0.0).apply(lambda x:tik if x == np.inf else x).astype(\"float64\")\n","    convs[qua+\"未缴税额\"] = (convs[qua+\"开票税额\"] - convs[qua+\"进项税额\"] - convs[qua+\"入库税额\"]).fillna(0.0).apply(lambda x:tik if x == np.inf else x).astype(\"float64\")\n","feature_len = int(len(convs.columns)/12)\n","\n","convs[\"行业\"] = train_data[\"行业\"]\n","hys = np.unique(train_data[\"行业\"].values)\n","hydf = pd.DataFrame()\n","for hy in hys:\n","    hydf[hy] = convs[convs[\"行业\"] == hy][convs.columns[0:feature_len * 12]].mean()\n","\n","hydf = pd.DataFrame(hydf.values.T,columns = hydf.index,index = hydf.columns)\n","hydf[\"行业\"] = hydf.index\n","convs = convs.join(hydf,on = \"行业\",rsuffix=\"_所在行业\")\n","convs.drop(columns=[\"行业\",\"行业_所在行业\"],inplace=True)\n","\n","convs = convs[sorted(list(convs.columns))]\n","feature_len = int(len(convs.columns)/12)\n","\n","purecols = [i.replace(\"2017Q1\",\"\") for i in convs.columns[0:feature_len]]\n","# purecols = [\"进项金额\"]\n","for qua in quater:\n","    for purecol in purecols[::2]:\n","        convs[qua+purecol+\"_所在行业\"] =  (convs[qua+purecol] /convs[qua+purecol+\"_所在行业\"] ).fillna(0.0).apply(lambda x:0 if x == np.inf else x).astype(\"float64\")\n","\n","feature_len = int(len(convs.columns)/12)\n","\n","y = test_data[\"异常\"].astype(\"float64\").values\n","\n","# purecols = [i.replace(\"2017Q1\",\"\") for i in convs.columns[0:feature_len]]\n","purecols = []\n","DATA = DATA0.copy()\n","for col in purecols[::2]:\n","    DATA[col+\"标准差\"] = convs[[qua +col for qua in quater]].fillna(0.0).astype(\"float64\").var(axis = 1) \n","\n","input_cols = ['2017Q1开票均值',\n","       '2017Q2开票均值', '2017Q3开票均值', '2017Q4开票均值', '2018Q1开票均值', '2018Q2开票均值',\n","       '2018Q3开票均值', '2018Q4开票均值', '2019Q1开票均值', '2019Q2开票均值', '2019Q3开票均值',\n","       '2019Q4开票均值', '开票平均金额的均值', '开票平均金额的标准差', '季度间开票金额的均值', '季度间开票金额的标准差',\n","       '至2020年开业天数', '至上一次开发票的天数', '开发票的天数与开业时间的比值', '开票税率众数频率（占非零频率）',\n","       '开票税率众数频率（占全部频率）', '进项税率众数频率（占非零频率）', '进项税率众数频率（占全部频率）', '入库税额/开票税额',\n","       '总入库税额', '总开票税额', '总进项税额', '发票增量/发票定额', '开票税额/注册时间', '进项税额/注册时间','行业门类风险', '行业大类风险',\n","              '行业中类风险', '行业风险',]+ [col+\"标准差\" for col in purecols[::2]]\n","X = DATA[input_cols].iloc[:pureShape,].fillna(0.0).astype(\"float64\").values\n","\n","\n","conv_X = convs.iloc[:pureShape,0:feature_len * 12].fillna(0.0).astype(\"float64\").values.reshape((-1,feature_len,12))\n","probe = DATA[input_cols].iloc[pureShape:,].fillna(0.0).astype(\"float64\").values\n","probe_conv = convs.iloc[pureShape:,0:feature_len * 12].fillna(0.0).astype(\"float64\").values.reshape((-1,feature_len,12))\n","\n","# a = X[y == 1].copy()\n","# b = conv_X[y == 1].copy()\n","# tims = np.sum(y == 0) // np.sum(y == 1)\n","# for i in range(0,1):\n","#     X = np.vstack((X,a))\n","#     y = np.hstack((y,np.array([1.0,] * 1000)))\n","#     conv_X = np.vstack((conv_X,b))\n","\n","\n"],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n","Requirement already satisfied: tensorflow in /opt/conda/lib/python3.7/site-packages (2.0.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.16.4)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.1.8)\n","Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.8.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.20.0)\n","Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.0.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.0.8)\n","Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.9.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (3.7.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (0.33.4)\n","Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.11.2)\n","Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (41.0.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (1.10.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0.0)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.25.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.6.16)\n","Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.2)\n","Model: \"model_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input1 (InputLayer)             [(None, 32, 12)]     0                                            \n","__________________________________________________________________________________________________\n","input4 (InputLayer)             [(None, 32, 12, 1)]  0                                            \n","__________________________________________________________________________________________________\n","conv1d_30 (Conv1D)              (None, 31, 256)      6400        input1[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 30, 10, 64)   640         input4[0][0]                     \n","__________________________________________________________________________________________________\n","conv1d_31 (Conv1D)              (None, 30, 256)      131328      conv1d_30[0][0]                  \n","__________________________________________________________________________________________________\n","input3 (InputLayer)             [(None, 12, 32)]     0                                            \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 28, 8, 32)    18464       conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_32 (Conv1D)              (None, 29, 128)      65664       conv1d_31[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_34 (Conv1D)              (None, 11, 128)      8320        input3[0][0]                     \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 26, 6, 32)    9248        conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","conv1d_33 (Conv1D)              (None, 28, 128)      32896       conv1d_32[0][0]                  \n","__________________________________________________________________________________________________\n","input2 (InputLayer)             [(None, 34)]         0                                            \n","__________________________________________________________________________________________________\n","conv1d_35 (Conv1D)              (None, 10, 128)      32896       conv1d_34[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_5 (MaxPooling2D)  (None, 13, 3, 32)    0           conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","global_average_pooling1d_10 (Gl (None, 128)          0           conv1d_33[0][0]                  \n","__________________________________________________________________________________________________\n","dense_26 (Dense)                (None, 64)           2240        input2[0][0]                     \n","__________________________________________________________________________________________________\n","global_average_pooling1d_11 (Gl (None, 128)          0           conv1d_35[0][0]                  \n","__________________________________________________________________________________________________\n","flatten_10 (Flatten)            (None, 1248)         0           max_pooling2d_5[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_5 (Concatenate)     (None, 1568)         0           global_average_pooling1d_10[0][0]\n","                                                                 dense_26[0][0]                   \n","                                                                 global_average_pooling1d_11[0][0]\n","                                                                 flatten_10[0][0]                 \n","__________________________________________________________________________________________________\n","flatten_11 (Flatten)            (None, 1568)         0           concatenate_5[0][0]              \n","__________________________________________________________________________________________________\n","dense_27 (Dense)                (None, 128)          200832      flatten_11[0][0]                 \n","__________________________________________________________________________________________________\n","dense_28 (Dense)                (None, 128)          16512       dense_27[0][0]                   \n","__________________________________________________________________________________________________\n","dense_29 (Dense)                (None, 128)          16512       dense_28[0][0]                   \n","__________________________________________________________________________________________________\n","output (Dense)                  (None, 1)            129         dense_29[0][0]                   \n","==================================================================================================\n","Total params: 542,081\n","Trainable params: 542,081\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Train on 11993 samples\n","Epoch 1/55\n","11993/11993 [==============================] - 9s 727us/sample - loss: 10553.0618 - accuracy: 0.9711\n","Epoch 2/55\n","11993/11993 [==============================] - 7s 578us/sample - loss: 0.0280 - accuracy: 0.9948\n","Epoch 3/55\n","11993/11993 [==============================] - 7s 577us/sample - loss: 1424.1443 - accuracy: 0.9932\n","Epoch 4/55\n","11993/11993 [==============================] - 7s 605us/sample - loss: 125.3562 - accuracy: 0.9951\n","Epoch 5/55\n","11993/11993 [==============================] - 7s 595us/sample - loss: 0.0161 - accuracy: 0.9960\n","Epoch 6/55\n","11993/11993 [==============================] - 7s 595us/sample - loss: 1109.5843 - accuracy: 0.9954\n","Epoch 7/55\n","11993/11993 [==============================] - 7s 591us/sample - loss: 0.0103 - accuracy: 0.9967\n","Epoch 8/55\n","11993/11993 [==============================] - 7s 600us/sample - loss: 0.0106 - accuracy: 0.9974\n","Epoch 9/55\n","11993/11993 [==============================] - 7s 609us/sample - loss: 455.0211 - accuracy: 0.9972\n","Epoch 10/55\n","11993/11993 [==============================] - 7s 587us/sample - loss: 0.0099 - accuracy: 0.9974\n","Epoch 11/55\n","11993/11993 [==============================] - 7s 585us/sample - loss: 349.8831 - accuracy: 0.9962\n","Epoch 12/55\n","11993/11993 [==============================] - 7s 587us/sample - loss: 0.0105 - accuracy: 0.9974\n","Epoch 13/55\n","11993/11993 [==============================] - 7s 601us/sample - loss: 373.1402 - accuracy: 0.9972\n","Epoch 14/55\n","11993/11993 [==============================] - 7s 610us/sample - loss: 0.0103 - accuracy: 0.9974\n","Epoch 15/55\n","11993/11993 [==============================] - 7s 586us/sample - loss: 0.0106 - accuracy: 0.9974\n","Epoch 16/55\n","11993/11993 [==============================] - 7s 602us/sample - loss: 1.4280 - accuracy: 0.9972\n","Epoch 17/55\n","11993/11993 [==============================] - 7s 599us/sample - loss: 0.0106 - accuracy: 0.9974\n","Epoch 18/55\n","11993/11993 [==============================] - 7s 621us/sample - loss: 598.7025 - accuracy: 0.9956\n","Epoch 19/55\n","11993/11993 [==============================] - 7s 578us/sample - loss: 0.0102 - accuracy: 0.9974\n","Epoch 20/55\n","11993/11993 [==============================] - 7s 589us/sample - loss: 16.5403 - accuracy: 0.9972\n","Epoch 21/55\n","11993/11993 [==============================] - 7s 584us/sample - loss: 122.0546 - accuracy: 0.9972\n","Epoch 22/55\n","11993/11993 [==============================] - 7s 611us/sample - loss: 0.0105 - accuracy: 0.9974\n","Epoch 23/55\n","11993/11993 [==============================] - 7s 591us/sample - loss: 0.0106 - accuracy: 0.9974\n","Epoch 24/55\n","11993/11993 [==============================] - 7s 598us/sample - loss: 0.0102 - accuracy: 0.9974\n","Epoch 25/55\n","11993/11993 [==============================] - 7s 602us/sample - loss: 0.0101 - accuracy: 0.9974\n","Epoch 26/55\n","11993/11993 [==============================] - 7s 611us/sample - loss: 0.0099 - accuracy: 0.9974\n","Epoch 27/55\n","11993/11993 [==============================] - 7s 621us/sample - loss: 278.5804 - accuracy: 0.9971\n","Epoch 28/55\n","11993/11993 [==============================] - 7s 618us/sample - loss: 0.0098 - accuracy: 0.9974\n","Epoch 29/55\n","11993/11993 [==============================] - 7s 589us/sample - loss: 0.0097 - accuracy: 0.9974\n","Epoch 30/55\n","11993/11993 [==============================] - 7s 604us/sample - loss: 0.0098 - accuracy: 0.9974\n","Epoch 31/55\n","11993/11993 [==============================] - 7s 587us/sample - loss: 0.0098 - accuracy: 0.9974\n","Epoch 32/55\n","11993/11993 [==============================] - 7s 581us/sample - loss: 0.0099 - accuracy: 0.9974\n","Epoch 33/55\n","11993/11993 [==============================] - 7s 589us/sample - loss: 0.0102 - accuracy: 0.9974\n","Epoch 34/55\n","11993/11993 [==============================] - 7s 603us/sample - loss: 0.0103 - accuracy: 0.9974\n","Epoch 35/55\n","11993/11993 [==============================] - 7s 603us/sample - loss: 0.0100 - accuracy: 0.9974\n","Epoch 36/55\n","11993/11993 [==============================] - 7s 600us/sample - loss: 0.0097 - accuracy: 0.9974\n","Epoch 37/55\n","11993/11993 [==============================] - 7s 591us/sample - loss: 0.1278 - accuracy: 0.9973\n","Epoch 38/55\n","11993/11993 [==============================] - 7s 618us/sample - loss: 0.0098 - accuracy: 0.9974\n","Epoch 39/55\n","11993/11993 [==============================] - 8s 631us/sample - loss: 377.9978 - accuracy: 0.9951\n","Epoch 40/55\n","11993/11993 [==============================] - 7s 615us/sample - loss: 0.0099 - accuracy: 0.9974\n","Epoch 41/55\n","11993/11993 [==============================] - 7s 597us/sample - loss: 0.0100 - accuracy: 0.9974\n","Epoch 42/55\n","11993/11993 [==============================] - 8s 631us/sample - loss: 14.6007 - accuracy: 0.9972\n","Epoch 43/55\n","11993/11993 [==============================] - 7s 621us/sample - loss: 0.0098 - accuracy: 0.9974\n","Epoch 44/55\n","11993/11993 [==============================] - 7s 607us/sample - loss: 0.0103 - accuracy: 0.9974\n","Epoch 45/55\n","11993/11993 [==============================] - 7s 609us/sample - loss: 0.0104 - accuracy: 0.9974\n","Epoch 46/55\n","11993/11993 [==============================] - 8s 628us/sample - loss: 0.0101 - accuracy: 0.9974\n","Epoch 47/55\n","11993/11993 [==============================] - 8s 647us/sample - loss: 0.0099 - accuracy: 0.9974\n","Epoch 48/55\n","11993/11993 [==============================] - 7s 611us/sample - loss: 0.0101 - accuracy: 0.9974\n","Epoch 49/55\n","11993/11993 [==============================] - 7s 615us/sample - loss: 0.0099 - accuracy: 0.9974\n","Epoch 50/55\n","11993/11993 [==============================] - 7s 622us/sample - loss: 28.6691 - accuracy: 0.9972\n","Epoch 51/55\n","11993/11993 [==============================] - 8s 642us/sample - loss: 0.0094 - accuracy: 0.9974\n","Epoch 52/55\n","11993/11993 [==============================] - 7s 619us/sample - loss: 0.0101 - accuracy: 0.9974\n","Epoch 53/55\n","11993/11993 [==============================] - 7s 620us/sample - loss: 0.0102 - accuracy: 0.9974\n","Epoch 54/55\n","11993/11993 [==============================] - 7s 617us/sample - loss: 0.0100 - accuracy: 0.9974\n","Epoch 55/55\n","11993/11993 [==============================] - 8s 628us/sample - loss: 0.0101 - accuracy: 0.9974\n"]}],"metadata":{},"execution_count":27,"source":["!pip install tensorflow\n","import tensorflow.keras as keras\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras import callbacks\n","from tensorflow.keras import regularizers\n","from tensorflow.keras import Input\n","###############时序卷积模块###################\n","input1 = keras.Input(shape=(feature_len,12), name='input1')\n","x1 = layers.Conv1D(256, 2)(input1)\n","# x1 = layers.LeakyReLU(alpha=0.3)(x1)\n","x1 = layers.Conv1D(256, 2)(x1)\n","x1 = layers.Conv1D(128, 2)(x1)\n","x1 = layers.Conv1D(128, 2)(x1)\n","# x1 = layers.LeakyReLU(alpha=0.3)(x1)\n","x1 = layers.GlobalAveragePooling1D()(x1)\n","\n","##############全连接模块###################\n","input2 = keras.Input(shape=(len(input_cols)), name='input2')\n","x2 = layers.Dense(128, activation='relu')(input2)\n","x2 = layers.Dense(64, activation='relu')(input2)\n","# x2 = layers.Dropout(0.25)(x2)\n","##############横向卷积模块########################\n","input3 = keras.Input(shape=(12,feature_len), name='input3')\n","x3 = layers.Conv1D(128, 2, input_shape=(12,8))(input3)\n","# x3 = layers.LeakyReLU(alpha=0.3)(x3)\n","x3 = layers.Conv1D(128, 2)(x3)\n","# x3 = layers.LeakyReLU(alpha=0.3)(x3)\n","x3 = layers.GlobalAveragePooling1D()(x3)\n","\n","################二维卷积模块##############################\n","input4 = keras.Input(shape=(feature_len,12,1), name='input4')\n","x4 = layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1, 1))(input4)\n","x4 = layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1, 1))(x4)\n","x4 = layers.Conv2D(filters=32, kernel_size=(3,3), strides=(1, 1))(x4)\n","x4 = layers.MaxPooling2D()(x4)\n","x4 = layers.Flatten()(x4)\n","\n","##############输出模块###################\n","x = layers.concatenate([x1, x2,x3,x4])\n","x = layers.Flatten()(x)\n","x = layers.Dense(128, activation='relu')(x)\n","x = layers.Dense(128, activation='relu')(x)\n","x = layers.Dense(128, activation='relu')(x)\n","output_ = layers.Dense(1,activation='sigmoid',name='output')(x)\n","##########################################\n","\n","model = keras.Model(inputs=[input1, input2,input3,input4], outputs=[output_])\n","model.summary()\n","model.compile(loss='binary_crossentropy',\n","          optimizer='rmsprop',\n","          metrics=['accuracy'])\n","history = model.fit([conv_X,X,conv_X.swapaxes(1,2),conv_X.reshape((-1,feature_len,12,1))],y,\n","                    batch_size = 64,epochs = 55,validation_split = 0.0,use_multiprocessing=True)\n"],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stdout","text":["User-id:13\n","程序开始运行时间为：2019-12-22 14:30:54.044865\n","程序结束运行时间为：2019-12-22 14:30:55.757635\n","程序运行时间（去除打分耗时）为：1.71277\n","程序的准确率为：95.76147475\n","最终得分为：96.18532727\n"]}],"metadata":{},"execution_count":28,"source":["from ustciscrBDL_B import get_score\n","\n","user_verify_data = pd.DataFrame()\n","user_verify_data['zjnsrsbh'] = probe_data[\"主键:纳税人识别号\"]\n","get_score.post_user_id('13')\n","user_verify_data['Probability'] = model.predict([probe_conv,probe,probe_conv.swapaxes(1,2),probe_conv.reshape((-1,feature_len,12,1))])\n","\n","get_score.post_verify_data(user_verify_data)"],"cell_type":"code"}],"nbformat":4}