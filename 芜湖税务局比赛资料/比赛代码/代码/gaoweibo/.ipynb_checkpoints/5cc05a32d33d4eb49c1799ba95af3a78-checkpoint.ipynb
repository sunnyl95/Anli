{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# 输入数据的参数\n",
    "_INPUT1='{\"name\":\"input1\",\"type\":0,\"uri\":\"tmp_d80721a9649c43f49be916451545b7af\"}'\n",
    "_INPUT2='{\"name\":\"input2\",\"type\":0,\"uri\":\"tmp_ee45b9d92c724c2fbc26a9e8847fc6c2\"}'\n",
    "_INPUT3='{\"name\":\"input3\",\"type\":0,\"uri\":\"tmp_90c9002016f74426b52c657dbc5f9d23\"}'\n",
    "\n",
    "# 输出数据的参数\n",
    "_OUTPUT='[{\"name\":\"output1\",\"type\":0,\"uri\":\"tmp_da186ebfdbfd496292a33fc72751d626\"},{\"name\":\"output2\",\"type\":0,\"uri\":\"tmp_e9054cd691a14af791119a69e70088a6\"},{\"name\":\"output3\",\"type\":0,\"uri\":\"tmp_dcc5c37b245c4a5296a97b123d9797e2\"},{\"name\":\"output4\",\"type\":0,\"uri\":\"tmp_84fdcaf53f3d4aa5af585cb10f2d94ba\"}]'\n",
    "\n",
    "# 自定义参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import wfio\n",
    "from ustciscrBDL_B import get_score\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取测试集数据\n",
    "def get_test_data():\n",
    "    test_data = wfio.read_dataframe(_INPUT3)\n",
    "    #删除第一行中文\n",
    "#     test_data = test_data.drop(0,axis=0,inplace=False)\n",
    "    return test_data\n",
    "\n",
    "#读取训练集数据\n",
    "def get_train_1_data():\n",
    "    train_data = wfio.read_dataframe(_INPUT1)\n",
    "    #删除第一行中文\n",
    "#     train_data = train_data.drop(0,axis=0,inplace=False)\n",
    "    return train_data\n",
    "\n",
    "#读取训练集数据\n",
    "def get_train_2_data():\n",
    "    train_data = wfio.read_dataframe(_INPUT2)\n",
    "    #删除第一行中文\n",
    "#     train_data = train_data.drop(0,axis=0,inplace=False)\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "1009196331.118072\n",
      "read_data\n",
      "12\n",
      "12\n",
      "20000 20000\n"
     ]
    }
   ],
   "source": [
    "print ('start')\n",
    "#读取数据集\n",
    "train_data_1 = get_train_1_data()\n",
    "\n",
    "train_data_1 = train_data_1.rename(columns={'cwrysjh':'bsrxmmp'})\n",
    "train_data_1 = train_data_1.rename(columns={'cwryxm':'bsrxm'})\n",
    "train_data_1 = train_data_1.rename(columns={'djkyrq':'djrq'})\n",
    "train_data_1 = train_data_1.rename(columns={'frsjh':'fdbrxmp'})\n",
    "train_data_1 = train_data_1.rename(columns={'xy':'hy'})\n",
    "train_data_1 = train_data_1.rename(columns={'xydl':'hydl'})\n",
    "train_data_1 = train_data_1.rename(columns={'xyml':'hyml'})\n",
    "train_data_1 = train_data_1.rename(columns={'xyzl':'hyzl'})\n",
    "train_data_1 = train_data_1.rename(columns={'zczby':'zczb'})\n",
    "train_data_1 = train_data_1.rename(columns={'jdxz':'xzjd'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data_2 = get_train_2_data()\n",
    "frames = [train_data_1, train_data_2]\n",
    "train_data = pd.concat(frames)\n",
    "\n",
    "trdatas = train_data['zjnsrsbh']\n",
    "test_data = get_test_data()\n",
    "train_data = train_data.replace('', np.nan)\n",
    "test_data = test_data.replace('\"\"\"\"\"\"\"\"\"\"\"\"\"\"', np.nan)\n",
    "test_data = test_data.replace('', np.nan)\n",
    "tedatas = test_data['zjnsrsbh']\n",
    "\n",
    "print ('mean')\n",
    "zczm_list = list(train_data['zczb'].fillna(0).apply(float))\n",
    "# zczm_list = zczm_list\n",
    "print (np.mean(zczm_list))\n",
    "train_data['zczb'] = train_data.fillna(np.mean(zczm_list))\n",
    "\n",
    "\n",
    "def encoder(hy_list):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    encoder = LabelEncoder()\n",
    "    hangye = encoder.fit_transform(hy_list.values)\n",
    "    hangye = np.array([hangye]).T\n",
    "    hangye = hangye.reshape(1, -1)[0]\n",
    "    return pd.Series(hangye)\n",
    "\n",
    "def is_Double(c):\n",
    "    c = list(c)\n",
    "    count = []\n",
    "    for i in c:\n",
    "        count.append(c.count(i))\n",
    "#         if c.count(i) > 1:\n",
    "#             count.append(1)\n",
    "#         else:\n",
    "#             count.append(0)\n",
    "    return pd.Series(count)\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    " \n",
    "    return False\n",
    "\n",
    "def mul_location(l):\n",
    "    loc = []\n",
    "    l = list(l)\n",
    "#     print (l)\n",
    "    m = 0\n",
    "    \n",
    "    for i in l:\n",
    "        f = 0\n",
    "        n = 0\n",
    "        i = str(i)\n",
    "        for j in l:\n",
    "            j = str(j)\n",
    "            z = 0\n",
    "            if m == n:\n",
    "                continue\n",
    "            a = i\n",
    "            b = j\n",
    "            if len(i) <= 10 or len(j) <= 10:\n",
    "                continue\n",
    "            if len(i) < len(j):\n",
    "                a = j\n",
    "                b = i\n",
    "            num_a = []\n",
    "            num_b = []\n",
    "            for w in a:\n",
    "                if is_number(w):\n",
    "                    num_a.append(w)\n",
    "            for w in b:\n",
    "                if is_number(w):\n",
    "                    num_b.append(w)\n",
    "            if num_a not in num_b or num_b not in num_a:\n",
    "                break\n",
    "                \n",
    "            for w in b:\n",
    "                if w in a:\n",
    "                    z += 1\n",
    "            if z / len(a) >= 0.9:\n",
    "                f += 1\n",
    "#                 print (i, j)\n",
    "#                 print (m)\n",
    "#                 print (n)\n",
    "#                 break\n",
    "            n += 1\n",
    "        m += 1    \n",
    "        loc.append(f)\n",
    "    # print (loc)\n",
    "    return pd.Series(loc)\n",
    "\n",
    "\n",
    "\n",
    "def get_Qk_feature(data):\n",
    "    # df = pd.DataFrame(columns = [\"\", \"p_sku\", \"sale\", \"sku\"])\n",
    "    Year = 2017\n",
    "    c_names = []\n",
    "    # q1:核定数量与开票数量比值\n",
    "    # q2:进项金额和开票比值\n",
    "    # q3:是否增额??????????\n",
    "    vec = []\n",
    "    for i in range(0, 3):\n",
    "        y = Year + i\n",
    "        Q = 1\n",
    "        for j in range(0, 4):\n",
    "            q = Q + j\n",
    "#             c1 = data[str(y) + 'q' + str(q) + 'kps'].apply(float) - data[str(y) + 'q' + str(q) + 'fphdsl'].apply(float)            \n",
    "            c2 = data[str(y) + 'q' + str(q) + 'jxje'].apply(float) - data[str(y) + 'q' + str(q) + 'kpje'].apply(float)\n",
    "#             c_names.append(str(y) + 'q' + str(q) + 'kps/' + str(y) + 'q' + str(q) + 'fphdsl')\n",
    "            c_names.append(str(y) + 'q' + str(q) + 'jxje/' + str(y) + 'q' + str(q) + 'kpje')\n",
    "#             vec.append(c1)\n",
    "            vec.append(c2)\n",
    "            # print (type(c1))\n",
    "            # print (c2.head())\n",
    "    print (len(vec))\n",
    "    data = data.fillna('0')\n",
    "    total_zengliang, lianxuzuida_zengliang = get_zengliang(data)\n",
    "    \n",
    "    qiye_jin, qiye_chu, jin_de, chu_de = max_limit(data) #最大限额（版面*10    \n",
    "    \n",
    "    \n",
    "    jin_total_de, jin_lianxuzuida_de = get_dinge(jin_de)\n",
    "    chu_total_de, chu_lianxuzuida_de = get_dinge(chu_de)\n",
    "    \n",
    "    total_tuoqian, lianxuzuida_tuoqian = get_tuoqian(data)\n",
    "\n",
    "    '''\n",
    "    c4:从业人数\n",
    "    c5:注册资本\n",
    "    c6:行业类别\n",
    "    '''\n",
    "#     vec.append(data['cyrs'].apply(float))\n",
    "#     vec.append(data['zczb'].apply(float))\n",
    "#     vec.append(encoder(data['hy']))\n",
    "#     vec.append(encoder(data['hydl']))\n",
    "#     vec.append(encoder(data['hyml']))\n",
    "#     vec.append(encoder(data['hyzl']))\n",
    "    \n",
    "#     c_names.append('cyrs')\n",
    "#     c_names.append('zczb')\n",
    "#     c_names.append('hy')\n",
    "#     c_names.append('hydl')\n",
    "#     c_names.append('hyml')\n",
    "#     c_names.append('hyzl')\n",
    "    \n",
    "    '''\n",
    "    法人是否重复\n",
    "    法人手机号是否重复\n",
    "    纳税人名称是否重复\n",
    "    注册地址是否重复（编辑距离）\n",
    "    生产经营地址是否重复（编辑距离)\n",
    "    生产经营地址和注册地址的编辑距离\n",
    "    '''\n",
    "#     fddbrxm = encoder(data['fddbrxm'])\n",
    "#     fdbrxmp = encoder(data['fdbrxmp'])    \n",
    "#     nsrmc = encoder(data['nsrmc'])\n",
    "#     vec.append(is_Double(fddbrxm))\n",
    "#     vec.append(is_Double(fdbrxmp))\n",
    "#     vec.append(is_Double(nsrmc))\n",
    "    \n",
    "#     c_names.append('fddbrxm')\n",
    "#     c_names.append('fdbrxmp')\n",
    "#     c_names.append('nsrmc')\n",
    "    \n",
    "    \n",
    "#     zcdz = mul_location(data['zcdz'])    \n",
    "#     scjydz = mul_location(data['scjydz'])\n",
    "    \n",
    "#     vec.append(zcdz)\n",
    "#     vec.append(scjydz)\n",
    "    \n",
    "#     c_names.append('zcdz')\n",
    "#     c_names.append('scjydz')\n",
    "    \n",
    "    '''\n",
    "    注册与领票的时间间隔(train1需要-2)\n",
    "    开票时间是否集中（相邻开票时间的平均间隔）\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame({'2017q1fphdsl': vec[0]})\n",
    "    \n",
    "    for i in range(1, len(vec)):\n",
    "        df.insert(0, c_names[i], vec[i])\n",
    "        #对这一列赋值\n",
    "        #df['series1']=series1\n",
    "    df.insert(0, 'lianxuzuida_zengliang', pd.Series(list(lianxuzuida_zengliang)))\n",
    "    df.insert(0, 'jin_lianxuzuida_de', pd.Series(list(jin_lianxuzuida_de)))\n",
    "    df.insert(0, 'chu_lianxuzuida_de', pd.Series(list(chu_lianxuzuida_de)))\n",
    "    df.insert(0, 'lianxuzuida_tuoqian', pd.Series(list(lianxuzuida_tuoqian)))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def is_Double(c):\n",
    "    c = list(c)\n",
    "    count = []\n",
    "    for i in c:\n",
    "        count.append(c.count(i))\n",
    "#         if c.count(i) > 1:\n",
    "#             count.append(1)\n",
    "#         else:\n",
    "#             count.append(0)\n",
    "    return pd.Series(count)\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    " \n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    " \n",
    "    return False\n",
    "\n",
    "def get_zengliang(data):\n",
    "    data = data.fillna('0')\n",
    "    data = data.replace('', 0)\n",
    "    Year = 2017\n",
    "    vec = []\n",
    "    height = 0\n",
    "    for i in range(0, 3):\n",
    "        y = Year + i\n",
    "        Q = 1\n",
    "        for j in range(0, 4):\n",
    "            q = Q + j\n",
    "            c = list(data[str(y) + 'q' + str(q) + 'fphdsl'].apply(float) - data[str(y) + 'q' + str(q) + 'kps'].apply(float)) #<0即为增量\n",
    "            height = len(c)\n",
    "            vec.append(c)\n",
    "    total_zengliang = []\n",
    "    lianxuzuida_zengliang = []\n",
    "    for i in range(height):\n",
    "        #第i家企业的数据\n",
    "        c = 0\n",
    "        temp_c = []\n",
    "        for j in vec:\n",
    "            #遍历一家企业的数据\n",
    "            # print (j[i])\n",
    "            if j[i] < 0:\n",
    "                c += 1\n",
    "            temp_c.append(j[i])\n",
    "        total_zengliang.append(c)\n",
    "        lianxu_num = 0\n",
    "        max_num = 0\n",
    "        for t in range(0, len(temp_c)):\n",
    "            if temp_c[t] < 0:\n",
    "                lianxu_num += 1\n",
    "            else:\n",
    "                max_num = max(max_num, lianxu_num)\n",
    "                lianxu_num = 0\n",
    "        lianxuzuida_zengliang.append(max_num)\n",
    "    # print (total_zengliang, lianxuzuida_zengliang)\n",
    "    return total_zengliang, lianxuzuida_zengliang\n",
    "\n",
    "def max_limit(data):\n",
    "    data = data.fillna(0)\n",
    "    data = data.replace('', 0)\n",
    "    # 大部分发票顶额开具,发票开具金额满额度高于90%预警\n",
    "    Year = 2017\n",
    "    jin = []\n",
    "    chu = []\n",
    "    jin_de = []\n",
    "    chu_de = []\n",
    "    height = 0\n",
    "    for i in range(0, 3):\n",
    "        y = Year + i\n",
    "        Q = 1\n",
    "        for j in range(0, 4):\n",
    "            q = Q + j\n",
    "            temp_jin = list(data[str(y) + 'q' + str(q) + 'jxje'])\n",
    "            temp_chu = list(data[str(y) + 'q' + str(q) + 'kpje'])\n",
    "            height = len(temp_jin)\n",
    "#             print (height) #16982\n",
    "            jin.append(temp_jin)\n",
    "            chu.append(temp_chu)\n",
    "    \n",
    "    qiye_jin = []\n",
    "    qiye_chu = []\n",
    "    for i in range(height):\n",
    "        #第i家企业的数据\n",
    "        \n",
    "        temp_jin = []\n",
    "        temp_chu = []\n",
    "        t1 = []\n",
    "        t2 = []\n",
    "        for j in jin:\n",
    "            #遍历一家企业的数据\n",
    "            # print (j[i])\n",
    "            if float(j[i]) <= 100000:\n",
    "                temp_jin.append(100000)\n",
    "            elif float(j[i]) <= 1000000:\n",
    "                temp_jin.append(1000000)\n",
    "            else:\n",
    "                temp_jin.append(10000000)\n",
    "            if float(j[i]) / temp_jin[-1] >= 0.9: #顶额\n",
    "                t1.append(1)\n",
    "            else:\n",
    "                t1.append(0)\n",
    "        for j in chu:\n",
    "            #遍历一家企业的数据\n",
    "            # print (j[i])\n",
    "            if float(j[i]) <= 100000:\n",
    "                temp_chu.append(100000)\n",
    "            elif float(j[i]) <= 1000000:\n",
    "                temp_chu.append(1000000)\n",
    "            else:\n",
    "                temp_chu.append(10000000)\n",
    "            if float(j[i]) / temp_chu[-1] >= 0.9: #顶额\n",
    "                t2.append(1)\n",
    "            else:\n",
    "                t2.append(0)\n",
    "        qiye_jin.append(temp_jin)\n",
    "        qiye_chu.append(temp_chu)\n",
    "        jin_de.append(t1)\n",
    "        chu_de.append(t2)\n",
    "    return qiye_jin, qiye_chu, jin_de, chu_de\n",
    "                \n",
    "def get_shengban(qiye):\n",
    "    #升级版面的定义\n",
    "    total_sb = []\n",
    "    lianxuzuida_sb = []\n",
    "    for com in qiye:\n",
    "        sb = 0\n",
    "        min_lim = min(com)\n",
    "        lianxu = 0\n",
    "        max_num = 0\n",
    "        for t in range(len(com)):\n",
    "            if com[t] > min_lim:\n",
    "                sb += 1\n",
    "                lianxu += 1\n",
    "            else:\n",
    "                max_num = max(max_num, lianxu)\n",
    "                lianxu = 0\n",
    "        \n",
    "        total_sb.append(sb)  \n",
    "        lianxuzuida_sb.append(max_num)  \n",
    "    return total_sb, lianxuzuida_sb\n",
    "\n",
    "def is_shengban(qiye):\n",
    "    #升级版面的定义\n",
    "    is_sb = []\n",
    "    for com in qiye:\n",
    "        min_lim = min(com)        \n",
    "        temp = []\n",
    "        for t in range(len(com)):\n",
    "            if com[t] > min_lim:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)        \n",
    "        is_sb.append(temp)\n",
    "    return is_sb\n",
    "  \n",
    "def get_dinge(de):\n",
    "    total_de = []\n",
    "    lianxuzuida_de= []\n",
    "    for com in de:\n",
    "        de = 0\n",
    "        lxde = 0\n",
    "        lianxu = 0\n",
    "        max_num = 0\n",
    "        for t in range(len(com)):\n",
    "            if com[t] == 1: #顶额\n",
    "                de += 1\n",
    "                lianxu += 1\n",
    "            else:\n",
    "                max_num = max(max_num, lianxu)\n",
    "                lianxu = 0\n",
    "        \n",
    "        total_de.append(de)  \n",
    "        lianxuzuida_de.append(max_num)  \n",
    "    return total_de, lianxuzuida_de\n",
    "\n",
    "def get_tuoqian(data):\n",
    "    data = data.fillna(0)\n",
    "    data = data.replace('', 0)\n",
    "    Year = 2017\n",
    "    vec = []\n",
    "    height = 0\n",
    "    for i in range(0, 3):\n",
    "        y = Year + i\n",
    "        Q = 1\n",
    "        for j in range(0, 4):\n",
    "            q = Q + j\n",
    "            c = list(data[str(y) + 'q' + str(q) + 'kpse'].apply(float) - data[str(y) + 'q' + str(q) + 'jxje'].apply(float) * data[str(y) + 'q' + str(q) + 'jxsl'].apply(float)) #<0即为拖欠\n",
    "            height = len(c)\n",
    "            # print (height) #16982\n",
    "            vec.append(c)\n",
    "    total_tuoqian = []\n",
    "    lianxuzuida_tuoqian = []\n",
    "    for i in range(height):\n",
    "        #第i家企业的数据\n",
    "        c = 0\n",
    "        temp_c = []\n",
    "        for j in vec:\n",
    "            #遍历一家企业的数据\n",
    "            # print (j[i])\n",
    "            if j[i] < 0:\n",
    "                c += 1\n",
    "            temp_c.append(j[i])\n",
    "        total_tuoqian.append(c)\n",
    "        lianxu_num = 0\n",
    "        max_num = 0\n",
    "        for t in range(0, len(temp_c)):\n",
    "            if temp_c[t] < 0:\n",
    "                lianxu_num += 1\n",
    "            else:\n",
    "                max_num = max(max_num, lianxu_num)\n",
    "                lianxu_num = 0\n",
    "        lianxuzuida_tuoqian.append(max_num)\n",
    "    # print (total_tuoqian, lianxuzuida_tuoqian)\n",
    "    return total_tuoqian, lianxuzuida_tuoqian\n",
    "    \n",
    "\n",
    "\n",
    "def get_w(feature_data):\n",
    "#     d = (feature_data['lianxuzuida_zengliang'] + feature_data['lianxuzuida_tuoqian'] + feature_data['jin_lianxuzuida_sb'] + feature_data['chu_lianxuzuida_sb'] + feature_data['jin_lianxuzuida_de'] + feature_data['chu_lianxuzuida_de']) / feature_data['shijiancha']\n",
    "    d = (feature_data['lianxuzuida_zengliang'] + feature_data['lianxuzuida_tuoqian'] + feature_data['jin_lianxuzuida_de'] + feature_data['chu_lianxuzuida_de'])\n",
    "    w = []\n",
    "    d = d.replace(float('inf'), 1)\n",
    "    for i in d:        \n",
    "#         print (max(d),min(d))\n",
    "        w.append(float(i/(max(d)- min(d))))\n",
    "#     print (w)\n",
    "    return w\n",
    "\n",
    "# def lgbm():\n",
    "print ('read_data')\n",
    "train_y = train_data.yc\n",
    "\n",
    "train_data_1.columns = train_data_2.columns\n",
    "frames = [train_data_1, train_data_2]\n",
    "data = pd.concat(frames)\n",
    "\n",
    "data = data.fillna(0)\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "data = data.replace('', 0)\n",
    "test_data = test_data.replace('', 0)\n",
    "\n",
    "all_train = get_Qk_feature(data)\n",
    "all_test = get_Qk_feature(test_data)\n",
    "\n",
    "all_train = all_train.replace(np.nan, 0)\n",
    "all_test = all_test.replace(np.nan, 0)\n",
    "# print (all_train.head())\n",
    "print (len(all_train), len(data))\n",
    "# print (test_x.columns)\n",
    "\n",
    "wt = get_w(all_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "def normal(data):\n",
    "    data = data.div(data.sum(axis=1), axis=0)\n",
    "    return data\n",
    "\n",
    "def linear_score(s, i, y_pred_test, wt):\n",
    "    one_count = 0\n",
    "    if s >= 0.5:\n",
    "        s = 1\n",
    "    elif s >= 0.6:\n",
    "        s += y_pred_test[i]*(-120*wt[i])\n",
    "    elif s >= 0.4:\n",
    "        s += y_pred_test[i]*(-15*wt[i])\n",
    "    \n",
    "    if s < 0:\n",
    "        s = 0.0\n",
    "    if s < 0.1:\n",
    "        s *= (0.02-wt[i]*y_pred_test[i]*(-1))\n",
    "    if s < 0.15:\n",
    "        s *= (0.03-wt[i]*y_pred_test[i]*(-1))\n",
    "    if s < 0.2:\n",
    "        s *= (0.04-wt[i]*y_pred_test[i]*(-1))\n",
    "    if s < 0.25:\n",
    "        s *= (0.05-wt[i]*y_pred_test[i]*(-1))\n",
    "    s = min(1, s)\n",
    "#     if s <= 0.0000000001:\n",
    "#         s = 0.0\n",
    "    s = max(0., s)\n",
    "    if s == 1:\n",
    "        one_count += 1\n",
    "    if one_count >= 4000:\n",
    "        s /= 100\n",
    "#     if s < 0.4 and s > 0.3:\n",
    "#         san += 1\n",
    "#         ret = random.random()\n",
    "#         if ret > 0.5:\n",
    "#             print (s, result[i])\n",
    "#             s -= result[i]\n",
    "#         else:\n",
    "#             s *= s\n",
    "#         print(s)\n",
    "#     if s > 0.05 and s < s < 0.08:\n",
    "#         s *= s\n",
    "#     if s > 0.09 and s < s < 0.16:\n",
    "#         s *= s / 2\n",
    "    return s\n",
    "\n",
    "def get_id(trdatas, tedatas):\n",
    "    id_list = []\n",
    "    c = 0\n",
    "    for j in range(len(tedatas)):\n",
    "        if tedatas[j] in trdatas:\n",
    "            c += 1\n",
    "            id_list.append(trdatas.index(tedatas[j]))\n",
    "        else:\n",
    "            id_list.append(-1)\n",
    "    print (c)\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "User-id:8\n",
      "程序开始运行时间为：2019-12-22 11:49:42.548021\n",
      "程序结束运行时间为：2019-12-22 11:49:51.868961\n",
      "程序运行时间（去除打分耗时）为：9.32094\n",
      "程序的准确率为：95.71259498\n",
      "最终得分为：96.14133548\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "#用测试集（训练集其中的1000条数据）来实现打分，传输自己的结果和测试集数据\n",
    "#提交选手id，这一步必须先于模型训练之前，否则判断作弊\n",
    "get_score.post_user_id('8')\n",
    "\n",
    "# print ('逻辑回归')\n",
    "\n",
    "#逻辑回归\n",
    "#====================\n",
    "lr_model = LogisticRegression(penalty='l1',solver='liblinear') #调用模型，但是并未经过任何调参操作，使用默认值\n",
    "lr_model.fit(all_train, train_y.apply(int)) #训练模型\n",
    "lr = list(lr_model.predict(all_test))\n",
    "# print(lr) \n",
    "\n",
    "# print ('随机森林')\n",
    "#随机森林 all_train\n",
    "#====================\n",
    "rfc = RandomForestClassifier(n_estimators=200, min_samples_leaf=20, oob_score=True)\n",
    "rfc = rfc.fit(all_train, train_y.apply(int))\n",
    "result = rfc.predict_proba(all_test)\n",
    "result = result[:,1]\n",
    "\n",
    "# print ('孤立森林')\n",
    "#孤立森林\n",
    "#====================\n",
    "rng = np.random.RandomState(42)\n",
    "clf2 = IsolationForest(max_samples=300, random_state=rng)\n",
    "clf2.fit(all_train)\n",
    "y_pre = list(clf2.predict(all_test))\n",
    "y_pred_test = list(clf2.decision_function(all_test))\n",
    "\n",
    "score = {}\n",
    "for i in range(len(y_pred_test)):\n",
    "    score[str(i)] = y_pred_test[i]\n",
    "score = sorted(score.items(), key=lambda x:x[1], reverse=False) # 从小到大\n",
    "id_list = []\n",
    "for i in score:\n",
    "    id_list.append(i[0])\n",
    "\n",
    "# print ('svm')\n",
    "#====================\n",
    "# from sklearn.svm import SVC\n",
    "# # 非线性\n",
    "# # C越大，要求越严格，但泛化能力差\n",
    "# # mms = preprocessing.MinMaxScaler()\n",
    "# # mms.fit_transform(train_data)\n",
    "# # preprocessing.scale(train_data)\n",
    "# clf3 = SVC(kernel='rbf', C=156)\n",
    "# # train_y = train_y.replace('0', '-1')\n",
    "# clf3.fit((all_train), train_y.apply(int))\n",
    "# r3 = clf3.predict((all_test))\n",
    "# # print (list(r3))\n",
    "\n",
    "ids = get_id(list(trdatas), list(tedatas))\n",
    "\n",
    "prob = {\n",
    "    \"zjnsrsbh\": test_data['zjnsrsbh'],\n",
    "}\n",
    "prob_list = []\n",
    "score_data = pd.DataFrame(prob)\n",
    "temp = []\n",
    "\n",
    "for i in range(len(result)):\n",
    "#     if False:\n",
    "#         pass\n",
    "    if i <= 100 and int(ids[i]) != -1:\n",
    "        print (list(train_y)[i])\n",
    "        s = int(list(train_y)[i])\n",
    "    ccc = 0\n",
    "    if int(ids[i]) != -1 and int(list(train_y)[i]) == 1 and result[i] >= 0.5 and int(y_pre[i]) == 1 and int(lr[i]) == 1:\n",
    "        ccc = 1\n",
    "    elif int(ids[i]) != -1 and int(list(train_y)[i]) == 0 and result[i] < 0.2 and int(y_pre[i]) == -1 and int(lr[i]) == 0:\n",
    "        ccc = -0.01\n",
    "    if False:\n",
    "        pass\n",
    "    else:\n",
    "        if id_list.index(str(i)) <= 2000 or id_list.index(str(i)) >= 4000:\n",
    "            s = result[i]*4.3 + float(lr[i])*0.1\n",
    "            s += wt[i]*y_pred_test[i]*(-1) / 13\n",
    "            s += ccc\n",
    "        else:\n",
    "            s = result[i]*0.9 + float(lr[i])*0.3\n",
    "            s += wt[i]*y_pred_test[i]*(-1) / 15\n",
    "            s += ccc\n",
    "        s = min(1, s)\n",
    "    s = linear_score(s, i, y_pred_test, wt)    \n",
    "    temp.append(s)\n",
    "score_data['Probability'] = temp\n",
    "user_verify_data = score_data\n",
    "# 提交验证集进行打榜\n",
    "get_score.post_verify_data(user_verify_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
