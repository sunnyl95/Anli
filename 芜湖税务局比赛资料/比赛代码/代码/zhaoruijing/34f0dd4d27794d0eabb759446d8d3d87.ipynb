{"nbformat_minor":2,"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","file_extension":".py","mimetype":"text/x-python","version":"3.7.3"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"cells":[{"outputs":[],"metadata":{"tags":["parameters"]},"execution_count":1,"source":["# 输入数据的参数\n","_INPUT1='{\"name\":\"input1\",\"type\":0,\"uri\":\"tmp_924decc15eed45238b5eb7d3b7cc7c26\"}'\n","_INPUT2='{\"name\":\"input2\",\"type\":0,\"uri\":\"tmp_8a7e45d110c24152980c1aa2587b010c\"}'\n","_INPUT3='{\"name\":\"input3\",\"type\":0,\"uri\":\"tmp_60ecea6cbfae47f2954238c219c8f2d2\"}'\n","\n","# 输出数据的参数\n","_OUTPUT='[{\"name\":\"output1\",\"type\":0,\"uri\":\"tmp_4d0f0b1a707f4e2392233f916158897a\"},{\"name\":\"output2\",\"type\":0,\"uri\":\"tmp_3ec9d1e17dad4021b6110e8c75299812\"},{\"name\":\"output3\",\"type\":0,\"uri\":\"tmp_e3790caf415a4a248fb11cd7667153e6\"},{\"name\":\"output4\",\"type\":0,\"uri\":\"tmp_055ddd8c9be54f40ada7a0a081ef9c1d\"}]'\n","\n","# 自定义参数\n"],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n","Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.3.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch) (1.16.4)\n","Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n","Requirement already satisfied: ipdb in /opt/conda/lib/python3.7/site-packages (0.12.3)\n","Requirement already satisfied: ipython>=5.1.0; python_version >= \"3.4\" in /opt/conda/lib/python3.7/site-packages (from ipdb) (7.6.1)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from ipdb) (41.0.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.7.0)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.4.0)\n","Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.14.1)\n","Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (2.0.9)\n","Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (2.4.2)\n","Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (4.3.2)\n","Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.7.5)\n","Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.6.0)\n","Requirement already satisfied: parso>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.5.1)\n","Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.1.7)\n","Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (1.12.0)\n","Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=5.1.0; python_version >= \"3.4\"->ipdb) (0.2.0)\n"]}],"metadata":{},"execution_count":2,"source":["!pip install torch\n","!pip install ipdb\n","import pandas as pd\n","import numpy as np\n","import re\n","import random\n","import sklearn\n","from sklearn.ensemble import GradientBoostingClassifier\n","#from sklearn.externals import joblib\n","import joblib\n","import wfio\n","from ustciscrBDL_B import get_score\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as data\n","from torch.utils.data import DataLoader\n","import pickle\n","#!pip install ipdb"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":3,"source":["#!rm model.pth"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":4,"source":["#!wget home.ustc.edu.cn/~zrj1997/model.pth"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":5,"source":["#!wget -c --referer=https://pan.baidu.com/s/1jRVF5SdlTqyByZ3OryDBHw -O model.pth \"https://bjbgp01.baidupcs.com/file/76524301enb25e7340f3ec0032fa6a79?bkt=en-43ea5360a23c0e2022955787247f6b8b05228903fb8d8985d9645be186dc59a55cf42c99b5df6e50cbc57aede2281f222ab6768ec6fe2d205137ca032d50407f&fid=3734286207-250528-727342125319077&time=1576912347&sign=FDTAXGERLQBHSKfW-DCb740ccc5511e5e8fedcff06b081203-wpBBlce0AVhuL2NL3c6JWhqqorY%3D&to=75&size=16354&sta_dx=16354&sta_cs=2&sta_ft=pth&sta_ct=1&sta_mt=1&fm2=MH%2CYangquan%2CAnywhere%2C%2Canhui%2Cce&ctime=1576742908&mtime=1576742908&resv0=cdnback&resv1=0&resv2=rlim&resv3=5&resv4=16354&vuk=3734286207&iv=0&htype=&randtype=&newver=1&newfm=1&secfm=1&flow_ver=3&pkey=en-87e26db05518e6cb7a9c5c38a0615fa079d42aca88523e757752a51d2c4146a966ee4195b1b8f2eebbc2c0005fb1bd0736f384daeb653c1e305a5e1275657320&sl=68616270&expires=8h&rt=sh&r=553265769&vbdid=4269441613&fin=model.pth&fn=model.pth&rtype=1&dp-logid=8224955292230391832&dp-callid=0.1&hps=1&tsl=200&csl=200&csign=Ms6794UnRgvx8TBYvFZ4bj4bJYE%3D&so=0&ut=6&uter=4&serv=0&uc=2825019094&ti=cdac69781712398031a67f7aeda69655bb55fe4fb6f7c28d305a5e1275657320&reqlabel=250528_f_9edf4b80b1193f7e8742fcf0c8451f9a_-1_1fad5c55b4c28a72c2a489d697dc94a3&by=themis\""],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":6,"source":["#读取测试集数据\n","def get_test_data():\n","    test_data = wfio.read_dataframe(_INPUT3)\n","    #删除第一行中文\n","    #test_data = test_data.drop(0,axis=0,inplace=False)\n","    return test_data"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":7,"source":["#读取训练集数据\n","def get_train_data():\n","    train_data = wfio.read_dataframe(_INPUT2)\n","    #删除第一行中文\n","    #print(train_data.columns.values)\n","    #train_data = train_data.drop(0,axis=0,inplace=False)\n","    return train_data"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":8,"source":["def Digital(d):\n","    tmp1 = np.array(d)\n","    tmp2 = []\n","    for x in tmp1:\n","        if x.isdigit() or x.split(\".\")[0].isdigit():\n","            tmp2.append(str(x))\n","        else:\n","            tmp2.append(\"999999\")\n","    return np.array(tmp2)"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":9,"source":["def FP_Q_feature(data, FP_Q):\n","    years = ['2017', '2018', '2019']\n","    seasons = ['q1', 'q2', 'q3', 'q4']\n","    names = ['fphdsl', 'kps', 'kpje', 'kpsl', 'kpse', 'jxje', 'jxsl', 'rkse']\n","    #names = ['kpje', 'kpsl', 'kpse', 'jxje', 'jxsl', 'rkse']\n","    KPJE_mark = np.zeros((len(data), len(years)*len(seasons)))\n","    #import ipdb;ipdb.set_trace()\n","    i = 0\n","    for y in years:\n","        for s in seasons:\n","            pre = y+s\n","            #发票增量, 发票顶额\n","            #print(y, s)\n","            #import ipdb;ipdb.set_trace()\n","            for n in range(len(names)):\n","                data[pre+names[n]] = Digital(data[pre+names[n]])\n","                FP_Q[pre+names[n]] = data[pre+names[n]]\n","            FPZL = np.array(data[pre+names[1]].astype('float')) - np.array(data[pre+names[0]].astype('float'))\n","            FPDE = np.array(data[pre+names[2]].astype('float')) / (np.array(data[pre+names[1]].astype('float'))+1e-4)\n","            #销项进项比值\n","            KP_JX = np.array(data[pre+names[2]].astype('float')) / (np.array(data[pre+names[5]].astype('float'))+1e-4)\n","            #计算的开票税额，进项税额，入库税额\n","            KPSE = np.array(data[pre+names[2]].astype('float')) * np.array(data[pre+names[3]].astype('float'))\n","            JXSE = np.array(data[pre+names[5]].astype('float')) * np.array(data[pre+names[6]].astype('float'))\n","            RKSE = np.array(np.where(data[pre+names[6]].astype('float')==0.03, KPSE, KPSE-JXSE))\n","            #与真实的开票税额、入库税额之间的差值\n","            KPSE_diff = KPSE - data[pre+names[4]].astype('float')\n","            RKSE_diff = RKSE - data[pre+names[7]].astype('float')\n","            \n","            #FP_Q[pre+'FPZL'] = FPZL\n","            #FP_Q[pre+'FPDE'] = FPDE\n","            FP_Q[pre+'KP_JX'] = KP_JX\n","            FP_Q[pre+'KPSE'] = KPSE\n","            FP_Q[pre+'JXSE'] = JXSE\n","            FP_Q[pre+'RKSE'] = RKSE\n","            #FP_Q[pre+'KPSE_diff'] = KPSE_diff\n","            #FP_Q[pre+\"RKSE_diff\"] = RKSE_diff\n","\n","            KPJE_mark[:, i] = data[pre+names[2]].astype('float')\n","            i += 1\n","    tmp_CXSJ = []\n","    for i in range(len(data)):\n","        tmp = np.where(KPJE_mark[i,:]!=0)[0]\n","        if len(tmp)!=0:\n","            tmp_CXSJ.extend([tmp[-1]-tmp[0]])\n","        else:\n","            tmp_CXSJ.extend([0])\n","    #FP_Q['CXSJ'] = tmp_CXSJ\n","    return"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":10,"source":["def extract_feature(data):\n","    feature = {}\n","    feature['NSRSBH'] = data['zjnsrsbh']\n","\n","    # WXHY:是否属于危险行业: 0->dangerous\n","    #col_data = data['HYML']\n","    #dangerous = set(['批发和零售业','建筑业','商贸','批发','零售业','零售','服务业','服务','咨询','鉴证','人力资源', '纺织','服饰','木材加工','中药','农产品','收购','租赁'])\n","    #tmp_feature = []\n","    #for f in col_data:\n","    #    words = set(jieba.lcut(f))\n","    #    tmp_feature.extend([not words & dangerous])\n","    #feature['WXHY'] = tmp_feature\n","\n","    # ZCDZ_repeat/SCJYDZ_repeat：地址是否重复出现: 0->yes\n","    #ZCDZ = data['ZCDZ']\n","    #SCJYDZ = data['SCJYDZ']\n","    #ZCDZ = address_repeat_feature(ZCDZ)\n","    #SCJYDZ = address_repeat_feature(SCJYDZ)\n","    #feature['ZCDZ_repeat'] = ZCDZ\n","    #feature['SCJYDZ_repeat'] = SCJYDZ\n","\n","    # 地址是否非商业区:0-?非商业区\n","    #ZCDZ = data['ZCDZ']\n","    #SCJYDZ = data['SCJYDZ']\n","    #ZCDZ = address_nobusiness_feature(ZCDZ)\n","    #SCJYDZ = address_nobusiness_feature(SCJYDZ)\n","\n","    # 多户企业法人/财务人员相同/身份交叉:0->相同\n","    #FDDBRXM = data['FDDBRXM']\n","    #BSRXM = data['BSRXM']\n","    #identity = identity_feature(FDDBRXM, BSRXM)\n","\n","    # 季节发票特征\n","    FP_Q_feature(data, feature) \n","\n","    #登记到领票之间的间隔\n","    #standard = ['2017/01/01']*len(data)\n","    #diff = pd.to_datetime(standard) - pd.to_datetime(data['djrq']) + pd.Timedelta(days = 730)\n","    #feature['LPJG'] = np.array(diff)\n","\n","    return feature"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":11,"source":["def generate_feature_data(features):\n","    feature_data = []\n","    keys = features.keys()\n","    for key in keys:\n","        if key != 'NSRSBH':\n","            feature_data.append(features[key])\n","    return np.array(feature_data).T, features['NSRSBH']\n","def generate_train_data(train_feauture_data,train_data):\n","    train_y = np.array(train_data['yc']).astype('float')\n","    #import ipdb;ipdb.set_trace()\n","    #train_feature_data  = [x.astype('float') for x in train_feature_data]\n","    pos_len = len(np.where(train_y>=0.5)[0])\n","    neg_idx = np.where(train_y<0.5)[0]\n","    neg_idx_sample = random.sample(list(neg_idx), int(pos_len*3/2))\n","    pos_idx = np.where(train_y>=0.5)[0]\n","    idx = np.concatenate([pos_idx, neg_idx_sample], 0)\n","    return train_feature_data[idx], train_y[idx]\n","def generate_test_data(feature_data):\n","    \n","    #NSRSBH = list(NSRSBH)\n","    #for id in list(train_data['zjnsrsbh']):\n","    #    sub = NSRSBH.index(id)\n","    #    train_x.append(feature_data[sub])\n","    return feature_data"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":12,"source":["class Net(nn.Module):\n","    def __init__(self, input_size):\n","        super(Net, self).__init__()\n","        self.batchnorm = nn.Sequential(\n","            nn.BatchNorm1d(input_size),\n","        )\n","        self.conv1 = nn.Sequential(\n","            nn.Conv1d(1, 4, 3),\n","            )\n","        self.batchnorm_conv = nn.Sequential(\n","            nn.BatchNorm1d(4),\n","        )\n","        self.conv2 = nn.Conv1d(4, 4, 3)\n","        self.linear = nn.Sequential(\n","            nn.Linear(4*140, 4),\n","            #nn.ReLU(True),\n","            #nn.Conv1d(16, 16, 16),\n","            nn.Linear(4, 1),\n","            nn.Sigmoid(),\n","            )\n","    def forward(self, feature_data):\n","        #import ipdb;ipdb.set_trace()\n","        norm_output = self.batchnorm(feature_data)\n","        norm_output = norm_output.view(norm_output.size(0), 1, norm_output.size(1))\n","        conv_output = self.conv1(norm_output)\n","        conv_output = self.batchnorm_conv(conv_output)\n","        conv_output = self.conv2(conv_output)\n","        conv_output = conv_output.view(conv_output.size(0), -1)\n","        out = self.linear(conv_output)\n","        return out\n","    \n","class Net2(nn.Module):\n","    def __init__(self, input_size):\n","        super(Net2, self).__init__()\n","        self.batchnorm = nn.Sequential(\n","            nn.BatchNorm1d(input_size),\n","        )\n","        self.conv1 = nn.Sequential(\n","            nn.Conv1d(1, 4, 3),\n","            #nn.Conv1d(4, 8, 3),\n","            )\n","        self.conv2= nn.Sequential(\n","            nn.BatchNorm1d(4),\n","            nn.Conv1d(4, 4, 3)\n","        )\n","        self.linear = nn.Sequential(\n","            nn.Linear(4*140, 4),\n","            #nn.ReLU(True),\n","            #nn.Conv1d(16, 4, 3),\n","            #nn.Linear(32, 16),\n","            #nn.Linear(16, 4),\n","            nn.Linear(4, 1),\n","            nn.Sigmoid(),\n","            )\n","    def forward(self, feature_data):\n","        #import ipdb;ipdb.set_trace()\n","        #norm_output = self.batchnorm(feature_data)\n","        norm_output = norm_output.view(norm_output.size(0), 1, norm_output.size(1))\n","        conv_output_1 = self.conv1(norm_output)\n","\n","        conv_output_2 = self.conv2(conv_output_1)\n","        #conv_output_2 = self.batch2(conv_output_1)\n","        pool_output = conv_output_2.view(conv_output_2.size(0), -1)\n","        out = self.linear(pool_output)\n","        return out\n","\n","class FP_dataset(data.Dataset):\n","    def __init__(self, x_data, y_data):\n","        super(FP_dataset, self).__init__()\n","        self.x = x_data\n","        self.y = y_data\n","    def __getitem__(self, index):\n","        #import ipdb;ipdb.set_trace()\n","        return self.x[index].astype(np.float32), self.y[index]\n","    def __len__(self):\n","        return len(self.x)"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":13,"source":["def create_verify_data(NSRSBH, predictions):\n","    predictions = predictions.reshape(len(predictions))\n","    predictions = np.where(predictions>0.60, 1, predictions)\n","    predictions = np.where(predictions<0.13, 0, predictions)\n","    prob = {'zjnsrsbh':NSRSBH, 'Probability':predictions}\n","    user_verify_data = pd.DataFrame(prob)\n","\n","    return user_verify_data"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":14,"source":["#train_data = get_train_data()\n","test_data = get_test_data()\n","get_score.post_user_id('18')"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":15,"source":["#train_features = extract_feature(train_data) \n","test_features = extract_feature(test_data)"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":16,"source":["test_feature_data, NSRSBH=generate_feature_data(test_features)\n","test_x = generate_test_data(test_feature_data)\n","net = Net(len(test_feature_data[0]))\n","#train_x = np.array([x.astype(np.float32) for x in train_x])\n","\n","#fp_dataset = FP_dataset(train_x, train_y)\n","#loader = DataLoader(dataset = fp_dataset, batch_size = 128, shuffle = True)\n","#opt = torch.optim.Adam(net.parameters())\n","#loss_func = torch.nn.BCELoss()\n","#net.train()\n","#for epoch in range(50):\n","#    print('Epoch: ', epoch, end = ' ')\n","#    loss_array = []\n","#    #import ipdb;ipdb.set_trace()\n","#    for step, (x, y) in enumerate(loader):\n","#        output = net(x)\n","#        #import ipdb;ipdb.set_trace()\n","#        loss = loss_func(output.squeeze(), y)\n","#        opt.zero_grad()\n","#        loss.backward()\n","#        opt.step()\n","#        loss_array.append(loss.data.numpy())\n","#    print('loss: ', loss.data.numpy())\n","#torch.save(net, 'test.pth')\n","##net = torch.load('model.pkl')\n"],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stdout","text":["model.pth  model.pth.1\tmodel.pth.2\n"]}],"metadata":{},"execution_count":17,"source":["!ls "],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":18,"source":["net = torch.load('model.pth')"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":19,"source":["net.eval()\n","#import ipdb;ipdb.set_trace()\n","feature_data = np.array([x.astype(np.float32) for x in test_x])\n","feature_data = torch.from_numpy(feature_data)\n","predictions = net(feature_data).detach().numpy()"],"cell_type":"code"},{"outputs":[],"metadata":{},"execution_count":20,"source":["user_verify_data = create_verify_data(test_data['zjnsrsbh'], predictions)"],"cell_type":"code"},{"outputs":[{"output_type":"stream","name":"stdout","text":["User-id:18\n","程序开始运行时间为：2019-12-22 14:44:29.062054\n","程序结束运行时间为：2019-12-22 14:44:30.545579\n","程序运行时间（去除打分耗时）为：1.483525\n","程序的准确率为：95.60628525\n","最终得分为：96.04565673\n"]}],"metadata":{},"execution_count":21,"source":["get_score.post_verify_data(user_verify_data)"],"cell_type":"code"},{"outputs":[],"metadata":{},"source":[],"cell_type":"code"},{"outputs":[],"metadata":{},"source":[],"cell_type":"code"}],"nbformat":4}