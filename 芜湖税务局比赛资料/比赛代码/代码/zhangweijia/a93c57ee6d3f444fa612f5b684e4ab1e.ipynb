{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# 输入数据的参数\n",
    "_INPUT1='{\"name\":\"input1\",\"type\":0,\"uri\":\"tmp_08acd76f74ac46c0b2d644822d282bea\"}'\n",
    "_INPUT2='{\"name\":\"input2\",\"type\":0,\"uri\":\"tmp_fbf13fa0fc4e470dab25b537975d561d\"}'\n",
    "_INPUT3='{\"name\":\"input3\",\"type\":0,\"uri\":\"tmp_56b0903ca61f432abb87ee2dd4115c29\"}'\n",
    "_INPUT4='{\"name\":\"input4\",\"type\":0,\"uri\":\"tmp_488f5dc446454fe78445329009ed531d\"}'\n",
    "\n",
    "# 输出数据的参数\n",
    "_OUTPUT='[{\"name\":\"output1\",\"type\":0,\"uri\":\"tmp_7bb4285b6dfd4090a52303928a59e0c4\"},{\"name\":\"output2\",\"type\":0,\"uri\":\"tmp_bb421772d288408c9fa024dcd6451e32\"},{\"name\":\"output3\",\"type\":0,\"uri\":\"tmp_1aeaf77f93ab4e1cad39b7e5f60f29d4\"},{\"name\":\"output4\",\"type\":0,\"uri\":\"tmp_7d72ccfe4e0a41569ea354447bbe1f29\"}]'\n",
    "\n",
    "# 自定义参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfio\n",
    "import xgboost as xgb\n",
    "import random\n",
    "df_train1 = wfio.read_dataframe(_INPUT1)\n",
    "df_train2 = wfio.read_dataframe(_INPUT2)\n",
    "df_testA = wfio.read_dataframe(_INPUT3)\n",
    "df_testB = wfio.read_dataframe(_INPUT4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train2[\"yc\"]=df_train2[\"yc\"].astype('int')\n",
    "df_zc = df_train2[df_train2[\"yc\"]==0].reset_index(drop=True)\n",
    "df_yc = df_train2[df_train2[\"yc\"]==1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.concat([df_zc[:500],df_yc[:500]],axis=0,ignore_index=True)\n",
    "df_train = pd.concat([df_zc[500:],df_yc[500:]],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15000\n",
       "1     1000\n",
       "Name: yc, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['2017q1fphdsl', '2017q1jxje', '2017q1jxsl', '2017q1kpje', '2017q1kps', '2017q1kpse', '2017q1kpsl', '2017q1rkse', '2017q2fphdsl', '2017q2jxje', '2017q2jxsl', '2017q2kpje', '2017q2kps', '2017q2kpse', '2017q2kpsl', '2017q2rkse', '2017q3fphdsl', '2017q3jxje', '2017q3jxsl', '2017q3kpje', '2017q3kps', '2017q3kpse', '2017q3kpsl', '2017q3rkse', '2017q4fphdsl', '2017q4jxje', '2017q4jxsl', '2017q4kpje', '2017q4kps', '2017q4kpse', '2017q4kpsl', '2017q4rkse', '2018q1fphdsl', '2018q1jxje', '2018q1jxsl', '2018q1kpje', '2018q1kps', '2018q1kpse', '2018q1kpsl', '2018q1rkse', '2018q2fphdsl', '2018q2jxje', '2018q2jxsl', '2018q2kpje', '2018q2kps', '2018q2kpse', '2018q2kpsl', '2018q2rkse', '2018q3fphdsl', '2018q3jxje', '2018q3jxsl', '2018q3kpje', '2018q3kps', '2018q3kpse', '2018q3kpsl', '2018q3rkse', '2018q4fphdsl', '2018q4jxje', '2018q4jxsl', '2018q4kpje', '2018q4kps', '2018q4kpse', '2018q4kpsl', '2018q4rkse', '2019q1fphdsl', '2019q1jxje', '2019q1jxsl', '2019q1kpje', '2019q1kps', '2019q1kpse', '2019q1kpsl', '2019q1rkse', '2019q2fphdsl', '2019q2jxje', '2019q2jxsl', '2019q2kpje', '2019q2kps', '2019q2kpse', '2019q2kpsl', '2019q2rkse', '2019q3fphdsl', '2019q3jxje', '2019q3jxsl', '2019q3kpje', '2019q3kps', '2019q3kpse', '2019q3kpsl', '2019q3rkse', '2019q4fphdsl', '2019q4jxje', '2019q4jxsl', '2019q4kpje', '2019q4kps', '2019q4kpse', '2019q4kpsl', '2019q4rkse',\\\n",
    "'bsrxmmp', 'bsrxm',  'cyrs', 'djrq','fddbrxm', 'fdbrxmp', 'xzjd','jyfw', 'nsrmc', 'scjydz', 'hy', 'hydl', 'hyml', 'hyzl', 'yc', 'zcdz', 'zczb', 'zjnsrsbh']\n",
    "df_train1.columns = colnames\n",
    "df_testA[\"yc\"] = [0]*len(df_testA)\n",
    "df_testB[\"yc\"] = [0]*len(df_testB)\n",
    "df_raw = pd.concat([df_train,df_valid,df_testB],axis=0,sort=False,ignore_index=True)\n",
    "# df_raw = pd.concat([df,df_testB],axis=0,sort=False,ignore_index=True)\n",
    "df_raw[\"yc\"] = df_raw[\"yc\"].astype('int')\n",
    "df_raw[\"yc\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2017q1fphdsl', '2017q1jxje', '2017q1jxsl', '2017q1kpje', '2017q1kps',\n",
      "       '2017q1kpse', '2017q1kpsl', '2017q1rkse', '2017q2fphdsl', '2017q2jxje',\n",
      "       ...\n",
      "       'hyml', 'hyzl', 'jyfw', 'nsrmc', 'scjydz', 'xzjd', 'yc', 'zcdz', 'zczb',\n",
      "       'zjnsrsbh'],\n",
      "      dtype='object', length=114)\n",
      "Index(['2017q1fphdsl', '2017q1jxje', '2017q1jxsl', '2017q1kpje', '2017q1kps',\n",
      "       '2017q1kpse', '2017q1kpsl', '2017q1rkse', '2017q2fphdsl', '2017q2jxje',\n",
      "       ...\n",
      "       'hyml', 'hyzl', 'jyfw', 'nsrmc', 'scjydz', 'xzjd', 'yc', 'zcdz', 'zczb',\n",
      "       'zjnsrsbh'],\n",
      "      dtype='object', length=114)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_raw.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zjnsrsbh        0\n",
       "2017q4kps       0\n",
       "2017q4kpsl      0\n",
       "2017q4rkse      0\n",
       "2018q1fphdsl    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 缺失值补充\n",
    "df_raw.replace('\"\"\"\"\"\"\"\"\"\"\"\"\"\"',np.nan,inplace=True)\n",
    "df_raw.replace('',np.nan,inplace=True)\n",
    "median_col = [\"zczb\",\"cyrs\"]\n",
    "df_raw.loc[df_raw.cyrs==0,\"cyrs\"]=df_raw.cyrs.median()\n",
    "df_raw[median_col] = df_raw[median_col].fillna(value=df_raw[median_col].median())\n",
    "df_raw.fillna(value=0.0,inplace=True)\n",
    "df_raw.isnull().sum().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_colname = df_raw.columns[:96].tolist()\n",
    "val_colname.extend([\"cyrs\",\"zczb\"]) # 从业人数, 注册资本\n",
    "for ele in val_colname:\n",
    "    df_raw[ele] = df_raw[ele].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.885287\tvalid_1's auc: 0.686156\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's auc: 0.794042\tvalid_1's auc: 0.688319\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.884297\tvalid_1's auc: 0.693432\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's auc: 0.838072\tvalid_1's auc: 0.699022\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.886315\tvalid_1's auc: 0.693065\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's auc: 0.874749\tvalid_1's auc: 0.693828\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.885651\tvalid_1's auc: 0.703136\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.760196\tvalid_1's auc: 0.706662\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.884978\tvalid_1's auc: 0.694278\n",
      "[100]\ttraining's auc: 0.922785\tvalid_1's auc: 0.695751\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's auc: 0.916517\tvalid_1's auc: 0.696975\n",
      "0    0.309103\n",
      "1    0.324085\n",
      "2    0.364978\n",
      "3    0.283448\n",
      "4    0.214427\n",
      "dtype: float64\n",
      "10000\n",
      "9550    0.949739\n",
      "9799    0.936725\n",
      "8968    0.933539\n",
      "9710    0.921747\n",
      "9886    0.915786\n",
      "dtype: float64\n",
      "0    0.309103\n",
      "1    0.324085\n",
      "2    0.364978\n",
      "3    0.283448\n",
      "4    0.214427\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "############################### 对抗验证 LGB ############################################\n",
    "%matplotlib inline\n",
    "import xgboost as xgb\n",
    "from xgboost import DMatrix\n",
    "import lightgbm as lgb\n",
    "from lightgbm import Dataset\n",
    "from sklearn.model_selection import KFold,StratifiedKFold, GridSearchCV,cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "params = {'num_leaves': 60, #结果对最终效果影响较大，越大值越好，太大会出现过拟合\n",
    "          'min_data_in_leaf': 30,\n",
    "          'objective': 'binary', #定义的目标函数\n",
    "          'max_depth': -1,\n",
    "          'min_child_samples': 100,\n",
    "          'learning_rate': 0.1,\n",
    "          \"min_sum_hessian_in_leaf\": 6,\n",
    "          \"boosting\": \"gbdt\",\n",
    "          \"feature_fraction\": 0.9,  #提取的特征比率\n",
    "          \"bagging_freq\": 1,\n",
    "          'subsample': 1.0,\n",
    "          \"bagging_fraction\": 0.8,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"lambda_l1\": 0.1,             #l1正则\n",
    "#           'lambda_l2': 0.001,     #l2正则\n",
    "          \"verbosity\": -1,\n",
    "          \"nthread\": 8,                #线程数量，-1表示全部线程，线程越多，运行的速度越快\n",
    "          'metric': {'auc'},  ##评价函数选择\n",
    "          \"random_state\": 33, #随机数种子，可以防止每次运行的结果不一致\n",
    "          'scale_pos_weight':1, # 负样本数0/正样本数1, 如果取值大于0的话，在类别样本不平衡的情况下有助于快速收敛。\n",
    "          # 'device': 'gpu' ##如果安装的事gpu版本的lightgbm,可以加快运算\n",
    "          }\n",
    "\n",
    "\"\"\"仅加入98个数值特征\"\"\"\n",
    "df_val = df_raw[val_colname].copy() # 98\n",
    "# df_val = df.drop(df.columns[:96],axis=1).copy() # 131\n",
    "print(len(df_val.columns))\n",
    "X = df_val.values\n",
    "trian_num = 10000\n",
    "y = np.zeros(len(X))\n",
    "y[trian_num:] = 1\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=66)\n",
    "cv_weight = []\n",
    "cv_index = []\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X,y)):\n",
    "    X_train, X_valid = X[train_index], X[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "    model = lgb.train(params=params,train_set=train_data,num_boost_round=500,\n",
    "                      valid_sets = [train_data, valid_data],verbose_eval=50,early_stopping_rounds=50)\n",
    "    pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    cv_index.append(valid_index)\n",
    "    cv_weight.append(pred)\n",
    "    \n",
    "cv_index = np.concatenate(cv_index,axis=0)\n",
    "cv_weight = np.concatenate(cv_weight,axis=0)\n",
    "weight = pd.Series(cv_weight,index=cv_index)\n",
    "weight = weight.sort_index()\n",
    "print(weight.head())\n",
    "weight_train = weight[weight.index<trian_num]\n",
    "# weight_train = weight.copy()\n",
    "print(len(weight_train))\n",
    "print(weight_train.sort_values(ascending=False)[:5])\n",
    "print(weight_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:\n",
      " zczb            0\n",
      "2017q4fphdsl    0\n",
      "2017q4jxsl      0\n",
      "2017q4kpje      0\n",
      "2017q4kps       0\n",
      "dtype: int64\n",
      "mid:\n",
      " jxjeZFSPSTD    0\n",
      "2019q3kpse     0\n",
      "2019q3kpje     0\n",
      "2019q3jxsl     0\n",
      "2019q3jxje     0\n",
      "dtype: int64\n",
      "after:\n",
      " sediffFVALMEAN    0\n",
      "2019q4kpje        0\n",
      "2019q4jxje        0\n",
      "2019q4fphdsl      0\n",
      "2019q3rkse        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"仅加入98个数值特征\"\"\"\n",
    "df = df_raw[val_colname].copy() # 98\n",
    "print(\"before:\\n\",df.isnull().sum().sort_values(ascending=False)[:5])\n",
    "\"\"\" 加入其他特征 \"\"\"\n",
    "Year_Quarter = [\"2017q1\",\"2017q2\",\"2017q3\",\"2017q4\",\"2018q1\",\"2018q2\",\"2018q3\",\"2018q4\",\"2019q1\",\"2019q2\",\"2019q3\",\"2019q4\"]\n",
    "extend_valfeat = []\n",
    "\n",
    "# zczbccyrs 注册资本/从业人数\n",
    "# df[\"zczbccyrs\"] = df[\"zczb\"]/df[\"cyrs\"]\n",
    "# extend_valfeat.append(\"zczbccyrs\")\n",
    "\n",
    "# FPDIFF 发票核定数量差值 \n",
    "for time_prefix in Year_Quarter:\n",
    "    FPHDSL = time_prefix+'fphdsl' # 发票核定数量\n",
    "    KPS = time_prefix+'kps' # 开票数\n",
    "    FPDIFF = time_prefix + 'fpdiff' \n",
    "    fp_diff = df[FPHDSL]-df[KPS] # 差值>0\n",
    "    extend_valfeat.append(FPDIFF)\n",
    "    df[FPDIFF] = fp_diff\n",
    "\n",
    "# JXSE 进项税额=进项金额*进项税率 \n",
    "for time_prefix in Year_Quarter:\n",
    "    JXJE = time_prefix + 'jxje'\n",
    "    JXSL = time_prefix + 'jxsl'\n",
    "    JXSE = time_prefix + 'jxse'\n",
    "    df.loc[df[JXSL]<=0.03,JXSL]=0\n",
    "    jxse = df[JXJE]*df[JXSL]\n",
    "    extend_valfeat.append(JXSE)\n",
    "    df[JXSE] = jxse\n",
    "\n",
    "# CALRKSE 计算的入库税额\n",
    "# SEDIFF 税额差值=(计算的入库税额-入库税额)*I(入库税额>0) \n",
    "# JXYC 进销异常，查看是否存在有进无销或有销无进 (xor)\n",
    "for time_prefix in Year_Quarter:\n",
    "    # CALRKSE\n",
    "    cal_rkse = df[time_prefix+'kpse']-df[time_prefix+'jxse'] # 销项 - 进项\n",
    "    CALRKSE = time_prefix+'calrkse'\n",
    "    extend_valfeat.append(CALRKSE)\n",
    "    df[CALRKSE] = cal_rkse\n",
    "    # SEDIFF\n",
    "    se_diff = (df[time_prefix+'rkse']-cal_rkse)*(df[time_prefix+'rkse']>0)\n",
    "    SEDIFF = time_prefix+'sediff'\n",
    "    extend_valfeat.append(SEDIFF)\n",
    "    df[SEDIFF] = se_diff\n",
    "    # JXYC\n",
    "    has_kpje = df[time_prefix+'kpje'] > 0\n",
    "    has_jxje = df[time_prefix+'jxje'] > 0\n",
    "    JXYC = time_prefix+'jxyc'\n",
    "    extend_valfeat.append(JXYC)\n",
    "    df[JXYC] = has_kpje ^ has_jxje\n",
    "\n",
    "    \n",
    "\"\"\"一些特征的统计值 max,min,mean,std\"\"\"\n",
    "# 发票核定数量 FPHDSL max,min,mean,std\n",
    "# ...\n",
    "def Stat_fea(feat):\n",
    "    global df\n",
    "    feat_vals = []\n",
    "    for time_prefix in Year_Quarter:\n",
    "        colname = time_prefix+feat\n",
    "        feat_vals.append(df[colname].values)\n",
    "    feat_all = []\n",
    "    kpcs = []\n",
    "    for i in range(len(df)):\n",
    "        feat_line = []\n",
    "        for t in range(len(feat_vals)):\n",
    "            now_val = feat_vals[t][i]\n",
    "            if(abs(now_val) < 1e-8): # 特征值为0\n",
    "                continue\n",
    "            feat_line.append(now_val)\n",
    "        feat_line = np.asarray(feat_line)\n",
    "        if(len(feat_line) == 0):\n",
    "            feat_all.append([0,0,0,0,0])\n",
    "            kpcs.append(0)\n",
    "        else:\n",
    "            feat_all.append([feat_line.max(),feat_line.min(),feat_line.mean(),feat_line.std(),feat_line.sum()])\n",
    "            kpcs.append(len(feat_line))\n",
    "    feat_all = np.asarray(feat_all)\n",
    "    feat_names = [feat+'MAX',feat+'MIN',feat+'MEAN',feat+'STD',feat+'SUM']\n",
    "    extend_valfeat.extend(feat_names)\n",
    "    feat_df = pd.DataFrame(feat_all,columns=feat_names)\n",
    "    df = pd.concat([df,feat_df],axis=1)\n",
    "    if(feat == 'fphdsl'):\n",
    "        extend_valfeat.append(\"kpcs\")\n",
    "        df[\"kpcs\"] = kpcs\n",
    "    \n",
    "Stat_fea('fphdsl')\n",
    "Stat_fea('kpje')\n",
    "Stat_fea('jxje') # 强特\n",
    "Stat_fea('rkse') \n",
    "Stat_fea('fpdiff')\n",
    "Stat_fea('calrkse')\n",
    "Stat_fea('sediff')\n",
    "\n",
    "\"\"\"增幅,增幅量/每季度,变化率的max,min,mean,std\"\"\"\n",
    "# 发票核定数量 FPHDSL \n",
    "# 开票金额及 KPJE\n",
    "# 进项金额及 JXJE\n",
    "def ZengFu(feat): # max,min,mean,std\n",
    "    global df\n",
    "    feat_vals = []\n",
    "    for time_prefix in Year_Quarter:\n",
    "        colname = time_prefix+feat\n",
    "        feat_vals.append(df[colname].values)\n",
    "    zf_all = []\n",
    "    ratio_all = []\n",
    "    speed_all = []\n",
    "    for i in range(len(df)):\n",
    "        zf_line = []\n",
    "        ratio_line = []\n",
    "        speed_line = []\n",
    "        pre = 0\n",
    "        last_time = 0\n",
    "        for t in range(len(feat_vals)):\n",
    "            now_val = feat_vals[t][i]\n",
    "            if(abs(now_val) < 1e-8): # 特征值为0\n",
    "                continue\n",
    "            if(abs(pre) > 1e-8):\n",
    "                zf_line.append(now_val - pre)\n",
    "                ratio_line.append((now_val - pre)/pre)\n",
    "                speed_line.append((now_val - pre)/(t-last_time))\n",
    "            pre = now_val\n",
    "            last_time = t\n",
    "        zf_line = np.asarray(zf_line)\n",
    "        ratio_line = np.asarray(ratio_line)\n",
    "        speed_line = np.asarray(speed_line)\n",
    "        if(len(zf_line) == 0):\n",
    "            zf_all.append([0,0,0,0])\n",
    "            ratio_all.append([0,0,0,0])\n",
    "            speed_all.append([0,0,0,0])\n",
    "        else:\n",
    "            zf_all.append([zf_line.max(),zf_line.min(),zf_line.mean(),zf_line.std()])\n",
    "            ratio_all.append([ratio_line.max(),ratio_line.min(),ratio_line.mean(),ratio_line.std()])\n",
    "            speed_all.append([speed_line.max(),speed_line.min(),speed_line.mean(),speed_line.std()])\n",
    "    zf_all = np.asarray(zf_all)\n",
    "    ratio_all = np.asarray(ratio_all)\n",
    "    speed_all = np.asarray(speed_all)\n",
    "    zf_names = [feat+'ZFMAX',feat+'ZFMIN',feat+'ZFMEAN',feat+'ZFSTD']\n",
    "    ratio_names = [feat+'ZFRMAX',feat+'ZFRMIN',feat+'ZFRMEAN',feat+'ZFRSTD']\n",
    "    speed_names = [feat+'ZFSPMAX',feat+'ZFSPMIN',feat+'ZFSPMEAN',feat+'ZFSPSTD']\n",
    "    extend_valfeat.extend(zf_names)\n",
    "    extend_valfeat.extend(ratio_names)\n",
    "    extend_valfeat.extend(speed_names)\n",
    "    zf_df = pd.DataFrame(zf_all,columns=zf_names)\n",
    "    ratio_df = pd.DataFrame(ratio_all,columns=ratio_names)\n",
    "    speed_df = pd.DataFrame(speed_all,columns=speed_names)\n",
    "    df = pd.concat([df,zf_df,ratio_df,speed_df],axis=1)\n",
    "    \n",
    "ZengFu('fphdsl')\n",
    "ZengFu('kpje')\n",
    "ZengFu('jxje')\n",
    "\n",
    "\"\"\"第一次的值，开业时长（月），值/开业时长（每月）\"\"\"\n",
    "# 第一次发票核定数量 FPHDSL\n",
    "...\n",
    "def First_Month(feat):\n",
    "    global df,df_raw\n",
    "    feat_vals = []\n",
    "    for time_prefix in Year_Quarter:\n",
    "        colname = time_prefix+feat\n",
    "        feat_vals.append(df[colname].values)\n",
    "    time = pd.to_datetime(df_raw[\"djrq\"])\n",
    "    year,month,day = time.dt.year, time.dt.month, time.dt.day\n",
    "    first_val = []\n",
    "    for i in range(len(df)):\n",
    "        row_val = [36,0,0]\n",
    "        for t in range(len(feat_vals)):\n",
    "            now_val = feat_vals[t][i]\n",
    "            if(abs(now_val) > 0): # 第一次值不为0\n",
    "# =============== method1 - 94.567 ===================\n",
    "                if(year[i]>2016 or i<10000):\n",
    "                    dmonth = (2017-(year[i]-1))*12 + (12-month[i]) + (t+1)*3\n",
    "                else:\n",
    "                    dmonth = (2017-(year[i]+1))*12 + (12-month[i]) + (t+1)*3\n",
    "                    \n",
    "# =============== method2 - 94.277 ===================\n",
    "#                 dmonth = (2017-(year[i]-1))*12 + (12-month[i]) + (t+1)*3\n",
    "                \n",
    "# =============== method3 - 93.773 ===================\n",
    "#                 if(i<10000):\n",
    "#                     dmonth = (2017-(year[i]-1))*12 + (12-month[i]) + (t+1)*3\n",
    "#                 else:\n",
    "#                     if(year[i]*12+month[i] < 2017*12+(t+1)*3 or (year[i]*12+month[i] <= 2017*12+(t+1)*3 and day[i] < 15)):\n",
    "#                         dmonth = 2017*12+(t+1)*3 - (year[i]*12+month[i])\n",
    "#                     else:\n",
    "#                         dmonth = (2017-(year[i]-1))*12 + (12-month[i]) + (t+1)*3\n",
    "                if(day[i] < 15):\n",
    "                    dmonth += 1\n",
    "                row_val = [dmonth,now_val,now_val/dmonth]\n",
    "                break\n",
    "        first_val.append(row_val)\n",
    "    first_val = np.asarray(first_val)\n",
    "    fv_colname = [feat+\"MONTH\",feat+\"FVAL\",feat+\"FVALMEAN\"] \n",
    "    fv_df = pd.DataFrame(first_val,columns=fv_colname)\n",
    "    if(feat == \"fphdsl\"):\n",
    "        extend_valfeat.extend(fv_colname)\n",
    "    else:\n",
    "        extend_valfeat.extend(fv_colname[1:])\n",
    "        fv_df.drop(feat+\"MONTH\",axis=1,inplace=True)\n",
    "    df = pd.concat([df,fv_df],axis=1)\n",
    "    \n",
    "print(\"mid:\\n\",df.isnull().sum().sort_values(ascending=False)[:5])    \n",
    "First_Month('fphdsl')\n",
    "First_Month('kps')\n",
    "First_Month('fpdiff')\n",
    "First_Month('kpje')\n",
    "First_Month('jxje') #strong\n",
    "First_Month('rkse') #strong\n",
    "First_Month('calrkse')\n",
    "First_Month('sediff')\n",
    "print(\"after:\\n\",df.isnull().sum().sort_values(ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA处理类别特征\n",
    "# from sklearn.decomposition import PCA\n",
    "# # 加入数值和类别特征(转化为one-hot)\n",
    "# # cate_colname = [\"XZJD\",\"HY\",\"HYDL\",\"HYML\",\"HYZL\"]\n",
    "# cate_colname = [\"hy\"]\n",
    "# df_cate = df_raw[cate_colname].copy()\n",
    "\n",
    "# train_num = 20000\n",
    "# for colname in cate_colname:\n",
    "#     cate_train = set(df_cate[colname][:train_num])\n",
    "# #     print(cate_train)\n",
    "#     col_series = df_cate[colname].values.copy()\n",
    "#     for i in range(train_num,len(df_cate)): # test dataset\n",
    "#         if(col_series[i] not in cate_train):\n",
    "#             col_series[i] = 'UNK'\n",
    "#     fea_df = pd.get_dummies(col_series)\n",
    "# #     print(sum(fea_df.sum(axis=1)))\n",
    "#     pca=PCA(n_components=0.9)\n",
    "#     newfea=pca.fit_transform(fea_df)\n",
    "# #     print(newfea_df.shape)\n",
    "#     pca_col = []\n",
    "#     for i in range(newfea.shape[1]):\n",
    "#         pca_col.append(\"pca_{}\".format(i))\n",
    "#     newfea_df = pd.DataFrame(newfea,columns=pca_col)\n",
    "#     df_cate = pd.concat([df_cate,newfea_df],axis=1)\n",
    "#     df_cate.drop(colname,axis=1,inplace=True)\n",
    "# df = pd.concat([df,df_cate],axis=1) \n",
    "# # col_name = df_cate.columns.tolist()\n",
    "# # used_name = set()\n",
    "# # for i,name in enumerate(col_name):\n",
    "# #     if(name in used_name):\n",
    "# #         col_name[i] = name+str(i)\n",
    "# #     else:\n",
    "# #         used_name.add(name)\n",
    "# # print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化\n",
    "df_norm = df.copy()\n",
    "mx = df_norm.max()\n",
    "mx[mx.abs()<1e-8] = 1e-8\n",
    "df_norm = (df_norm-df_norm.min())/(mx-df_norm.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of train_set: 9000\n",
      "num of feat: 91\n",
      "num of valid_set: 1000\n",
      "num of test_set: 6000\n",
      "[0]\tvalidation_0-logloss:0.101462\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044724\n",
      "\n",
      "-- xgb best acc: 95.5276012184011\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101457\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.048279\n",
      "\n",
      "-- xgb best acc: 95.17212392003276\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10128\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041723\n",
      "\n",
      "-- xgb best acc: 95.82773717918026\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101359\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.043138\n",
      "\n",
      "-- xgb best acc: 95.68623955762014\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101398\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.040779\n",
      "\n",
      "-- xgb best acc: 95.9220976837125\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101378\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041422\n",
      "\n",
      "-- xgb best acc: 95.85781650883145\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101438\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042349\n",
      "\n",
      "-- xgb best acc: 95.76514706418384\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101505\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042339\n",
      "\n",
      "-- xgb best acc: 95.76614372881741\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101416\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041618\n",
      "\n",
      "-- xgb best acc: 95.83816716040019\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101361\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042752\n",
      "\n",
      "-- xgb best acc: 95.72476009686943\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101337\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.047234\n",
      "\n",
      "-- xgb best acc: 95.27663952363655\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101352\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044167\n",
      "\n",
      "-- xgb best acc: 95.58326890467434\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10135\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04165\n",
      "\n",
      "-- xgb best acc: 95.83495976556442\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101361\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.043327\n",
      "\n",
      "-- xgb best acc: 95.6672550777148\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101382\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041639\n",
      "\n",
      "-- xgb best acc: 95.8361122667964\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101356\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.042402\n",
      "\n",
      "-- xgb best acc: 95.75979238344445\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10138\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043545\n",
      "\n",
      "-- xgb best acc: 95.64546098282736\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101305\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041766\n",
      "\n",
      "-- xgb best acc: 95.82339383105864\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101431\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.047016\n",
      "\n",
      "-- xgb best acc: 95.29835837539868\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101372\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044716\n",
      "\n",
      "-- xgb best acc: 95.5283963929047\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10133\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042162\n",
      "\n",
      "-- xgb best acc: 95.7838004213525\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101373\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[9]\tvalidation_0-logloss:0.044596\n",
      "\n",
      "-- xgb best acc: 95.54041447322857\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101347\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041531\n",
      "\n",
      "-- xgb best acc: 95.84690290686558\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101345\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.045731\n",
      "\n",
      "-- xgb best acc: 95.42691343451297\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101328\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043159\n",
      "\n",
      "-- xgb best acc: 95.68409764562966\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101469\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044236\n",
      "\n",
      "-- xgb best acc: 95.57640699441545\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101414\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.040912\n",
      "\n",
      "-- xgb best acc: 95.908807560063\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101319\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.041464\n",
      "\n",
      "-- xgb best acc: 95.85364810787287\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101437\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042588\n",
      "\n",
      "-- xgb best acc: 95.74121204731637\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101414\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043891\n",
      "\n",
      "-- xgb best acc: 95.61094829498906\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101416\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043023\n",
      "\n",
      "-- xgb best acc: 95.69771313181263\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10139\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042797\n",
      "\n",
      "-- xgb best acc: 95.72032873299322\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101326\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041578\n",
      "\n",
      "-- xgb best acc: 95.8422003271553\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101366\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045642\n",
      "\n",
      "-- xgb best acc: 95.43577156024404\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101419\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04393\n",
      "\n",
      "-- xgb best acc: 95.60699191388848\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101441\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.04194\n",
      "\n",
      "-- xgb best acc: 95.80599605758762\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101394\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.046194\n",
      "\n",
      "-- xgb best acc: 95.3805851784913\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101375\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[7]\tvalidation_0-logloss:0.043043\n",
      "\n",
      "-- xgb best acc: 95.69568005346663\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101312\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04251\n",
      "\n",
      "-- xgb best acc: 95.74897150167962\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101391\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042269\n",
      "\n",
      "-- xgb best acc: 95.77307051457464\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101375\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.047233\n",
      "\n",
      "-- xgb best acc: 95.27668713274178\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101363\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042793\n",
      "\n",
      "-- xgb best acc: 95.72072807314981\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101424\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.041868\n",
      "\n",
      "-- xgb best acc: 95.81317752215546\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101361\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044018\n",
      "\n",
      "-- xgb best acc: 95.59819268382853\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101381\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042491\n",
      "\n",
      "-- xgb best acc: 95.7509421575116\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101402\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042557\n",
      "\n",
      "-- xgb best acc: 95.74429991264188\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101414\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041426\n",
      "\n",
      "-- xgb best acc: 95.85737833522143\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101456\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.046352\n",
      "\n",
      "-- xgb best acc: 95.36483008352079\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101338\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041887\n",
      "\n",
      "-- xgb best acc: 95.81127300724039\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101361\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04371\n",
      "\n",
      "-- xgb best acc: 95.62899886799859\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101409\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041678\n",
      "\n",
      "-- xgb best acc: 95.83221488290292\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101339\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041644\n",
      "\n",
      "-- xgb best acc: 95.83561321597081\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101396\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041484\n",
      "\n",
      "-- xgb best acc: 95.85161992078065\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101411\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.0429\n",
      "\n",
      "-- xgb best acc: 95.70999300157855\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101338\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.045096\n",
      "\n",
      "-- xgb best acc: 95.49044846211909\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10129\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041515\n",
      "\n",
      "-- xgb best acc: 95.84846868413733\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101393\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042109\n",
      "\n",
      "-- xgb best acc: 95.78906906863558\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101365\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041996\n",
      "\n",
      "-- xgb best acc: 95.8003607316612\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101349\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043518\n",
      "\n",
      "-- xgb best acc: 95.64817728573689\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101331\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041526\n",
      "\n",
      "-- xgb best acc: 95.84744218135019\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101337\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042406\n",
      "\n",
      "-- xgb best acc: 95.75944919203467\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101331\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.041609\n",
      "\n",
      "-- xgb best acc: 95.83911442770187\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101408\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043521\n",
      "\n",
      "-- xgb best acc: 95.64793088234146\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101339\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044247\n",
      "\n",
      "-- xgb best acc: 95.57526105321013\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101353\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042853\n",
      "\n",
      "-- xgb best acc: 95.71469351849518\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101365\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.046696\n",
      "\n",
      "-- xgb best acc: 95.33042306542048\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101387\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044634\n",
      "\n",
      "-- xgb best acc: 95.53660996106919\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101258\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044681\n",
      "\n",
      "-- xgb best acc: 95.53189664368983\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101348\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04542\n",
      "\n",
      "-- xgb best acc: 95.45799087219639\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101278\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043935\n",
      "\n",
      "-- xgb best acc: 95.60649289367721\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10132\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.046073\n",
      "\n",
      "-- xgb best acc: 95.39271384659223\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101368\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044371\n",
      "\n",
      "-- xgb best acc: 95.56292664552166\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101422\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041888\n",
      "\n",
      "-- xgb best acc: 95.81116183084669\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101282\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042826\n",
      "\n",
      "-- xgb best acc: 95.71743110015522\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101325\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.048453\n",
      "\n",
      "-- xgb best acc: 95.1546664952999\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101326\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045524\n",
      "\n",
      "-- xgb best acc: 95.44761405017925\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10132\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041454\n",
      "\n",
      "-- xgb best acc: 95.8545926821389\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101411\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041555\n",
      "\n",
      "-- xgb best acc: 95.84451704221428\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101431\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04368\n",
      "\n",
      "-- xgb best acc: 95.63202589972352\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101406\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045022\n",
      "\n",
      "-- xgb best acc: 95.49774933482986\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101406\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042576\n",
      "\n",
      "-- xgb best acc: 95.74236314228037\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101302\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041641\n",
      "\n",
      "-- xgb best acc: 95.83586591654458\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101412\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045606\n",
      "\n",
      "-- xgb best acc: 95.43937461512397\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101368\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041523\n",
      "\n",
      "-- xgb best acc: 95.84768855955917\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101312\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.045477\n",
      "\n",
      "-- xgb best acc: 95.45233929168899\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101368\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045165\n",
      "\n",
      "-- xgb best acc: 95.48348483212757\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101348\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.047369\n",
      "\n",
      "-- xgb best acc: 95.26315110604628\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101367\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045955\n",
      "\n",
      "-- xgb best acc: 95.40451926267706\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101409\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041443\n",
      "\n",
      "-- xgb best acc: 95.85568559937528\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101335\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042695\n",
      "\n",
      "-- xgb best acc: 95.730539927067\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10136\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[20]\tvalidation_0-logloss:0.044132\n",
      "\n",
      "-- xgb best acc: 95.58683464276504\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101464\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[4]\tvalidation_0-logloss:0.050899\n",
      "\n",
      "-- xgb best acc: 94.91005773976686\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101284\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.047518\n",
      "\n",
      "-- xgb best acc: 95.24823992748861\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101428\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042195\n",
      "\n",
      "-- xgb best acc: 95.78049250631884\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101496\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042673\n",
      "\n",
      "-- xgb best acc: 95.73266272070178\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101287\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044681\n",
      "\n",
      "-- xgb best acc: 95.53191927482548\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101399\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041753\n",
      "\n",
      "-- xgb best acc: 95.82470638673404\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101451\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041662\n",
      "\n",
      "-- xgb best acc: 95.83376935835113\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101433\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041846\n",
      "\n",
      "-- xgb best acc: 95.81544215241301\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101389\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043631\n",
      "\n",
      "-- xgb best acc: 95.63689388388302\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101377\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.045324\n",
      "\n",
      "-- xgb best acc: 95.46760345762013\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101382\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-logloss:0.045888\n",
      "\n",
      "-- xgb best acc: 95.41118611689416\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101351\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.042263\n",
      "\n",
      "-- xgb best acc: 95.77375037968159\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101415\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04184\n",
      "\n",
      "-- xgb best acc: 95.81603856575093\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101323\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.05075\n",
      "\n",
      "-- xgb best acc: 94.92496668638196\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101315\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043131\n",
      "\n",
      "-- xgb best acc: 95.68689461618196\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10138\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042576\n",
      "\n",
      "-- xgb best acc: 95.74242886263528\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101326\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041539\n",
      "\n",
      "-- xgb best acc: 95.84609998015222\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101449\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043793\n",
      "\n",
      "-- xgb best acc: 95.62074742605037\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101324\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043689\n",
      "\n",
      "-- xgb best acc: 95.6310642796394\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101312\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044858\n",
      "\n",
      "-- xgb best acc: 95.51417898137296\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101346\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041478\n",
      "\n",
      "-- xgb best acc: 95.85217762897665\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101401\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042574\n",
      "\n",
      "-- xgb best acc: 95.74265020264137\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10138\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041645\n",
      "\n",
      "-- xgb best acc: 95.83548788767658\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101381\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044464\n",
      "\n",
      "-- xgb best acc: 95.55359034677967\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101406\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.052405\n",
      "\n",
      "-- xgb best acc: 94.75952913471265\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101362\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.049288\n",
      "\n",
      "-- xgb best acc: 95.07124197830562\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101444\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042473\n",
      "\n",
      "-- xgb best acc: 95.7526581872924\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101336\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041544\n",
      "\n",
      "-- xgb best acc: 95.84562035747221\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101357\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04182\n",
      "\n",
      "-- xgb best acc: 95.81800577485993\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101316\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.040765\n",
      "\n",
      "-- xgb best acc: 95.92349877399829\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101286\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041573\n",
      "\n",
      "-- xgb best acc: 95.84271046148206\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101371\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042697\n",
      "\n",
      "-- xgb best acc: 95.73025170731125\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101286\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041808\n",
      "\n",
      "-- xgb best acc: 95.81921458922443\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101358\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045588\n",
      "\n",
      "-- xgb best acc: 95.44116874976316\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101479\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044339\n",
      "\n",
      "-- xgb best acc: 95.56610563359136\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101391\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042788\n",
      "\n",
      "-- xgb best acc: 95.72117008202767\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101374\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041433\n",
      "\n",
      "-- xgb best acc: 95.85672291362425\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101378\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042893\n",
      "\n",
      "-- xgb best acc: 95.71074768275722\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101384\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041415\n",
      "\n",
      "-- xgb best acc: 95.85852121351635\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101385\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04677\n",
      "\n",
      "-- xgb best acc: 95.32300561828306\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101301\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045681\n",
      "\n",
      "-- xgb best acc: 95.43187878779136\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101404\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041583\n",
      "\n",
      "-- xgb best acc: 95.8416616011178\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101353\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.046534\n",
      "\n",
      "-- xgb best acc: 95.34660189193673\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101333\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041445\n",
      "\n",
      "-- xgb best acc: 95.85554195431759\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101288\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043893\n",
      "\n",
      "-- xgb best acc: 95.61074001408414\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101397\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041577\n",
      "\n",
      "-- xgb best acc: 95.84231606597314\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10136\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042124\n",
      "\n",
      "-- xgb best acc: 95.78761998481932\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101397\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042215\n",
      "\n",
      "-- xgb best acc: 95.77850039171172\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101373\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04145\n",
      "\n",
      "-- xgb best acc: 95.85498292000848\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101328\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041663\n",
      "\n",
      "-- xgb best acc: 95.83371765373158\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101315\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041848\n",
      "\n",
      "-- xgb best acc: 95.81523305764422\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101327\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.046686\n",
      "\n",
      "-- xgb best acc: 95.33143084932235\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101386\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045557\n",
      "\n",
      "-- xgb best acc: 95.44428983384569\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101419\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041548\n",
      "\n",
      "-- xgb best acc: 95.84516696288483\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101432\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045797\n",
      "\n",
      "-- xgb best acc: 95.4202791401418\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10144\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044651\n",
      "\n",
      "-- xgb best acc: 95.53485876923078\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10146\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044281\n",
      "\n",
      "-- xgb best acc: 95.57189124095312\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10143\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041498\n",
      "\n",
      "-- xgb best acc: 95.85020595741808\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101407\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045797\n",
      "\n",
      "-- xgb best acc: 95.42032537910853\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101341\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.047482\n",
      "\n",
      "-- xgb best acc: 95.25176659680437\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10135\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041526\n",
      "\n",
      "-- xgb best acc: 95.84735656105913\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101384\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04205\n",
      "\n",
      "-- xgb best acc: 95.7949713850714\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101317\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042157\n",
      "\n",
      "-- xgb best acc: 95.78425074203697\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101345\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041806\n",
      "\n",
      "-- xgb best acc: 95.81936403232393\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101487\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[40]\tvalidation_0-logloss:0.040867\n",
      "\n",
      "-- xgb best acc: nan\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101361\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: RuntimeWarning: divide by zero encountered in log\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042703\n",
      "\n",
      "-- xgb best acc: 95.7296930843353\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101424\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.046115\n",
      "\n",
      "-- xgb best acc: 95.38848399216803\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.1014\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.040829\n",
      "\n",
      "-- xgb best acc: 95.91714114690548\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101358\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042787\n",
      "\n",
      "-- xgb best acc: 95.72126569985994\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101305\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041912\n",
      "\n",
      "-- xgb best acc: 95.80880687877507\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101391\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044288\n",
      "\n",
      "-- xgb best acc: 95.57117777100648\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101419\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.046222\n",
      "\n",
      "-- xgb best acc: 95.37782637720811\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101281\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041506\n",
      "\n",
      "-- xgb best acc: 95.84936762159631\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101425\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045508\n",
      "\n",
      "-- xgb best acc: 95.44918194220809\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101443\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.048983\n",
      "\n",
      "-- xgb best acc: 95.10169968918781\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10131\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045709\n",
      "\n",
      "-- xgb best acc: 95.42910652975551\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101416\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04164\n",
      "\n",
      "-- xgb best acc: 95.83596907323226\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10145\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.046984\n",
      "\n",
      "-- xgb best acc: 95.30156784101855\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101396\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.041507\n",
      "\n",
      "-- xgb best acc: 95.8492796635095\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.106401\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045278\n",
      "\n",
      "-- xgb best acc: 95.4721529580449\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101381\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[26]\tvalidation_0-logloss:0.053479\n",
      "\n",
      "-- xgb best acc: nan\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10137\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041887\n",
      "\n",
      "-- xgb best acc: 95.8113077424001\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101468\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044095\n",
      "\n",
      "-- xgb best acc: 95.5904608814395\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101375\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041659\n",
      "\n",
      "-- xgb best acc: 95.83408568697051\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101368\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045263\n",
      "\n",
      "-- xgb best acc: 95.47366631318873\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101417\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04166\n",
      "\n",
      "-- xgb best acc: 95.83403387364815\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.10148\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042168\n",
      "\n",
      "-- xgb best acc: 95.7832224008569\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101327\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041911\n",
      "\n",
      "-- xgb best acc: 95.8089406424202\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101489\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.047127\n",
      "\n",
      "-- xgb best acc: 95.2872778820456\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101391\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041967\n",
      "\n",
      "-- xgb best acc: 95.8033388206677\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101436\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.045761\n",
      "\n",
      "-- xgb best acc: 95.42386074457899\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101402\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04889\n",
      "\n",
      "-- xgb best acc: 95.11100445145857\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101413\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.044146\n",
      "\n",
      "-- xgb best acc: 95.58541855872318\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101435\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[37]\tvalidation_0-logloss:0.041462\n",
      "\n",
      "-- xgb best acc: 95.85378986647355\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101353\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041999\n",
      "\n",
      "-- xgb best acc: 95.80006458770657\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101395\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.0415\n",
      "\n",
      "-- xgb best acc: 95.850024634719\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101394\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.043457\n",
      "\n",
      "-- xgb best acc: 95.65432702500839\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101347\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.040797\n",
      "\n",
      "-- xgb best acc: 95.92033161344298\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101449\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041529\n",
      "\n",
      "-- xgb best acc: 95.84714070370536\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101434\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.043104\n",
      "\n",
      "-- xgb best acc: 95.68963246110798\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101419\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.04235\n",
      "\n",
      "-- xgb best acc: 95.76495800195843\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101343\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.048608\n",
      "\n",
      "-- xgb best acc: 95.1392321467807\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101439\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3]\tvalidation_0-logloss:0.040703\n",
      "\n",
      "-- xgb best acc: 95.92970691033553\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101434\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041754\n",
      "\n",
      "-- xgb best acc: 95.82463378159446\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.106251\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.045424\n",
      "\n",
      "-- xgb best acc: 95.45765073496149\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101411\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041657\n",
      "\n",
      "-- xgb best acc: 95.83427534904914\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101427\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.042016\n",
      "\n",
      "-- xgb best acc: 95.7983770752151\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.111231\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.047245\n",
      "\n",
      "-- xgb best acc: 95.27546285307835\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.101375\n",
      "Will train until validation_0-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-logloss:0.041466\n",
      "\n",
      "-- xgb best acc: 95.85340348345635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "\n",
    "# # custom eval_metric\n",
    "# def weight_ce_lgb(y, pred):\n",
    "# #     score = (1-np.abs(1/np.sum(weight)*np.sum((y*np.log(pred) + (1-y)*np.log(1-pred))*weight)))*100 # 带权重的交叉熵\n",
    "#     score = -1/len(y)*np.sum(0.9*y*np.log(pred) + 0.1*(1-y)*np.log(1-pred))\n",
    "#     return 'Weight_CE', score, False\n",
    "\n",
    "# # custom eval_metric\n",
    "# def weight_ce_xgb(y,pred):\n",
    "# #     y = dtrain.get_label()\n",
    "# #     weight = dtrain.get_weight()\n",
    "#     score = -1/len(y)*np.sum(0.9*y*np.log(pred) + 0.1*(1-y)*np.log(1-pred))\n",
    "# #     score = -1/np.sum(weight)*np.sum((y*np.log(predt) + (1-y)*np.log(1-predt))*weight) # 带权重的交叉熵\n",
    "#     # score = (1-np.abs(1/np.sum(weight)*np.sum((y*np.log(predt) + (1-y)*np.log(1-predt))*weight)))*100 # 带权重的交叉熵\n",
    "#     return 'Weight_CE', score\n",
    "\n",
    "\n",
    "# 模型预测\n",
    "def score_func(y,pred):\n",
    "    yc_num = int(len(y)*0.5)\n",
    "    acc = (1 - np.abs((1/yc_num)*np.sum(0.5*y*np.log(pred) + 0.5*(1-y)*np.log(1-pred))))*100\n",
    "    return acc\n",
    "\n",
    "# stacking\n",
    "def get_stacking(clf_tp,train_set, val_set,weight=None,verbose=100):\n",
    "    model_name,clf = clf_tp[0],clf_tp[1]\n",
    "    X_train, y_train = train_set[0], train_set[1]\n",
    "    X_val, y_val =  val_set[0], val_set[1]\n",
    "    train_num = X_train.shape[0]\n",
    "    if(model_name in ['lgb_gbdt','lgb_rf']):\n",
    "        clf.fit(X=X_train,y=y_train,sample_weight=weight,eval_set=[(X_val,y_val)],\\\n",
    "                early_stopping_rounds=50,verbose=verbose)\n",
    "    elif(model_name == 'xgb'):\n",
    "        clf.fit(X=X_train,y=y_train,sample_weight=weight,eval_set=[(X_val,y_val)],\\\n",
    "                early_stopping_rounds=50,verbose=verbose,eval_metric='logloss')\n",
    "    elif(model_name == 'nn'):\n",
    "        clf.fit(X_train, y_train)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train, sample_weight=weight) # 模型训练\n",
    "    second_level_train_set = clf.predict_proba(X_val)[:,1] \n",
    " \n",
    "    return second_level_train_set, clf\n",
    "\n",
    "drop_col = []\n",
    "for ele in df.columns:\n",
    "    if(str.isdigit(ele[:4])):\n",
    "        drop_col.append(ele)\n",
    "# df_drop = df.drop(drop_col,axis=1) # drop掉12个季度的数值特征\n",
    "df_drop = df_norm.drop(drop_col,axis=1) # drop掉12个季度的数值特征\n",
    "# df_drop = df[val_colname]\n",
    "\"\"\"训练集\"\"\"\n",
    "train_num = 9000\n",
    "train_X = df_drop[:train_num].values\n",
    "train_y = df_raw[\"yc\"][:train_num].values\n",
    "print('num of train_set:',train_X.shape[0])\n",
    "print('num of feat:',train_X.shape[1])\n",
    "train_dataset = (train_X,train_y)\n",
    "\n",
    "\"\"\"验证集\"\"\"\n",
    "valid_X = df_drop[train_num:10000].values\n",
    "valid_y = df_raw[\"yc\"][train_num:10000].values\n",
    "print('num of valid_set:',valid_X.shape[0])\n",
    "val_dataset = (valid_X,valid_y)\n",
    "\n",
    "\"\"\"测试集\"\"\"\n",
    "test_X = df_drop[10000:].values\n",
    "print('num of test_set:',test_X.shape[0])\n",
    "\n",
    "\"\"\"模型选择\"\"\"\n",
    "num_round = 200\n",
    "# lgb_gbdt = lgb.LGBMClassifier(boosting_type='gbdt',objective = 'binary' ,n_estimators = num_round, learning_rate = 0.1,max_depth=-1,\\\n",
    "#                          reg_alpha=0.1,num_leaves = 35,feature_fraction=0.9,bagging_fraction= 0.9,bagging_freq= 8,subsample = 0.7,\\\n",
    "#                          lambda_l1= 0.6,lambda_l2= 0,n_jobs = 8,random_state=0)\n",
    "# lgb_rf = lgb.LGBMClassifier(boosting_type='rf',objective = 'binary',n_estimators = num_round, learning_rate = 0.1,\\\n",
    "#                          num_leaves = 60,feature_fraction=0.7,bagging_fraction= 0.9,bagging_freq= 8,subsample = 0.7,\\\n",
    "#                          lambda_l1= 0.6,lambda_l2= 0,n_jobs = 8,random_state=33)\n",
    "# xgb_model = xgb.XGBClassifier(n_estimators=num_round,max_depth=3,learning_rate=2.5,gamma=0,min_child_weight=1,max_delta_step=2,\\\n",
    "#                         subsample=0.75,colsample_bytree=0.7,reg_alpha=0,reg_lambda=0.6,scale_pos_weight=1,n_jobs=8,random_state=30)\n",
    "# svc = SVC(C=100,probability=True)\n",
    "# lr = LogisticRegression(max_iter=num_round)\n",
    "# nn = MLPClassifier(solver='adam',activation = 'relu',max_iter = num_round,alpha = 1e-5,learning_rate_init=0.001,validation_fraction=0.1,\\\n",
    "#                    hidden_layer_sizes = (64,64),random_state = 1,verbose = 50,early_stopping=True,n_iter_no_change=50)\n",
    "# model_sets = [(\"xgb\",xgb_model),(\"lgb_gbdt\",lgb_gbdt),(\"nn\",nn),(\"rf\",rf_model)]\n",
    "# model_sets = [(\"xgb\",xgb_model)]\n",
    "\"\"\"底层分类器\"\"\"\n",
    "model_sets = []\n",
    "for seed in range(200,400):\n",
    "    xgb_model = xgb.XGBClassifier(n_estimators=num_round,max_depth=3,learning_rate=2.5,gamma=0,min_child_weight=1,max_delta_step=2,\\\n",
    "                        subsample=0.75,colsample_bytree=0.7,reg_alpha=0,reg_lambda=0.6,scale_pos_weight=1,n_jobs=8,random_state=seed)\n",
    "    model_sets.append((\"xgb\",xgb_model))\n",
    "train_predsets = []\n",
    "model_train = []\n",
    "weight = weight_train.values\n",
    "for i,clf_tp in enumerate(model_sets):\n",
    "#     train_pred, clf = get_stacking(clf_tp,train_dataset,val_dataset,weight=np.ones(train_num))\n",
    "    train_pred, clf = get_stacking(clf_tp,train_dataset,val_dataset,weight=weight[:train_num])\n",
    "    pred = clf.predict_proba(valid_X)[:,1]\n",
    "    acc = score_func(valid_y,pred)\n",
    "    print(\"-- {} best acc: {}\\n\".format(clf_tp[0],acc))\n",
    "    train_predsets.append(train_pred) # [M,N] - N为样本数,M为模型数\n",
    "    model_train.append(clf)\n",
    "meta_train = np.concatenate([result_set.reshape(-1,1) for result_set in train_predsets], axis=1) #meta feature (N,M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-id:19\n",
      "程序开始运行时间为：2019-12-22 12:12:50.677992\n",
      "程序结束运行时间为：2019-12-22 12:12:51.325736\n",
      "程序运行时间（去除打分耗时）为：0.647744\n",
      "程序的准确率为：95.57256964\n",
      "最终得分为：96.01531267\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 元分类器 \"\"\"\n",
    "# ==================== sklearn clf ========================\n",
    "meta_clf = LogisticRegression(max_iter=num_round,C=25,penalty='l2',solver='sag',warm_start=True) # 逻辑回归 89.198\n",
    "# meta_clf = MLPClassifier(solver='adam',activation = 'logistic',max_iter = 200,alpha = 1e-5,learning_rate_init=0.001,validation_fraction=0.1,\\\n",
    "#                    hidden_layer_sizes = (100),random_state = 1,verbose = 50)\n",
    "# meta_clf = RandomForestClassifier(verbose=1) # 随机森林 \n",
    "# meta_clf = SVC(C=3,probability=True) # SVM # 84.96216\n",
    "# meta_clf = AdaBoostClassifier() # 65.692\n",
    "meta_clf.fit(meta_train, valid_y)\n",
    "\n",
    "# ===================== other clf ==========================\n",
    "# num_round_meta = 1000\n",
    "# meta_clf = lgb.LGBMClassifier(boosting_type='gbdt',objective = 'binary' ,n_estimators = num_round_meta, learning_rate = 0.01,max_depth=6,\\\n",
    "#                          reg_alpha=0.1,num_leaves = 35,feature_fraction=0.9,bagging_fraction= 0.9,bagging_freq= 8,subsample = 0.7,\\\n",
    "#                          lambda_l1= 0.6,lambda_l2= 0,n_jobs = 8,random_state=33)\n",
    "# lgb_rf = lgb.LGBMClassifier(boosting_type='rf',objective = 'binary',n_estimators = num_round, learning_rate = 0.01,\\\n",
    "#                          num_leaves = 35,feature_fraction=0.7,bagging_fraction= 0.9,bagging_freq= 8,subsample = 0.7,\\\n",
    "#                          lambda_l1= 0.6,lambda_l2= 0,n_jobs = 8,random_state=34)\n",
    "# xgb_model = xgb.XGBClassifier(max_depth=3, learning_rate=0.1,n_estimators=num_round,n_jobs=8,gamma=0.1,reg_alpha=0,reg_lambda=2,\\\n",
    "#                               colsample_bytree=0.7,min_child_weight=3, subsample=0.7,random_state=35)\n",
    "\n",
    "# meta_clf.fit(X=meta_train,y=train_y,sample_weight=weight,eval_set=[(test_X,test_y)],\\\n",
    "#                 early_stopping_rounds=100,verbose=100)\n",
    "\n",
    "#计时打分程序\n",
    "from ustciscrBDL_B import get_score\n",
    "get_score.post_user_id('19')\n",
    "test_sets = []\n",
    "for clf in model_train:\n",
    "    pred = clf.predict_proba(test_X)[:,1]\n",
    "    test_sets.append(pred)\n",
    "meta_test = np.concatenate([y_test_set.reshape(-1,1) for y_test_set in test_sets], axis=1) # (N, M)\n",
    "final_pred = meta_clf.predict_proba(meta_test)[:,1]\n",
    "# final_pred = meta_test.mean(axis=-1)\n",
    "user_verify_data = pd.DataFrame({'zjnsrsbh':df_raw['zjnsrsbh'][10000:],'Probability':final_pred})\n",
    "get_score.post_verify_data(user_verify_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import KFold\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "# from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier, ExtraTreesClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import LinearSVC,SVC\n",
    "\n",
    "# # # custom eval_metric\n",
    "# # def weight_ce_lgb(y, pred):\n",
    "# # #     score = (1-np.abs(1/np.sum(weight)*np.sum((y*np.log(pred) + (1-y)*np.log(1-pred))*weight)))*100 # 带权重的交叉熵\n",
    "# #     score = -1/len(y)*np.sum(0.9*y*np.log(pred) + 0.1*(1-y)*np.log(1-pred))\n",
    "# #     return 'Weight_CE', score, False\n",
    "\n",
    "# # # custom eval_metric\n",
    "# # def weight_ce_xgb(y,pred):\n",
    "# # #     y = dtrain.get_label()\n",
    "# # #     weight = dtrain.get_weight()\n",
    "# #     score = -1/len(y)*np.sum(0.9*y*np.log(pred) + 0.1*(1-y)*np.log(1-pred))\n",
    "# # #     score = -1/np.sum(weight)*np.sum((y*np.log(predt) + (1-y)*np.log(1-predt))*weight) # 带权重的交叉熵\n",
    "# #     # score = (1-np.abs(1/np.sum(weight)*np.sum((y*np.log(predt) + (1-y)*np.log(1-predt))*weight)))*100 # 带权重的交叉熵\n",
    "# #     return 'Weight_CE', score\n",
    "\n",
    "# def get_stacking(clf, model_name, x_train, y_train, kf, weight=None):\n",
    "#     \"\"\"\n",
    "#     这个函数是stacking的核心，使用交叉验证的方法得到次级训练集\n",
    "#     x_train, y_train 的值应该为numpy里面的数组类型 numpy.ndarray .\n",
    "#     \"\"\"\n",
    "#     train_num = x_train.shape[0]\n",
    "#     second_level_train_set = np.zeros((train_num,))\n",
    "#     models = []\n",
    "#     for i,(train_index, test_index) in enumerate(kf.split(x_train,y_train)):\n",
    "#         x_tra, y_tra = x_train[train_index], y_train[train_index]\n",
    "#         x_tst, y_tst =  x_train[test_index], y_train[test_index]\n",
    "        \n",
    "#         if(model_name in ['lgb_gbdt','lgb_rf']):\n",
    "#             clf.fit(X=train_X,y=train_y,sample_weight=weight,eval_set=[(x_tst,y_tst)],\\\n",
    "#                     early_stopping_rounds=50,verbose=100)\n",
    "#         elif(model_name == 'xgb'):\n",
    "#             clf.fit(X=train_X,y=train_y,sample_weight=weight,eval_set=[(x_tst,y_tst)],early_stopping_rounds=50,verbose=100,eval_metric='logloss')\n",
    "#         else:\n",
    "#             clf.fit(x_tra, y_tra, sample_weight=weight[train_index]) # 模型训练\n",
    "#         models.append(clf)\n",
    "#         second_level_train_set[test_index] = clf.predict_proba(x_tst)[:,1] # 训练集预测概率,k折后拼成完整\n",
    "# #             second_level_train_set[test_index] = clf.predict(x_tst)\n",
    "#         # test_nfolds_sets[:,i] = clf.predict_proba(x_test)[:,1] # k折每次都预测测试集\n",
    " \n",
    "#     return second_level_train_set, models\n",
    "\n",
    "\n",
    "\n",
    "# num_round = 2000 \n",
    "# lgb_gbdt = lgb.LGBMClassifier(boosting_type='gbdt',objective = 'binary' ,n_estimators = num_round, learning_rate = 0.01,max_depth=6,\\\n",
    "#                          reg_alpha=0.1,num_leaves = 35,feature_fraction=0.9,bagging_fraction= 0.9,bagging_freq= 8,subsample = 0.7,\\\n",
    "#                          lambda_l1= 0.6,lambda_l2= 0,n_jobs = 8,random_state=33)\n",
    "# lgb_rf = lgb.LGBMClassifier(boosting_type='rf',objective = 'binary',n_estimators = num_round, learning_rate = 0.01,\\\n",
    "#                          num_leaves = 35,feature_fraction=0.7,bagging_fraction= 0.9,bagging_freq= 8,subsample = 0.7,\\\n",
    "#                          lambda_l1= 0.6,lambda_l2= 0,n_jobs = 8,random_state=34)\n",
    "# xgb_model = xgb.XGBClassifier(max_depth=3, learning_rate=0.1,n_estimators=num_round,n_jobs=8,gamma=0.1,reg_alpha=0,reg_lambda=2,\\\n",
    "#                               colsample_bytree=0.7,min_child_weight=3, subsample=0.7,random_state=35)\n",
    "# # svc = LinearSVC()\n",
    "# rf_model = RandomForestClassifier(verbose=1)\n",
    "# # adb_model = AdaBoostClassifier()\n",
    "# # gdbc_model = GradientBoostingClassifier()\n",
    "# # et_model = ExtraTreesClassifier()\n",
    "\n",
    "# drop_col = []\n",
    "# for ele in df.columns:\n",
    "#     if(str.isdigit(ele[:4])):\n",
    "#         drop_col.append(ele)\n",
    "# df_drop = df.drop(drop_col,axis=1) # drop掉12个季度的数值特征\n",
    "# # df_drop = df[val_colname]\n",
    "# \"\"\"训练集\"\"\"\n",
    "# train_num = 10000\n",
    "# train_X = df_drop[:train_num].values\n",
    "# train_y = df_raw[\"yc\"][:train_num].values\n",
    "# print('num of train_set:',train_X.shape[0])\n",
    "# print('num of feat:',train_X.shape[1])\n",
    "\n",
    "# \"\"\"测试集\"\"\"\n",
    "# test_X = df_drop[train_num:].values\n",
    "# test_y = df_raw[\"yc\"][train_num:].values\n",
    "# train_sets = []\n",
    "# n_folds = 5\n",
    "# kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=33)\n",
    "# # model_sets = [xgb_model,lgb_gbdt,rf_model]\n",
    "# # model_name = ['xgb','lgb_gbdt','rf_model']\n",
    "# model_sets = [rf_model]\n",
    "# model_name = ['rf_model']\n",
    "# model_train = []\n",
    "# for i,clf in enumerate(model_sets):\n",
    "#     train_set, models = get_stacking(clf, model_name[i], train_X, train_y, kf, weight=np.ones(train_num))\n",
    "# #     train_set, models = get_stacking(clf, model_name[i], train_X, train_y, kf, weight=weight_train)\n",
    "#     train_sets.append(train_set) # [M,N1] - N1为样本数,M为模型数\n",
    "#     model_train.append(models)\n",
    "\n",
    "# meta_train = np.concatenate([result_set.reshape(-1,1) for result_set in train_sets], axis=1)\n",
    "\n",
    "# #使用逻辑回归作为我们的次级分类器\n",
    "# lr = LogisticRegression(max_iter=num_round)\n",
    "# lr.fit(meta_train, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_prob_stacking(text_X, trained_model,clf,n_folds):\n",
    "#     test_sets = []\n",
    "#     for model in trained_model:\n",
    "#         model_res = np.zeros((len(test_X), n_folds))\n",
    "#         for i,sub_model in enumerate(model):\n",
    "#             pred = sub_model.predict_proba(test_X)[:,1]\n",
    "#             model_res[:,i] = pred\n",
    "#         res = np.mean(model_res,axis=1)\n",
    "#         test_sets.append(res)\n",
    "#     meta_test = np.concatenate([y_test_set.reshape(-1,1) for y_test_set in test_sets], axis=1)\n",
    "#     y_pred = clf.predict_proba(meta_test)[:,1]\n",
    "#     return y_pred\n",
    "    \n",
    "# def predict_prob_single(test_X, trained_model_single,n_folds):\n",
    "#     test_sets = []\n",
    "#     model_res = np.zeros((len(test_X), n_folds))\n",
    "#     for i,sub_model in enumerate(trained_model_single):\n",
    "#         pred = sub_model.predict_proba(test_X)[:,1]\n",
    "#         model_res[:,i] = pred\n",
    "#     y_pred = np.mean(model_res,axis=1)\n",
    "#     return y_pred\n",
    "    \n",
    "# #计时打分程序\n",
    "# from ustciscrLab_A import get_score\n",
    "# get_score.post_user_id('23')\n",
    "# #====================================模型预测===================\n",
    "# # print(model_train[0])\n",
    "# # y_pred = predict_prob_stacking(test_X, model_train,lr,n_folds)\n",
    "# y_pred = predict_prob_single(test_X, model_train[0],n_folds)\n",
    "# #=====================================================\n",
    "# user_verify_data = pd.DataFrame({'zjnsrsbh':df_raw['zjnsrsbh'][train_num:],'Probability':y_pred})\n",
    "# get_score.post_verify_data(user_verify_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #计时打分程序\n",
    "# from ustciscrLab_A import get_score\n",
    "# get_score.post_user_id('23')\n",
    "# # 模型预测\n",
    "# test_sets = []\n",
    "# for model in model_train:\n",
    "#     model_res = np.zeros((len(test_X), n_folds))\n",
    "#     for i,sub_model in enumerate(model):\n",
    "#         pred = sub_model.predict_proba(test_X)[:,1]\n",
    "#         model_res[:,i] = pred\n",
    "#     res = np.mean(model_res,axis=1)\n",
    "#     test_sets.append(res)\n",
    "# meta_test = np.concatenate([y_test_set.reshape(-1,1) for y_test_set in test_sets], axis=1)\n",
    "# y_pred = lr.predict_proba(meta_test)[:,1]\n",
    "# user_verify_data = pd.DataFrame({'zjnsrsbh':df_raw['zjnsrsbh'][train_num:],'Probability':y_pred})\n",
    "# get_score.post_verify_data(user_verify_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
