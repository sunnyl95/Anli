{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**<font size=3>导入平台数据集</font>**\n",
    "\n",
    "**数据集插件 -> 添加数据集 -> 数据集列表 -> 插入代码**\n",
    "\n",
    "导入平台数据集并调试好代码后，点击代码编辑区的【运行全量】按钮，查看在全量数据的运行结果，全量数据运行结果的调用方式可参考：[《用户手册-全量运行代码调用》](/#/user-manual/experiment/experiment-debug)\n",
    "\n",
    "全量运行之后，获取全量运行结果的主要流程：\n",
    "**上传模型文件 -> 申报审核文件 -> 审核通过 ->下载文件**\n",
    "\n",
    "上传模型文件接口示例：\n",
    "\n",
    "```python\n",
    "import wfio\n",
    "wfio.upload_to_oss(server_path,local_path) \n",
    "#server_path是上传到服务器的文件名称，可以自定义\n",
    "#local_path是本地上传的文件路径, 必须是本地已经存在的文件路径。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1000 files...\n",
      "Downloading 1000 files...\n",
      "Downloading 1000 files...\n",
      "Downloading 1000 files...\n",
      "Downloading 1000 files...\n",
      "Downloading 1000 files...\n",
      "Downloading 1000 files...\n",
      "Downloading 1000 files...\n",
      "Downloading 965 files...\n",
      "All files download completed\n"
     ]
    }
   ],
   "source": [
    "#从S3将训练数据集下载到当前目录下的\"./traindata\"文件夹下\n",
    "\n",
    "import wfio\n",
    "_INPUT1 = '{\"type\":25,\"uri\":\"awss3442b3cbc7ba141e388f8b5ab770dd51d:/\"}'   #文件的路径\n",
    "marker = \"\"\n",
    "while True:\n",
    "    ret = wfio.listdir(_INPUT1, marker=marker)\n",
    "    print(\"Downloading {0} files...\".format(len(ret[\"file_list\"])))\n",
    "    wfio.download(\n",
    "        _INPUT1,\n",
    "        local_path=\"traindata\",                 # 文件下载保存的目录，为None则表示下载到当前目录\n",
    "        selected_files=ret[\"file_list\"], # 下载的文件名称列表，至少指定一个文件名称\n",
    "        overwrite=False                  # 是否覆盖同名文件\n",
    "    )\n",
    "    if not ret[\"has_more\"]:              # 判断是否有更多文件\n",
    "        print(\"All files download completed\")\n",
    "        break\n",
    "    marker = ret[\"next_marker\"]          # 下一次分页查询的开始标识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 1000 files...\n",
      "Downloading 1000 files...\n",
      "Downloading 399 files...\n",
      "All files download completed\n"
     ]
    }
   ],
   "source": [
    "#导入数据集garbage-test-sample\n",
    "#测试数据集将下载到当前目录下的\"./testdata\"文件夹下，如需改变目录名称请自行修改\n",
    "import wfio\n",
    "_INPUT = '{\"type\":25,\"uri\":\"awss3635559b903864399b44f4bd378d93e60:/\"}'\n",
    "dir_name = './testdata'\n",
    "marker = \"\" # 下一次分页查询的开始标识\n",
    "while True:\n",
    "   ret = wfio.listdir(_INPUT, marker=marker)  \n",
    "   print(\"Downloading {0} files...\".format(len(ret[\"file_list\"])))\n",
    "   wfio.download(\n",
    "       _INPUT,\n",
    "       local_path=\"testdata\",                 # 文件下载保存的目录，为None则表示下载到当前目录\n",
    "       selected_files=ret[\"file_list\"], # 下载的文件名称列表，至少指定一个文件名称\n",
    "       overwrite=False                  # 是否覆盖同名文件\n",
    "   )\n",
    "   if not ret[\"has_more\"]:              # 判断是否有更多文件, has_more字段不能修改\n",
    "       print(\"All files download completed\")\n",
    "       break\n",
    "   marker = ret[\"next_marker\"]          # 下一次分页查询的开始标识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要的包\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from wf_analyse.analyse import base\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据集\n",
    "class GarbageDataset(Dataset):\n",
    "    def __init__(self, root_path, transform=None, target_transform=None):\n",
    "        imgs_path = []\n",
    "        imgs_label = []\n",
    "        for file in os.listdir(root_path): \n",
    "            img_path = os.path.join(root_path, file)\n",
    "            imgs_path.append(img_path)\n",
    "            imgs_label.append(img_path.replace(\"images\", \"labels\").replace(\"jpg\", \"txt\"))\n",
    "        \n",
    "        self.imgs_path = imgs_path\n",
    "        self.imgs_label = imgs_label\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.imgs_path[idx])\n",
    "        \n",
    "        #如果图像非三通道，则读取下一张图片，直至读取到正确的三通道图片\n",
    "        while len(image.split())!=3:\n",
    "            idx += 1\n",
    "            image = Image.open(self.imgs_path[idx])\n",
    "        \n",
    "        #读取label文件\n",
    "        with open(self.imgs_label[idx], \"r\") as f:\n",
    "            label = int(f.read().split(\",\")[-1][1:])\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义简单CNN，输入是224*224\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, classes_num = 4):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 128,3,3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(128, 16,3, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, classes_num)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, class_num, alpha=None, gamma=2, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        if alpha is None:\n",
    "            self.alpha = Variable(torch.ones(class_num, 1))\n",
    "        else:\n",
    "            if isinstance(alpha, Variable):\n",
    "                self.alpha = torch.ones(class_num, 1)*alpha\n",
    "            else:\n",
    "                self.alpha = Variable(torch.ones(class_num, 1)*alpha)\n",
    "        self.gamma = gamma\n",
    "        self.class_num = class_num\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        N = inputs.size(0)\n",
    "        C = inputs.size(1)\n",
    "        P = F.softmax(inputs)\n",
    "\n",
    "        class_mask = inputs.data.new(N, C).fill_(0)\n",
    "        class_mask = Variable(class_mask)\n",
    "        ids = targets.view(-1, 1)\n",
    "        class_mask.scatter_(1, ids.data, 1.)\n",
    "\n",
    "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "        alpha = self.alpha[ids.data.view(-1)]\n",
    "\n",
    "        probs = (P*class_mask).sum(1).view(-1,1)\n",
    "\n",
    "        log_p = probs.log()\n",
    "\n",
    "        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_p\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = batch_loss.mean()\n",
    "        else:\n",
    "            loss = batch_loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,  dataloaders,dataset_sizes,num_epochs=100):\n",
    "    best_loss = 100\n",
    "    best_acc = 0\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_loss_list = []\n",
    "    test_acc_list = []\n",
    "    \n",
    "    print(\"\\nStart Train......\")\n",
    "    #创建模型保存的文件夹\n",
    "    if not  os.path.exists(\"./models\"):\n",
    "        os.makedirs(\"./models\")\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        start = time.time()\n",
    "        print('\\nEpoch: {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for i, data in enumerate(dataloaders[phase], 0):\n",
    "                batch_img, batch_labels = data['image'], data['label']\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(batch_img)\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    loss = criterion(outputs, batch_labels)\n",
    "                    \n",
    "                    #训练模式进行反向传播，更新参数\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * batch_img.size(0)\n",
    "                running_corrects += torch.sum(preds.float() == batch_labels.float())\n",
    "            end = time.time()\n",
    "            \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "    \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            #保存acc最佳的模型\n",
    "            if phase == 'test' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model, './models/mycnn.pth')\n",
    "            \n",
    "            if phase == 'test' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "            \n",
    "            #保存训练过程loss与acc值\n",
    "            if phase == \"train\":\n",
    "                train_loss_list.append(epoch_loss)\n",
    "                train_acc_list.append(epoch_acc)\n",
    "            else:\n",
    "                test_loss_list.append(epoch_loss)\n",
    "                test_acc_list.append(epoch_acc)\n",
    "            \n",
    "        \n",
    "        \n",
    "        print('Training complete in {:.4f} mins'.format((end - start)/60))\n",
    "        print('Best val Loss: {:4f}\\n'.format(best_loss))\n",
    "        print('Best val acc: {:4f}\\n'.format(best_acc))\n",
    "    \n",
    "    \n",
    "    print(\"End Train......\\n\")\n",
    "    \n",
    "    #在全量运行时，保存训练集在训练过程中的loss和acc值，用于绘制loss和acc变化曲线图\n",
    "    for i in range(0, num_epochs, 1):\n",
    "        base.save_norm_by_step(model_name='train', norm_name='Loss',norm_value=np.float(train_loss_list[i]),step=i)\n",
    "        base.save_norm_by_step(model_name='train', norm_name='Accuracy',norm_value=np.float(train_acc_list[i]),step=i)\n",
    "    \n",
    "     #在全量运行时，保存测试集在训练过程中的loss与acc值，用于绘制loss和acc变化曲线图\n",
    "    for i in range(0, num_epochs, 1):\n",
    "        base.save_norm_by_step(model_name='test', norm_name='Loss',norm_value=np.float(test_loss_list[i]),step=i)\n",
    "        base.save_norm_by_step(model_name='test', norm_name='Accuracy',norm_value=np.float(test_acc_list[i]),step=i)\n",
    "        \n",
    "    #绘制验证集在训练过程中的loss曲线图\n",
    "    epoch = []  # 横坐标,迭代次数\n",
    "    for i in range(0, num_epochs, 1):\n",
    "        epoch.append(i)\n",
    "\n",
    "    plt.plot(epoch, train_loss_list)\n",
    "    # plt.plot([1,3,3,4], [1,4,9,16])\n",
    "    plt.ylabel('train loss')\n",
    "    plt.xlabel('train epoch')\n",
    "    plt.title(\" Curve of loss(crossentory) function of train set\")\n",
    "    plt.show()\n",
    "    \n",
    "    #绘制验证集在训练过程中的acc曲线图\n",
    "    epoch = []  # 横坐标,迭代次数\n",
    "    for i in range(0, num_epochs, 1):\n",
    "        epoch.append(i)\n",
    "\n",
    "    plt.plot(epoch, train_acc_list)\n",
    "    # plt.plot([1,3,3,4], [1,4,9,16])\n",
    "    plt.ylabel('train acc')\n",
    "    plt.xlabel('train epoch')\n",
    "    plt.title(\" Curve of Accuracy  function of train set\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #1.基本参数设置\n",
    "    learning_rate = 0.01  #学习率\n",
    "    epoch_num = 50         #学习迭代次数\n",
    "    \n",
    "    \n",
    "    #2.数据位置\n",
    "    train_root_path = '/home/nbuser/work_2347b8d076f44f16a78f622099a9b1e8/traindata/train/images/'\n",
    "    test_root_path = '/home/nbuser/work_2347b8d076f44f16a78f622099a9b1e8/testdata/test/images/'\n",
    "    \n",
    "    \n",
    "    #4.数据预处理\n",
    "    train_transform =transforms.Compose(\n",
    "        [transforms.RandomHorizontalFlip(),\n",
    "        transforms.Resize([224,224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "     \n",
    "    test_transform =transforms.Compose(\n",
    "        [transforms.Resize([224,224]),\n",
    "         transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) ])\n",
    "    \n",
    "    #5.生成dataloader数据集\n",
    "    train_set = GarbageDataset(root_path=train_root_path,transform=train_transform)\n",
    "    train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "    \n",
    "    test_set = GarbageDataset(root_path=test_root_path,transform=test_transform)\n",
    "    test_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "    \n",
    "    dataloaders = {'train': train_loader, 'test': test_loader}\n",
    "    dataset_sizes = {'train': len(train_set), 'test': len(test_set)}\n",
    "    print('train samples:{}张'.format(dataset_sizes[\"train\"]))\n",
    "    print('test samples:{}张'.format(dataset_sizes[\"test\"]))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #6。定义模型、优化器、损失函数\n",
    "    #model = Net(39)\n",
    "    model = models.resnet50(pretrained=True, progress=True)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #7.开始训练模型\n",
    "    train_model(model, criterion, optimizer, num_epochs=epoch_num, dataloaders=dataloaders, dataset_sizes=dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train samples:4482张\n",
      "test samples:1199张\n",
      "\n",
      "Start Train......\n",
      "\n",
      "Epoch: 1/50\n",
      "----------\n",
      "train Loss: 2.5133 Acc: 0.2992\n",
      "test Loss: 1.7651 Acc: 0.4287\n",
      "Training complete in 26.4895 mins\n",
      "Best val Loss: 1.765090\n",
      "\n",
      "Best val acc: 0.428691\n",
      "\n",
      "\n",
      "Epoch: 2/50\n",
      "----------\n",
      "train Loss: 1.5451 Acc: 0.5054\n",
      "test Loss: 1.4157 Acc: 0.5563\n",
      "Training complete in 26.1127 mins\n",
      "Best val Loss: 1.415704\n",
      "\n",
      "Best val acc: 0.556297\n",
      "\n",
      "\n",
      "Epoch: 3/50\n",
      "----------\n",
      "train Loss: 1.1184 Acc: 0.6421\n",
      "test Loss: 1.2155 Acc: 0.6330\n",
      "Training complete in 26.1400 mins\n",
      "Best val Loss: 1.215479\n",
      "\n",
      "Best val acc: 0.633028\n",
      "\n",
      "\n",
      "Epoch: 4/50\n",
      "----------\n",
      "train Loss: 0.8660 Acc: 0.7218\n",
      "test Loss: 1.2939 Acc: 0.6539\n",
      "Training complete in 26.0378 mins\n",
      "Best val Loss: 1.215479\n",
      "\n",
      "Best val acc: 0.653878\n",
      "\n",
      "\n",
      "Epoch: 5/50\n",
      "----------\n",
      "train Loss: 0.6996 Acc: 0.7742\n",
      "test Loss: 1.0401 Acc: 0.7039\n",
      "Training complete in 26.0621 mins\n",
      "Best val Loss: 1.040053\n",
      "\n",
      "Best val acc: 0.703920\n",
      "\n",
      "\n",
      "Epoch: 6/50\n",
      "----------\n",
      "train Loss: 0.5691 Acc: 0.8141\n",
      "test Loss: 0.8897 Acc: 0.7306\n",
      "Training complete in 26.0154 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.730609\n",
      "\n",
      "\n",
      "Epoch: 7/50\n",
      "----------\n",
      "train Loss: 0.4517 Acc: 0.8534\n",
      "test Loss: 0.8916 Acc: 0.7273\n",
      "Training complete in 26.0798 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.730609\n",
      "\n",
      "\n",
      "Epoch: 8/50\n",
      "----------\n",
      "train Loss: 0.3589 Acc: 0.8831\n",
      "test Loss: 1.1460 Acc: 0.6881\n",
      "Training complete in 25.9780 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.730609\n",
      "\n",
      "\n",
      "Epoch: 9/50\n",
      "----------\n",
      "train Loss: 0.3310 Acc: 0.8878\n",
      "test Loss: 1.4495 Acc: 0.6514\n",
      "Training complete in 26.0500 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.730609\n",
      "\n",
      "\n",
      "Epoch: 10/50\n",
      "----------\n",
      "train Loss: 0.3750 Acc: 0.8788\n",
      "test Loss: 1.0724 Acc: 0.7331\n",
      "Training complete in 26.0707 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.733111\n",
      "\n",
      "\n",
      "Epoch: 11/50\n",
      "----------\n",
      "train Loss: 0.2788 Acc: 0.9045\n",
      "test Loss: 0.9127 Acc: 0.7531\n",
      "Training complete in 26.0558 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.753128\n",
      "\n",
      "\n",
      "Epoch: 12/50\n",
      "----------\n",
      "train Loss: 0.2609 Acc: 0.9145\n",
      "test Loss: 1.0025 Acc: 0.7314\n",
      "Training complete in 26.0304 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.753128\n",
      "\n",
      "\n",
      "Epoch: 13/50\n",
      "----------\n",
      "train Loss: 0.1986 Acc: 0.9337\n",
      "test Loss: 0.9911 Acc: 0.7440\n",
      "Training complete in 26.0760 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.753128\n",
      "\n",
      "\n",
      "Epoch: 14/50\n",
      "----------\n",
      "train Loss: 0.1712 Acc: 0.9433\n",
      "test Loss: 1.0493 Acc: 0.7706\n",
      "Training complete in 26.0008 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 15/50\n",
      "----------\n",
      "train Loss: 0.1958 Acc: 0.9386\n",
      "test Loss: 1.0692 Acc: 0.7498\n",
      "Training complete in 25.9321 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 16/50\n",
      "----------\n",
      "train Loss: 0.1389 Acc: 0.9536\n",
      "test Loss: 0.9474 Acc: 0.7706\n",
      "Training complete in 25.9695 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 17/50\n",
      "----------\n",
      "train Loss: 0.1027 Acc: 0.9656\n",
      "test Loss: 1.4473 Acc: 0.7098\n",
      "Training complete in 25.8922 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 18/50\n",
      "----------\n",
      "train Loss: 0.1391 Acc: 0.9534\n",
      "test Loss: 1.1548 Acc: 0.7373\n",
      "Training complete in 25.8795 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 19/50\n",
      "----------\n",
      "train Loss: 0.1450 Acc: 0.9496\n",
      "test Loss: 1.0339 Acc: 0.7556\n",
      "Training complete in 25.8892 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 20/50\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9679\n",
      "test Loss: 0.9611 Acc: 0.7706\n",
      "Training complete in 25.9173 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 21/50\n",
      "----------\n",
      "train Loss: 0.1288 Acc: 0.9585\n",
      "test Loss: 1.0178 Acc: 0.7581\n",
      "Training complete in 26.0107 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 22/50\n",
      "----------\n",
      "train Loss: 0.1347 Acc: 0.9576\n",
      "test Loss: 1.0006 Acc: 0.7515\n",
      "Training complete in 25.9570 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 23/50\n",
      "----------\n",
      "train Loss: 0.0968 Acc: 0.9690\n",
      "test Loss: 1.1842 Acc: 0.7415\n",
      "Training complete in 25.7536 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 24/50\n",
      "----------\n",
      "train Loss: 0.0686 Acc: 0.9788\n",
      "test Loss: 1.2951 Acc: 0.7131\n",
      "Training complete in 25.8904 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.770642\n",
      "\n",
      "\n",
      "Epoch: 25/50\n",
      "----------\n",
      "train Loss: 0.0714 Acc: 0.9797\n",
      "test Loss: 0.9841 Acc: 0.7748\n",
      "Training complete in 25.9320 mins\n",
      "Best val Loss: 0.889670\n",
      "\n",
      "Best val acc: 0.774812\n",
      "\n",
      "\n",
      "Epoch: 26/50\n",
      "----------\n",
      "train Loss: 0.0522 Acc: 0.9826\n",
      "test Loss: 0.8753 Acc: 0.8065\n",
      "Training complete in 25.7969 mins\n",
      "Best val Loss: 0.875332\n",
      "\n",
      "Best val acc: 0.806505\n",
      "\n",
      "\n",
      "Epoch: 27/50\n",
      "----------\n",
      "train Loss: 0.0771 Acc: 0.9748\n",
      "test Loss: 0.8681 Acc: 0.7998\n",
      "Training complete in 25.9396 mins\n",
      "Best val Loss: 0.868110\n",
      "\n",
      "Best val acc: 0.806505\n",
      "\n",
      "\n",
      "Epoch: 28/50\n",
      "----------\n",
      "train Loss: 0.0891 Acc: 0.9721\n",
      "test Loss: 1.0959 Acc: 0.7706\n",
      "Training complete in 25.7757 mins\n",
      "Best val Loss: 0.868110\n",
      "\n",
      "Best val acc: 0.806505\n",
      "\n",
      "\n",
      "Epoch: 29/50\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.9835\n",
      "test Loss: 1.3090 Acc: 0.7406\n",
      "Training complete in 25.9329 mins\n",
      "Best val Loss: 0.868110\n",
      "\n",
      "Best val acc: 0.806505\n",
      "\n",
      "\n",
      "Epoch: 30/50\n",
      "----------\n",
      "train Loss: 0.0689 Acc: 0.9748\n",
      "test Loss: 1.0279 Acc: 0.7756\n",
      "Training complete in 25.9995 mins\n",
      "Best val Loss: 0.868110\n",
      "\n",
      "Best val acc: 0.806505\n",
      "\n",
      "\n",
      "Epoch: 31/50\n",
      "----------\n",
      "train Loss: 0.0687 Acc: 0.9768\n",
      "test Loss: 0.9461 Acc: 0.7882\n",
      "Training complete in 25.9563 mins\n",
      "Best val Loss: 0.868110\n",
      "\n",
      "Best val acc: 0.806505\n",
      "\n",
      "\n",
      "Epoch: 32/50\n",
      "----------\n",
      "test Loss: 1.1602 Acc: 0.7781\n",
      "Training complete in 26.1807 mins\n",
      "Best val Loss: 0.868110\n",
      "\n",
      "Best val acc: 0.806505\n",
      "\n",
      "\n",
      "Epoch: 33/50\n",
      "----------\n",
      "train Loss: 0.0645 Acc: 0.9815\n",
      "test Loss: 0.9620 Acc: 0.7915\n",
      "Training complete in 25.8536 mins\n",
      "Best val Loss: 0.868110\n",
      "\n",
      "Best val acc: 0.806505\n",
      "\n",
      "\n",
      "Epoch: 34/50\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #训练\n",
    "    main()\n",
    "    #模型申报审核\n",
    "    wfio.upload_to_oss(\"mycnn.model\", \"./models/mycnn.model\")  #将分类模型上传至 oss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}